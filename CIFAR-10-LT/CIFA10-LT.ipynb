{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6eHm7W0Kc4Fu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 07:41:59.480016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tensorflow.python.training.tracking import base as trackable\n",
    "# from tensorflow.python.keras.engine import data_adapter\n",
    "# from tensorflow.python.eager import backprop\n",
    "from functools import partial\n",
    "# from tensorflow.python.keras.engine.training import _minimize\n",
    "# import tensorflow_addons as tfa\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Uz7ssaYixpuN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 07:42:01.288471: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-26 07:42:01.289623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-26 07:42:01.330548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:48:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2023-04-26 07:42:01.330571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-26 07:42:01.332676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-26 07:42:01.332722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-26 07:42:01.334766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-26 07:42:01.335063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-26 07:42:01.337157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-26 07:42:01.338224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-26 07:42:01.342415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-26 07:42:01.349937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lup2j6RUelce"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 07:42:01.362055: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function decode at 0x7fba02ebcee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function decode at 0x7fba02ebcee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 07:42:01.370446: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-26 07:42:01.374802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:48:00.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2023-04-26 07:42:01.374843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-26 07:42:01.374885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-26 07:42:01.374895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-26 07:42:01.374905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-26 07:42:01.374915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-26 07:42:01.374925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-26 07:42:01.374935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-26 07:42:01.374946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-26 07:42:01.387298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-26 07:42:01.387358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-26 07:42:02.372963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-26 07:42:02.372991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-04-26 07:42:02.372997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-04-26 07:42:02.387272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30104 MB memory) -> physical GPU (device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:48:00.0, compute capability: 7.0)\n",
      "2023-04-26 07:42:02.438017: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-04-26 07:42:02.438467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2095165000 Hz\n"
     ]
    }
   ],
   "source": [
    "n_class = 10\n",
    "train_set_size = 12406\n",
    "test_set_size = 10000\n",
    "valid_size_per_class = 5\n",
    "\n",
    "valid_set_size = valid_size_per_class * n_class\n",
    "\n",
    "\n",
    "\n",
    "def decode(instance):\n",
    "    feature_spec = {\n",
    "    'image/encoded': tf.io.FixedLenFeature((), tf.string),\n",
    "    'image/class/label': tf.io.FixedLenFeature((), tf.int64)\n",
    "    }\n",
    "    instance = tf.io.parse_example(instance, feature_spec)\n",
    "    image = tf.io.decode_raw(instance[\"image/encoded\"], tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [32, 32, 3])\n",
    "    label = instance[\"image/class/label\"]\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "traing_dateset = tf.data.TFRecordDataset(\"./data/cifar10-lt_train.tfrecord\").map(decode)\n",
    "\n",
    "train_x, train_y = np.zeros([train_set_size, 32, 32, 3]), np.zeros([train_set_size])\n",
    "for i,instance in enumerate(traing_dateset.as_numpy_iterator()):\n",
    "    train_x[i] = instance[0]\n",
    "    train_y[i] = instance[1]\n",
    "\n",
    "valid_x, valid_y = np.zeros([valid_set_size,32,32,3]), np.zeros([valid_set_size])\n",
    "\n",
    "train_set_size_no_valid = train_set_size - valid_set_size\n",
    "train_x_no_valid = train_x\n",
    "train_y_no_valid = train_y\n",
    "\n",
    "train_size_no_valid_per_class = np.zeros([n_class])\n",
    "\n",
    "for i in range(n_class):\n",
    "    indices_of_instances = np.where(train_y_no_valid == i)[0]\n",
    "    train_size_no_valid_per_class[i] = len(indices_of_instances) - valid_size_per_class\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    np.random.shuffle(indices_of_instances)\n",
    "    \n",
    "    indices_of_valid_instances = indices_of_instances[ : valid_size_per_class]\n",
    "    valid_x[i * valid_size_per_class : (i+1) * valid_size_per_class] = \\\n",
    "        train_x_no_valid[indices_of_valid_instances]\n",
    "    \n",
    "    valid_y[i * valid_size_per_class : (i+1) * valid_size_per_class] = \\\n",
    "        train_y_no_valid[indices_of_valid_instances]\n",
    "    \n",
    "    train_x_no_valid = np.delete(train_x_no_valid, indices_of_valid_instances, 0)\n",
    "    train_y_no_valid = np.delete(train_y_no_valid, indices_of_valid_instances, 0)\n",
    "\n",
    "    \n",
    "test_dateset = tf.data.TFRecordDataset(\"./data/cifar10_test.tfrecord\").map(decode)\n",
    "\n",
    "test_x, test_y = np.zeros([test_set_size, 32, 32, 3]), np.zeros([test_set_size])\n",
    "for i,instance in enumerate(test_dateset.as_numpy_iterator()):\n",
    "    test_x[i] = instance[0]\n",
    "    test_y[i] = instance[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 12356\n",
      "test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('training set size:',len(train_x_no_valid))\n",
    "print('test set size:',len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q5nA5eZEfHXn"
   },
   "outputs": [],
   "source": [
    "normalize_x = lambda x: x/255 - 0.5\n",
    "\n",
    "train_x_no_valid = tf.constant(normalize_x(train_x_no_valid))\n",
    "test_x = tf.constant(normalize_x(test_x))\n",
    "valid_x = tf.constant(normalize_x(valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qqabQ0IpfIlM"
   },
   "outputs": [],
   "source": [
    "train_y_no_valid = tf.constant(keras.utils.to_categorical(train_y_no_valid, n_class))\n",
    "test_y = tf.constant(keras.utils.to_categorical(test_y, n_class))\n",
    "valid_y = tf.constant(keras.utils.to_categorical(valid_y, n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(train_size_no_valid_per_class)), train_size_no_valid_per_class)\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.xlabel('Sorted Index of Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 4\n",
    "\n",
    "# @trackable.no_automatic_dependency_tracking \n",
    "def train_generator(epochs, batch_size, encoding_matrix):\n",
    "    def preprocess_data(x, y):\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 32 + padding, 32 + padding)\n",
    "        x = tf.image.random_crop(x, [32, 32, 3])\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        y = tf.matmul(train_y_no_valid, encoding_matrix)\n",
    "    \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_x_no_valid, y)\n",
    "        ).map(\n",
    "            preprocess_data\n",
    "        ).shuffle(\n",
    "            train_set_size, epoch\n",
    "        ).batch(\n",
    "            batch_size\n",
    "        ).prefetch(\n",
    "            tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "    \n",
    "        for batch in train_dataset:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal loss \n",
    "def focal(gamma=2.):\n",
    "    def focal_loss (y_true, y_pred):\n",
    "        ep = 1e-7\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_pred = y_pred + (1. - 2.*y_pred) * ep\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_sum(-y_true*((1-y_pred)**gamma)*tf.math.log(y_pred), axis=1)\n",
    "    \n",
    "    return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_key = 'ce'\n",
    "focal_gamma = 1.\n",
    "loss_fn_dic = {'focal':focal(focal_gamma), \n",
    "               'ce':keras.losses.categorical_crossentropy,\n",
    "               'mse':keras.losses.mean_squared_error}\n",
    "loss_fn = loss_fn_dic[loss_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NizAKxPTxpuQ"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9CiBEzRDxpuQ"
   },
   "outputs": [],
   "source": [
    "evaluation_batch_size = 5000\n",
    "\n",
    "class UpdateEncodingMatrixAndGetMetrics_EEC (keras.callbacks.Callback):\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def __init__(self, \n",
    "                 beginEncodingEpoch,endEncodingEpoch, \n",
    "                 codingEnhancementRate, mu, \n",
    "                 trainSet_x, trainSet_y, \n",
    "                 validSet_x, validSet_y,\n",
    "                 trainMetrics, validMetrics,\n",
    "                 keyWord):\n",
    "        super().__init__()\n",
    "        self.beginEncodingEpoch = beginEncodingEpoch\n",
    "        self.endEncodingEpoch = endEncodingEpoch\n",
    "        self.codingEnhancementRate = tf.constant(codingEnhancementRate)\n",
    "        self.trainSet_x = trainSet_x\n",
    "        self.trainSet_y = trainSet_y\n",
    "        self.validSet_x = validSet_x\n",
    "        self.validSet_y = validSet_y\n",
    "        self.trainMetrics = trainMetrics\n",
    "        self.validMetrics = validMetrics\n",
    "        self.mu = mu\n",
    "        self.keyWord = keyWord\n",
    "\n",
    "    \n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def _confusion_matrix(self, labels, preds):\n",
    "        pred_classes = tf.one_hot(tf.argmax(preds, axis=1), 10)\n",
    "        cm=tf.matmul(labels, pred_classes, transpose_a=True)\n",
    "        cm=cm/tf.reduce_sum(cm, axis=1, keepdims=True)\n",
    "        return cm\n",
    "\n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def _soft_confusion_matrix(self, labels, preds):\n",
    "        scm=tf.matmul(labels, preds, transpose_a=True)\n",
    "        scm=scm/tf.reduce_sum(scm, axis=1, keepdims=True)\n",
    "        return scm\n",
    "\n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def _make_encoding_matrix(self, confusionMatrix):\n",
    "        coSenMatrix =  confusionMatrix - tf.eye(10)\n",
    "        encodingMatrix = - self.codingEnhancementRate \\\n",
    "                            * coSenMatrix \\\n",
    "                            + tf.eye(10)\n",
    "        \n",
    "        return encodingMatrix\n",
    "\n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def on_train_begin(self, logs):\n",
    "        if self.endEncodingEpoch <= 0 or self.beginEncodingEpoch > 0:\n",
    "            encodingMatrix = tf.eye(10)\n",
    "        else:\n",
    "            y_h = tf.constant(self.model.predict(self.validSet_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "            y = self.validSet_y\n",
    "            scm = self._soft_confusion_matrix(y, y_h)\n",
    "            encodingMatrix = ((1-self.mu) * encoding_matrix +\n",
    "                              self.mu * self._make_encoding_matrix(scm))\n",
    "        K.set_value(encoding_matrix, encodingMatrix)\n",
    "\n",
    "   \n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        print('\\n'+self.keyWord)\n",
    "        \n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        y_h = tf.constant(self.model.predict(self.trainSet_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "        y = self.trainSet_y\n",
    "        self.trainMetrics[0][epoch] = self._soft_confusion_matrix(y, y_h).numpy()\n",
    "        self.trainMetrics[1][epoch] = self._confusion_matrix(y, y_h).numpy()\n",
    "        self.trainMetrics[2][epoch] = tf.reduce_mean(loss_fn(y, y_h)).numpy()\n",
    "        self.trainMetrics[3][epoch] = tf.reduce_mean(keras.metrics.categorical_accuracy(y, y_h)).numpy()\n",
    "        self.trainMetrics[4][epoch] = metrics.roc_auc_score(y.numpy(), y_h.numpy(), multi_class='ovr')\n",
    "\n",
    "        print('\\nTest on train set:',\n",
    "              'loss=', self.trainMetrics[2][epoch],\n",
    "              'acc=', self.trainMetrics[3][epoch],\n",
    "              'auc=', self.trainMetrics[4][epoch] )\n",
    "\n",
    "        y_h = tf.constant(self.model.predict(self.validSet_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "        y = self.validSet_y\n",
    "        scm = self._soft_confusion_matrix(y, y_h)\n",
    "        self.validMetrics[0][epoch] = scm.numpy()\n",
    "        self.validMetrics[1][epoch] = tf.reduce_mean(loss_fn(y, y_h)).numpy()\n",
    "        self.validMetrics[2][epoch] = scm.numpy().diagonal().mean()\n",
    "        self.validMetrics[3][epoch] = metrics.roc_auc_score(y.numpy(), y_h.numpy(), multi_class='ovr')\n",
    "\n",
    "        print('Test on valid set:',\n",
    "            'loss=', self.validMetrics[1][epoch],\n",
    "            'acc=', self.validMetrics[2][epoch],\n",
    "            'auc=', self.validMetrics[3][epoch] )\n",
    "\n",
    "        if epoch+1 < self.endEncodingEpoch and epoch+1>=self.beginEncodingEpoch:\n",
    "            new_encoding_matrix = (1-self.mu) * encoding_matrix + \\\n",
    "                              self.mu * self._make_encoding_matrix(scm)\n",
    "            K.set_value(encoding_matrix, new_encoding_matrix)\n",
    "\n",
    "        elif epoch+1 == self.endEncodingEpoch:\n",
    "            K.set_value(encoding_matrix, tf.eye(10))\n",
    "            \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def on_train_end(self, logs):\n",
    "        K.set_value(encoding_matrix, tf.eye(10))\n",
    "        print('*'*100)\n",
    "        print('*'*100)\n",
    "        print('*'*100)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "class UpdateEncodingMatrixAndGetMetrics_Base (UpdateEncodingMatrixAndGetMetrics_EEC):\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def __init__(self, \n",
    "                 trainSet_x, trainSet_y, \n",
    "                 validSet_x, validSet_y,\n",
    "                 trainMetrics, validMetrics,\n",
    "                 keyWord):\n",
    "        super(UpdateEncodingMatrixAndGetMetrics_EEC, self).__init__()\n",
    "        self.trainSet_x = trainSet_x\n",
    "        self.trainSet_y = trainSet_y\n",
    "        self.validSet_x = validSet_x\n",
    "        self.validSet_y = validSet_y\n",
    "        self.trainMetrics = trainMetrics\n",
    "        self.validMetrics = validMetrics\n",
    "        self.keyWord = keyWord\n",
    "\n",
    "   \n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def _make_encoding_matrix(self):\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def on_train_begin(self, logs):\n",
    "        super(UpdateEncodingMatrixAndGetMetrics_EEC, self).on_train_begin(logs)\n",
    "\n",
    "\n",
    "    @trackable.no_automatic_dependency_tracking\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        y_h = tf.constant(self.model.predict(self.trainSet_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "        y = self.trainSet_y\n",
    "        self.trainMetrics[0][epoch] = self._soft_confusion_matrix(y, y_h).numpy()\n",
    "        self.trainMetrics[1][epoch] = self._confusion_matrix(y, y_h).numpy()\n",
    "        self.trainMetrics[2][epoch] = tf.reduce_mean(loss_fn(y, y_h)).numpy()\n",
    "        self.trainMetrics[3][epoch] = tf.reduce_mean(keras.metrics.categorical_accuracy(y, y_h)).numpy()\n",
    "        self.trainMetrics[4][epoch] = metrics.roc_auc_score(y.numpy(), y_h.numpy(), multi_class='ovr')\n",
    "\n",
    "        print('\\nTest on train set:',\n",
    "            'loss=', self.trainMetrics[2][epoch],\n",
    "            'acc=', self.trainMetrics[3][epoch],\n",
    "            'auc=', self.trainMetrics[4][epoch] )\n",
    "\n",
    "        y_h = tf.constant(self.model.predict(self.validSet_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "        y = self.validSet_y\n",
    "        scm = self._soft_confusion_matrix(y, y_h)\n",
    "        self.validMetrics[0][epoch] = scm.numpy()\n",
    "        self.validMetrics[1][epoch] = tf.reduce_mean(loss_fn(y, y_h)).numpy()\n",
    "        self.validMetrics[2][epoch] = scm.numpy().diagonal().mean()\n",
    "        self.validMetrics[3][epoch] = metrics.roc_auc_score(y.numpy(), y_h.numpy(), multi_class='ovr')\n",
    "        \n",
    "        print('Test on valid set:',\n",
    "            'loss=', self.validMetrics[1][epoch],\n",
    "            'acc=', self.validMetrics[2][epoch],\n",
    "            'auc=', self.validMetrics[3][epoch] )\n",
    "\n",
    "        print()\n",
    "\n",
    "        \n",
    "        \n",
    "#################################################################################################################        \n",
    "class UpdateEncodingMatrixAndGetMetrics_Reweight (UpdateEncodingMatrixAndGetMetrics_EEC):\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def _make_encoding_matrix(self, confusionMatrix):\n",
    "        CoSenMatrix =  confusionMatrix - tf.eye(10)\n",
    "        encodingMatrix = - self.codingEnhancementRate \\\n",
    "                            * CoSenMatrix \\\n",
    "                            + tf.eye(10)\n",
    "        encodingMatrix = encodingMatrix * tf.eye(10)\n",
    "        return encodingMatrix        \n",
    "\n",
    "#################################################################################################################        \n",
    "class UpdateEncodingMatrixAndGetMetrics_CoSen (UpdateEncodingMatrixAndGetMetrics_EEC):\n",
    "    @trackable.no_automatic_dependency_tracking \n",
    "    def _make_encoding_matrix(self, confusionMatrix):\n",
    "        CoSenMatrix =  (1 - tf.eye(10))*(confusionMatrix - tf.eye(10))\n",
    "        encodingMatrix = - self.codingEnhancementRate \\\n",
    "                            * CoSenMatrix \\\n",
    "                            + tf.eye(10)\n",
    "        return encodingMatrix     \n",
    "    \n",
    "##################################################################################################################\n",
    "class AdjustLR (keras.callbacks.Callback):\n",
    "    def __init__(self, schedule, base_learning_rate = None):\n",
    "        super().__init__()\n",
    "        self._schedule = schedule\n",
    "        self._base_learning_rate = base_learning_rate\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        warmup_lr_multiplier, warmup_end_epoch = self._schedule[0]\n",
    "        learning_rate = (\n",
    "            self._base_learning_rate * warmup_lr_multiplier * (epoch+1) /\n",
    "            (warmup_end_epoch+1))\n",
    "        for mult, start_epoch in self._schedule:\n",
    "            learning_rate = tf.where(epoch >= start_epoch,\n",
    "                                   self._base_learning_rate * mult, learning_rate)\n",
    "\n",
    "        K.set_value(self.model.optimizer.learning_rate, learning_rate)\n",
    "        print(self.model.optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu-nz9Bm3695"
   },
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 38, 38, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 36, 36, 16)        432       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 36, 36, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 36, 36, 16)        0         \n",
      "_________________________________________________________________\n",
      "residual_unit (ResidualUnit) (None, 36, 36, 16)        3008      \n",
      "_________________________________________________________________\n",
      "residual_unit_1 (ResidualUni (None, 36, 36, 16)        3008      \n",
      "_________________________________________________________________\n",
      "residual_unit_2 (ResidualUni (None, 36, 36, 16)        3008      \n",
      "_________________________________________________________________\n",
      "residual_unit_3 (ResidualUni (None, 36, 36, 16)        3008      \n",
      "_________________________________________________________________\n",
      "residual_unit_4 (ResidualUni (None, 36, 36, 16)        3008      \n",
      "_________________________________________________________________\n",
      "residual_unit_5 (ResidualUni (None, 18, 18, 32)        11776     \n",
      "_________________________________________________________________\n",
      "residual_unit_6 (ResidualUni (None, 18, 18, 32)        11648     \n",
      "_________________________________________________________________\n",
      "residual_unit_7 (ResidualUni (None, 18, 18, 32)        11648     \n",
      "_________________________________________________________________\n",
      "residual_unit_8 (ResidualUni (None, 18, 18, 32)        11648     \n",
      "_________________________________________________________________\n",
      "residual_unit_9 (ResidualUni (None, 18, 18, 32)        11648     \n",
      "_________________________________________________________________\n",
      "residual_unit_10 (ResidualUn (None, 9, 9, 64)          46080     \n",
      "_________________________________________________________________\n",
      "residual_unit_11 (ResidualUn (None, 9, 9, 64)          45824     \n",
      "_________________________________________________________________\n",
      "residual_unit_12 (ResidualUn (None, 9, 9, 64)          45824     \n",
      "_________________________________________________________________\n",
      "residual_unit_13 (ResidualUn (None, 9, 9, 64)          45824     \n",
      "_________________________________________________________________\n",
      "residual_unit_14 (ResidualUn (None, 9, 9, 64)          45824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 304,226\n",
      "Trainable params: 300,494\n",
      "Non-trainable params: 3,732\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "he_normal = keras.initializers.HeUniform()\n",
    "glorot_normal = keras.initializers.GlorotNormal()\n",
    "he_uniform = keras.initializers.HeUniform()\n",
    "glorot_uniform = keras.initializers.GlorotUniform()\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
    "                        padding=\"SAME\", use_bias=False, \n",
    "                        kernel_initializer=he_normal)\n",
    "DefaultBN = partial(keras.layers.BatchNormalization, \n",
    "                      momentum=0.9,\n",
    "                      epsilon=1e-5)\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters,kernel_size=1,strides=strides),\n",
    "            DefaultBN(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            DefaultBN(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters,kernel_size=1),\n",
    "            DefaultBN()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                DefaultBN()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(keras.layers.ZeroPadding2D(padding=(3, 3)))\n",
    "model.add(DefaultConv2D(16,padding='valid'))\n",
    "model.add(DefaultBN())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "prev_filters = 16\n",
    "for filters in [16] * 5 + [32] * 5 + [64] * 5:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "\n",
    "model.add(DefaultBN())\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, kernel_initializer=keras.initializers.RandomNormal(stddev=0.01)))\n",
    "model.add(DefaultBN())\n",
    "model.add(keras.layers.Softmax())\n",
    "model.summary()\n",
    "initialWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = lambda learning_rate=0.01:keras.optimizers.SGD(learning_rate = learning_rate, \n",
    "                                                          momentum=0.9,  \n",
    "                                                          nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 07:42:12.006949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-26 07:42:12.298204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 7s 27ms/step - loss: 2.3240\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = Optimizer()\n",
    "model.compile(optimizer=optimizer, loss = loss_fn)\n",
    "model.set_weights(initialWeights)\n",
    "        \n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.prev_loss = 0\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        batch_loss = logs[\"loss\"] * (batch + 1) - self.prev_loss * batch\n",
    "        self.prev_loss = logs[\"loss\"]\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)        \n",
    "        \n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=100):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), 5.0])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    \n",
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, train_x_no_valid, train_y_no_valid, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-P5P0ZLDxpuW",
    "outputId": "168357d3-92d5-4f6f-eaba-92ef84ecea7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lrDic = {'focal':0.5,\n",
    "         'ce':0.1,\n",
    "         'mse':5.0\n",
    "        }\n",
    "lr = lrDic[loss_key]\n",
    "codingEnhancementRateDic = {'focal':0.5,\n",
    "                            'ce':1.0,\n",
    "                            'mse':0.5\n",
    "                           }\n",
    "codingEnhancementRate = codingEnhancementRateDic[loss_key]\n",
    "\n",
    "lr_schedule_dic = {'focal':[(1.0, 5), (0.1, 200), (0.01, 300)],\n",
    "                   'ce':[(1.0, 5), (0.1, 200), (0.01, 250)],\n",
    "                   'mse':[(1.0, 5), (0.1, 200), (0.01, 300)]}\n",
    "\n",
    "lr_schedule = lr_schedule_dic[loss_key]\n",
    "\n",
    "mu = 0.1 if loss_key == \"mse\" else 0.5  #update rate\n",
    "\n",
    "epochs_dic = {'focal':400,\n",
    "          'ce':300,\n",
    "          'mse':400} \n",
    "epochs = epochs_dic[loss_key]\n",
    "endEncodingEpoch = epochs\n",
    "beginEncodingEpoch = 0\n",
    "batch_size = 128\n",
    "steps = math.ceil(train_set_size_no_valid / batch_size) \n",
    "print(steps)\n",
    "\n",
    "if 'softConfusionMatrix_train' not in locals() or len(softConfusionMatrix_train[0]) != epochs:\n",
    "    softConfusionMatrix_train = np.zeros((4, epochs, n_class, n_class))\n",
    "    confusionMatrix_train = np.zeros((4, epochs, n_class, n_class))\n",
    "    loss_train=np.zeros((4,epochs))\n",
    "    acc_train=np.zeros((4,epochs))\n",
    "    auc_train=np.zeros((4,epochs))\n",
    "    \n",
    "    softConfusionMatrix_valid = np.zeros((4, epochs, n_class, n_class))\n",
    "    loss_valid=np.zeros((4,epochs))\n",
    "    acc_valid=np.zeros((4,epochs))\n",
    "    auc_valid=np.zeros((4,epochs))\n",
    "\n",
    "model_weights = [] \n",
    "\n",
    "\n",
    "# Pretrain-------------------------------------------------------------------------\n",
    "tf.compat.v1.reset_default_graph()\n",
    "encoding_matrix = tf.Variable(tf.eye(10), trainable=False)\n",
    "trainGen = train_generator(epochs, batch_size, encoding_matrix)\n",
    "model.set_weights(initialWeights)\n",
    "optimizer = Optimizer(lr)\n",
    "model.compile(optimizer=optimizer, loss = loss_fn)\n",
    "\n",
    "metric_idx = 0\n",
    "trainMetrics = (softConfusionMatrix_train[metric_idx], \n",
    "                confusionMatrix_train[metric_idx],loss_train[metric_idx], \n",
    "                acc_train[metric_idx], auc_train[metric_idx])\n",
    "\n",
    "validMetrics = (softConfusionMatrix_valid[metric_idx], \n",
    "                loss_valid[metric_idx], acc_valid[metric_idx], auc_valid[metric_idx])\n",
    "\n",
    "adjust_lr = AdjustLR(\n",
    "      schedule = lr_schedule,\n",
    "      base_learning_rate = lr,\n",
    "  )\n",
    "\n",
    "uemgm = UpdateEncodingMatrixAndGetMetrics_Base(train_x_no_valid, train_y_no_valid,\n",
    "                                               valid_x, valid_y, trainMetrics, \n",
    "                                               validMetrics, 'Pretrain')\n",
    "                        \n",
    "_ = model.fit(trainGen, epochs = beginEncodingEpoch, verbose = 2,\n",
    "                steps_per_epoch = steps, callbacks=[uemgm,\n",
    "                                             adjust_lr,\n",
    "                                            ])\n",
    "\n",
    "pretrainedWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.016666668>\n",
      "97/97 - 5s - loss: 1.6352\n",
      "\n",
      "Test on train set: loss= 1.5480849742889404 acc= 0.5391712784767151 auc= 0.7429752770525881\n",
      "Test on valid set: loss= 2.8479833602905273 acc= 0.17504021525382996 auc= 0.6635555555555556\n",
      "\n",
      "Epoch 2/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.033333335>\n",
      "97/97 - 2s - loss: 1.1611\n",
      "\n",
      "Test on train set: loss= 1.042225956916809 acc= 0.6455972790718079 auc= 0.820745934369846\n",
      "Test on valid set: loss= 2.516974925994873 acc= 0.20882709324359894 auc= 0.7275555555555556\n",
      "\n",
      "Epoch 3/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.05>\n",
      "97/97 - 3s - loss: 0.9999\n",
      "\n",
      "Test on train set: loss= 0.9291788339614868 acc= 0.6818549633026123 auc= 0.8470196317633285\n",
      "Test on valid set: loss= 2.583472967147827 acc= 0.2364359200000763 auc= 0.7577777777777779\n",
      "\n",
      "Epoch 4/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.06666667>\n",
      "97/97 - 3s - loss: 0.9181\n",
      "\n",
      "Test on train set: loss= 0.9008182287216187 acc= 0.6867108941078186 auc= 0.8746087409051002\n",
      "Test on valid set: loss= 2.398249626159668 acc= 0.25417274236679077 auc= 0.7933333333333332\n",
      "\n",
      "Epoch 5/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.083333336>\n",
      "97/97 - 3s - loss: 0.8659\n",
      "\n",
      "Test on train set: loss= 0.8221979737281799 acc= 0.7206215858459473 auc= 0.8935731706045363\n",
      "Test on valid set: loss= 2.430481195449829 acc= 0.27058082818984985 auc= 0.8302222222222222\n",
      "\n",
      "Epoch 6/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.8166\n",
      "\n",
      "Test on train set: loss= 0.808388888835907 acc= 0.7214308977127075 auc= 0.9034237969857051\n",
      "Test on valid set: loss= 2.2946600914001465 acc= 0.2812255024909973 auc= 0.833777777777778\n",
      "\n",
      "Epoch 7/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 0.7510\n",
      "\n",
      "Test on train set: loss= 0.8319997787475586 acc= 0.7093719840049744 auc= 0.9084280982781742\n",
      "Test on valid set: loss= 2.125194787979126 acc= 0.3132172226905823 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 8/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.7097\n",
      "\n",
      "Test on train set: loss= 0.6854159832000732 acc= 0.7671576738357544 auc= 0.9247107683377138\n",
      "Test on valid set: loss= 2.024702787399292 acc= 0.35114672780036926 auc= 0.8835555555555554\n",
      "\n",
      "Epoch 9/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.6632\n",
      "\n",
      "Test on train set: loss= 0.6763747930526733 acc= 0.7749271392822266 auc= 0.9384119058947331\n",
      "Test on valid set: loss= 2.2140958309173584 acc= 0.3304900527000427 auc= 0.8875555555555558\n",
      "\n",
      "Epoch 10/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.6281\n",
      "\n",
      "Test on train set: loss= 0.6328192353248596 acc= 0.7821301221847534 auc= 0.9450569744119717\n",
      "Test on valid set: loss= 2.091005563735962 acc= 0.35339367389678955 auc= 0.8728888888888889\n",
      "\n",
      "Epoch 11/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.5943\n",
      "\n",
      "Test on train set: loss= 0.6217831969261169 acc= 0.78852379322052 auc= 0.9508195930800107\n",
      "Test on valid set: loss= 1.716599941253662 acc= 0.37349367141723633 auc= 0.9120000000000001\n",
      "\n",
      "Epoch 12/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.5781\n",
      "\n",
      "Test on train set: loss= 0.5387848019599915 acc= 0.815636157989502 auc= 0.9582498574186695\n",
      "Test on valid set: loss= 1.5225943326950073 acc= 0.4305357336997986 auc= 0.9333333333333333\n",
      "\n",
      "Epoch 13/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.5463\n",
      "\n",
      "Test on train set: loss= 0.603235125541687 acc= 0.7993687391281128 auc= 0.9560859717538429\n",
      "Test on valid set: loss= 1.9908392429351807 acc= 0.4070340692996979 auc= 0.9271111111111112\n",
      "\n",
      "Epoch 14/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.5284\n",
      "\n",
      "Test on train set: loss= 0.6668986082077026 acc= 0.780268669128418 auc= 0.9542107354746644\n",
      "Test on valid set: loss= 1.7952125072479248 acc= 0.4530135691165924 auc= 0.9142222222222223\n",
      "\n",
      "Epoch 15/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.5082\n",
      "\n",
      "Test on train set: loss= 0.5024431347846985 acc= 0.8272903561592102 auc= 0.96894158288358\n",
      "Test on valid set: loss= 1.652246356010437 acc= 0.4729103147983551 auc= 0.9297777777777778\n",
      "\n",
      "Epoch 16/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.4846\n",
      "\n",
      "Test on train set: loss= 0.473725825548172 acc= 0.8374069333076477 auc= 0.9716634202520431\n",
      "Test on valid set: loss= 1.6380605697631836 acc= 0.472470760345459 auc= 0.9293333333333333\n",
      "\n",
      "Epoch 17/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.4715\n",
      "\n",
      "Test on train set: loss= 0.418567419052124 acc= 0.8546454906463623 auc= 0.9771537776598164\n",
      "Test on valid set: loss= 1.3847976922988892 acc= 0.4752431809902191 auc= 0.9359999999999999\n",
      "\n",
      "Epoch 18/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.4544\n",
      "\n",
      "Test on train set: loss= 0.5878980755805969 acc= 0.7897377610206604 auc= 0.9690724703313155\n",
      "Test on valid set: loss= 1.7853480577468872 acc= 0.43388447165489197 auc= 0.923111111111111\n",
      "\n",
      "Epoch 19/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.4449\n",
      "\n",
      "Test on train set: loss= 0.46313872933387756 acc= 0.842100977897644 auc= 0.9740825731051714\n",
      "Test on valid set: loss= 1.9884872436523438 acc= 0.38976413011550903 auc= 0.9044444444444444\n",
      "\n",
      "Epoch 20/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.4147\n",
      "\n",
      "Test on train set: loss= 0.39105740189552307 acc= 0.8663806915283203 auc= 0.9806964747552369\n",
      "Test on valid set: loss= 1.460391879081726 acc= 0.5171977281570435 auc= 0.9342222222222223\n",
      "\n",
      "Epoch 21/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.4083\n",
      "\n",
      "Test on train set: loss= 0.3749028742313385 acc= 0.8718031644821167 auc= 0.9806296312650666\n",
      "Test on valid set: loss= 1.5212854146957397 acc= 0.5160855054855347 auc= 0.9306666666666666\n",
      "\n",
      "Epoch 22/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.3974\n",
      "\n",
      "Test on train set: loss= 0.4787684679031372 acc= 0.8374878764152527 auc= 0.9765146677968101\n",
      "Test on valid set: loss= 1.8035380840301514 acc= 0.5218155980110168 auc= 0.936888888888889\n",
      "\n",
      "Epoch 23/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.3799\n",
      "\n",
      "Test on train set: loss= 0.5116362571716309 acc= 0.8223535418510437 auc= 0.9798499903587056\n",
      "Test on valid set: loss= 1.473024845123291 acc= 0.5411385893821716 auc= 0.9542222222222223\n",
      "\n",
      "Epoch 24/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.3658\n",
      "\n",
      "Test on train set: loss= 0.4656016230583191 acc= 0.8444480299949646 auc= 0.9802830446108993\n",
      "Test on valid set: loss= 1.5816763639450073 acc= 0.5613751411437988 auc= 0.9324444444444445\n",
      "\n",
      "Epoch 25/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.3606\n",
      "\n",
      "Test on train set: loss= 0.3612084686756134 acc= 0.8730980753898621 auc= 0.9845199056332647\n",
      "Test on valid set: loss= 1.3876346349716187 acc= 0.545086145401001 auc= 0.9528888888888888\n",
      "\n",
      "Epoch 26/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 0.3409\n",
      "\n",
      "Test on train set: loss= 0.41810423135757446 acc= 0.8583683967590332 auc= 0.9838079079893542\n",
      "Test on valid set: loss= 1.5975641012191772 acc= 0.5540645718574524 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 27/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.3395\n",
      "\n",
      "Test on train set: loss= 0.3969964385032654 acc= 0.8586921095848083 auc= 0.9868471436572397\n",
      "Test on valid set: loss= 1.7812711000442505 acc= 0.474200963973999 auc= 0.9337777777777777\n",
      "\n",
      "Epoch 28/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.3197\n",
      "\n",
      "Test on train set: loss= 0.34380531311035156 acc= 0.884914219379425 auc= 0.9879662156527941\n",
      "Test on valid set: loss= 1.7566964626312256 acc= 0.5430023670196533 auc= 0.9528888888888888\n",
      "\n",
      "Epoch 29/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.3240\n",
      "\n",
      "Test on train set: loss= 0.29099318385124207 acc= 0.8967303037643433 auc= 0.9902931374861043\n",
      "Test on valid set: loss= 1.5119009017944336 acc= 0.5367259383201599 auc= 0.9408888888888889\n",
      "\n",
      "Epoch 30/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.3152\n",
      "\n",
      "Test on train set: loss= 0.3498668670654297 acc= 0.8743929862976074 auc= 0.989754261321516\n",
      "Test on valid set: loss= 1.4454394578933716 acc= 0.5398468375205994 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 31/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.2939\n",
      "\n",
      "Test on train set: loss= 0.31680577993392944 acc= 0.8910650610923767 auc= 0.9889059620499594\n",
      "Test on valid set: loss= 1.596825122833252 acc= 0.5342111587524414 auc= 0.9302222222222222\n",
      "\n",
      "Epoch 32/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2861\n",
      "\n",
      "Test on train set: loss= 0.3641809821128845 acc= 0.8758497834205627 auc= 0.9885456439706374\n",
      "Test on valid set: loss= 1.9641027450561523 acc= 0.48797059059143066 auc= 0.9333333333333332\n",
      "\n",
      "Epoch 33/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2788\n",
      "\n",
      "Test on train set: loss= 0.3021690249443054 acc= 0.8975396752357483 auc= 0.9893539800912059\n",
      "Test on valid set: loss= 1.317468523979187 acc= 0.6090458631515503 auc= 0.9555555555555555\n",
      "\n",
      "Epoch 34/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2685\n",
      "\n",
      "Test on train set: loss= 0.3884938955307007 acc= 0.8756070137023926 auc= 0.9896799374137949\n",
      "Test on valid set: loss= 2.0676968097686768 acc= 0.5147250890731812 auc= 0.9284444444444444\n",
      "\n",
      "Epoch 35/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2642\n",
      "\n",
      "Test on train set: loss= 0.4264238476753235 acc= 0.8585302829742432 auc= 0.9888644085626697\n",
      "Test on valid set: loss= 2.243483066558838 acc= 0.47703391313552856 auc= 0.9195555555555556\n",
      "\n",
      "Epoch 36/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2706\n",
      "\n",
      "Test on train set: loss= 0.33839818835258484 acc= 0.8799773454666138 auc= 0.9905379079138512\n",
      "Test on valid set: loss= 1.675978422164917 acc= 0.5419233441352844 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 37/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2567\n",
      "\n",
      "Test on train set: loss= 0.2813888490200043 acc= 0.9004532098770142 auc= 0.993231755601651\n",
      "Test on valid set: loss= 1.6548489332199097 acc= 0.5139687061309814 auc= 0.9426666666666668\n",
      "\n",
      "Epoch 38/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2384\n",
      "\n",
      "Test on train set: loss= 0.3135611116886139 acc= 0.8875849843025208 auc= 0.9930185555908464\n",
      "Test on valid set: loss= 1.5729161500930786 acc= 0.5799423456192017 auc= 0.939111111111111\n",
      "\n",
      "Epoch 39/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2386\n",
      "\n",
      "Test on train set: loss= 0.27478548884391785 acc= 0.9006150960922241 auc= 0.9939001065110501\n",
      "Test on valid set: loss= 1.6337298154830933 acc= 0.563106894493103 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 40/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2220\n",
      "\n",
      "Test on train set: loss= 0.2500455379486084 acc= 0.9105697870254517 auc= 0.993981583414706\n",
      "Test on valid set: loss= 1.664456844329834 acc= 0.5800068378448486 auc= 0.9426666666666668\n",
      "\n",
      "Epoch 41/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.2294\n",
      "\n",
      "Test on train set: loss= 0.2766059637069702 acc= 0.9012625217437744 auc= 0.9940477572366296\n",
      "Test on valid set: loss= 1.6031091213226318 acc= 0.6036425232887268 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 42/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2250\n",
      "\n",
      "Test on train set: loss= 0.2401578724384308 acc= 0.9203625917434692 auc= 0.9942801402841486\n",
      "Test on valid set: loss= 1.4691566228866577 acc= 0.5928497910499573 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 43/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.2184\n",
      "\n",
      "Test on train set: loss= 0.211459219455719 acc= 0.9252185225486755 auc= 0.9961368870092528\n",
      "Test on valid set: loss= 2.0049796104431152 acc= 0.5484342575073242 auc= 0.9422222222222223\n",
      "\n",
      "Epoch 44/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.2004\n",
      "\n",
      "Test on train set: loss= 0.23207683861255646 acc= 0.9168015718460083 auc= 0.994779943103201\n",
      "Test on valid set: loss= 1.8559997081756592 acc= 0.5395311117172241 auc= 0.9364444444444444\n",
      "\n",
      "Epoch 45/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.2128\n",
      "\n",
      "Test on train set: loss= 0.26992863416671753 acc= 0.9049044847488403 auc= 0.995162830652635\n",
      "Test on valid set: loss= 1.5894829034805298 acc= 0.629633367061615 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 46/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.1982\n",
      "\n",
      "Test on train set: loss= 0.2859630882740021 acc= 0.9024765491485596 auc= 0.9957487203057038\n",
      "Test on valid set: loss= 1.7434701919555664 acc= 0.6103624105453491 auc= 0.9351111111111111\n",
      "\n",
      "Epoch 47/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1925\n",
      "\n",
      "Test on train set: loss= 0.25545477867126465 acc= 0.9142926335334778 auc= 0.9950963616159342\n",
      "Test on valid set: loss= 1.4996185302734375 acc= 0.6134697198867798 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 48/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1907\n",
      "\n",
      "Test on train set: loss= 0.15706554055213928 acc= 0.9453706741333008 auc= 0.9974661649024151\n",
      "Test on valid set: loss= 1.3116950988769531 acc= 0.6331814527511597 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 49/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1857\n",
      "\n",
      "Test on train set: loss= 0.16513200104236603 acc= 0.9393007159233093 auc= 0.9975325518847293\n",
      "Test on valid set: loss= 1.539689302444458 acc= 0.6493059992790222 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 50/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1803\n",
      "\n",
      "Test on train set: loss= 0.4193662703037262 acc= 0.8648430109024048 auc= 0.9928884632351144\n",
      "Test on valid set: loss= 1.781412959098816 acc= 0.5586540699005127 auc= 0.9351111111111111\n",
      "\n",
      "Epoch 51/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1695\n",
      "\n",
      "Test on train set: loss= 0.2358086258172989 acc= 0.9178536534309387 auc= 0.9952844481420206\n",
      "Test on valid set: loss= 2.1049399375915527 acc= 0.5186381340026855 auc= 0.9440000000000002\n",
      "\n",
      "Epoch 52/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1723\n",
      "\n",
      "Test on train set: loss= 0.15279977023601532 acc= 0.9457753300666809 auc= 0.997696620053549\n",
      "Test on valid set: loss= 1.468164324760437 acc= 0.6549030542373657 auc= 0.9426666666666665\n",
      "\n",
      "Epoch 53/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1606\n",
      "\n",
      "Test on train set: loss= 0.14955420792102814 acc= 0.9446423053741455 auc= 0.9980002062804744\n",
      "Test on valid set: loss= 1.7922406196594238 acc= 0.5878881216049194 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 54/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1623\n",
      "\n",
      "Test on train set: loss= 0.1788269281387329 acc= 0.9370346665382385 auc= 0.9975205576566779\n",
      "Test on valid set: loss= 1.6075773239135742 acc= 0.6135305166244507 auc= 0.9524444444444443\n",
      "\n",
      "Epoch 55/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1613\n",
      "\n",
      "Test on train set: loss= 0.3251395523548126 acc= 0.8897701501846313 auc= 0.9939402431895067\n",
      "Test on valid set: loss= 1.8661502599716187 acc= 0.5774673819541931 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 56/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1666\n",
      "\n",
      "Test on train set: loss= 0.1742696315050125 acc= 0.9376820921897888 auc= 0.9976118300804379\n",
      "Test on valid set: loss= 1.5789368152618408 acc= 0.5922779440879822 auc= 0.9400000000000001\n",
      "\n",
      "Epoch 57/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1486\n",
      "\n",
      "Test on train set: loss= 0.19201932847499847 acc= 0.9326642751693726 auc= 0.9975617762799172\n",
      "Test on valid set: loss= 1.650240421295166 acc= 0.6318531632423401 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 58/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1487\n",
      "\n",
      "Test on train set: loss= 0.1833515465259552 acc= 0.9338783025741577 auc= 0.9975990504965525\n",
      "Test on valid set: loss= 2.201956272125244 acc= 0.5787875056266785 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 59/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1474\n",
      "\n",
      "Test on train set: loss= 0.15925082564353943 acc= 0.9437520503997803 auc= 0.9980274191451354\n",
      "Test on valid set: loss= 2.116992473602295 acc= 0.5645692944526672 auc= 0.9422222222222223\n",
      "\n",
      "Epoch 60/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1448\n",
      "\n",
      "Test on train set: loss= 0.1528255045413971 acc= 0.9444804191589355 auc= 0.9984045885428777\n",
      "Test on valid set: loss= 1.5067065954208374 acc= 0.6501673460006714 auc= 0.9573333333333334\n",
      "\n",
      "Epoch 61/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1407\n",
      "\n",
      "Test on train set: loss= 0.18397602438926697 acc= 0.9342020153999329 auc= 0.9978520481775849\n",
      "Test on valid set: loss= 1.9735103845596313 acc= 0.5360839366912842 auc= 0.9391111111111112\n",
      "\n",
      "Epoch 62/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1321\n",
      "\n",
      "Test on train set: loss= 0.17404671013355255 acc= 0.9359015822410583 auc= 0.998155881924913\n",
      "Test on valid set: loss= 1.56398344039917 acc= 0.6418682336807251 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 63/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1311\n",
      "\n",
      "Test on train set: loss= 0.15178708732128143 acc= 0.9465036988258362 auc= 0.9983370106972916\n",
      "Test on valid set: loss= 2.135636329650879 acc= 0.5675438046455383 auc= 0.9377777777777778\n",
      "\n",
      "Epoch 64/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1233\n",
      "\n",
      "Test on train set: loss= 0.14211471378803253 acc= 0.9500647187232971 auc= 0.9983209172188025\n",
      "Test on valid set: loss= 1.9445981979370117 acc= 0.5732346177101135 auc= 0.9400000000000001\n",
      "\n",
      "Epoch 65/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1167\n",
      "\n",
      "Test on train set: loss= 0.11244082450866699 acc= 0.961395263671875 auc= 0.9988541976001292\n",
      "Test on valid set: loss= 1.7956477403640747 acc= 0.5748556852340698 auc= 0.9386666666666666\n",
      "\n",
      "Epoch 66/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1220\n",
      "\n",
      "Test on train set: loss= 0.15744225680828094 acc= 0.946099042892456 auc= 0.9981407694153226\n",
      "Test on valid set: loss= 1.6087353229522705 acc= 0.6265187859535217 auc= 0.9466666666666665\n",
      "\n",
      "Epoch 67/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1235\n",
      "\n",
      "Test on train set: loss= 0.12009944766759872 acc= 0.9574295878410339 auc= 0.9988303579045379\n",
      "Test on valid set: loss= 1.6223843097686768 acc= 0.6659945845603943 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 68/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1233\n",
      "\n",
      "Test on train set: loss= 0.17638692259788513 acc= 0.9397863149642944 auc= 0.9980006137987095\n",
      "Test on valid set: loss= 2.1710259914398193 acc= 0.6002815961837769 auc= 0.9315555555555555\n",
      "\n",
      "Epoch 69/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1123\n",
      "\n",
      "Test on train set: loss= 0.11846603453159332 acc= 0.9566202759742737 auc= 0.9989845046660148\n",
      "Test on valid set: loss= 1.9528597593307495 acc= 0.6263115406036377 auc= 0.9568888888888889\n",
      "\n",
      "Epoch 70/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1193\n",
      "\n",
      "Test on train set: loss= 0.13197657465934753 acc= 0.9527354836463928 auc= 0.9987779039661631\n",
      "Test on valid set: loss= 1.5840203762054443 acc= 0.632207989692688 auc= 0.9466666666666665\n",
      "\n",
      "Epoch 71/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1108\n",
      "\n",
      "Test on train set: loss= 0.09913928061723709 acc= 0.9665749669075012 auc= 0.9989782606677478\n",
      "Test on valid set: loss= 1.9839413166046143 acc= 0.6094771027565002 auc= 0.9413333333333334\n",
      "\n",
      "Epoch 72/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0957\n",
      "\n",
      "Test on train set: loss= 0.11336392164230347 acc= 0.9607478380203247 auc= 0.9991193042621456\n",
      "Test on valid set: loss= 1.9120885133743286 acc= 0.6343348622322083 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 73/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1088\n",
      "\n",
      "Test on train set: loss= 0.10620924085378647 acc= 0.9627711176872253 auc= 0.998873505486371\n",
      "Test on valid set: loss= 1.69511079788208 acc= 0.5937210321426392 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 74/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1128\n",
      "\n",
      "Test on train set: loss= 0.11852993816137314 acc= 0.9568630456924438 auc= 0.999091051227546\n",
      "Test on valid set: loss= 1.7944862842559814 acc= 0.5902724266052246 auc= 0.9359999999999999\n",
      "\n",
      "Epoch 75/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1106\n",
      "\n",
      "Test on train set: loss= 0.11777090281248093 acc= 0.9570249319076538 auc= 0.9989790206038046\n",
      "Test on valid set: loss= 2.3414978981018066 acc= 0.5415012240409851 auc= 0.9373333333333334\n",
      "\n",
      "Epoch 76/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0990\n",
      "\n",
      "Test on train set: loss= 0.09531378746032715 acc= 0.9638232588768005 auc= 0.9993134787445241\n",
      "Test on valid set: loss= 1.959325909614563 acc= 0.6237027049064636 auc= 0.9475555555555557\n",
      "\n",
      "Epoch 77/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0866\n",
      "\n",
      "Test on train set: loss= 0.11420340836048126 acc= 0.9582388997077942 auc= 0.9993322280873767\n",
      "Test on valid set: loss= 2.096266269683838 acc= 0.5607140064239502 auc= 0.9355555555555556\n",
      "\n",
      "Epoch 78/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0976\n",
      "\n",
      "Test on train set: loss= 0.11600670963525772 acc= 0.9583198428153992 auc= 0.9989083814085215\n",
      "Test on valid set: loss= 1.9308438301086426 acc= 0.633440375328064 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 79/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0909\n",
      "\n",
      "Test on train set: loss= 0.13947704434394836 acc= 0.9511978030204773 auc= 0.99902973410684\n",
      "Test on valid set: loss= 1.8901327848434448 acc= 0.6442247033119202 auc= 0.9444444444444446\n",
      "\n",
      "Epoch 80/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.1001\n",
      "\n",
      "Test on train set: loss= 0.0904575064778328 acc= 0.969083845615387 auc= 0.9993850415807902\n",
      "Test on valid set: loss= 1.4678778648376465 acc= 0.6652640104293823 auc= 0.952\n",
      "\n",
      "Epoch 81/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0968\n",
      "\n",
      "Test on train set: loss= 0.09081912785768509 acc= 0.9662511944770813 auc= 0.999353790251487\n",
      "Test on valid set: loss= 1.4558552503585815 acc= 0.6709955334663391 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 82/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0847\n",
      "\n",
      "Test on train set: loss= 0.06350018829107285 acc= 0.9785529375076294 auc= 0.9996342963372822\n",
      "Test on valid set: loss= 1.7636959552764893 acc= 0.6224187612533569 auc= 0.960888888888889\n",
      "\n",
      "Epoch 83/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0815\n",
      "\n",
      "Test on train set: loss= 0.0615350641310215 acc= 0.977177083492279 auc= 0.9996600401945994\n",
      "Test on valid set: loss= 1.9593368768692017 acc= 0.6000262498855591 auc= 0.952\n",
      "\n",
      "Epoch 84/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0802\n",
      "\n",
      "Test on train set: loss= 0.08511064201593399 acc= 0.9703787565231323 auc= 0.9994258615000271\n",
      "Test on valid set: loss= 2.0316641330718994 acc= 0.5945624113082886 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 85/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0775\n",
      "\n",
      "Test on train set: loss= 0.0866839736700058 acc= 0.969083845615387 auc= 0.9994391326522086\n",
      "Test on valid set: loss= 1.972609043121338 acc= 0.5760461688041687 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 86/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0767\n",
      "\n",
      "Test on train set: loss= 0.07161308079957962 acc= 0.9734541773796082 auc= 0.9995535359934735\n",
      "Test on valid set: loss= 2.0061697959899902 acc= 0.6246985197067261 auc= 0.9560000000000001\n",
      "\n",
      "Epoch 87/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0781\n",
      "\n",
      "Test on train set: loss= 0.1677437126636505 acc= 0.9448041319847107 auc= 0.9987450880136113\n",
      "Test on valid set: loss= 1.999756932258606 acc= 0.6578326225280762 auc= 0.9417777777777779\n",
      "\n",
      "Epoch 88/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0820\n",
      "\n",
      "Test on train set: loss= 0.10850034654140472 acc= 0.96147620677948 auc= 0.9992024952673221\n",
      "Test on valid set: loss= 2.513345718383789 acc= 0.6030569076538086 auc= 0.9351111111111112\n",
      "\n",
      "Epoch 89/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0740\n",
      "\n",
      "Test on train set: loss= 0.13026489317417145 acc= 0.9545160531997681 auc= 0.9989312581683663\n",
      "Test on valid set: loss= 2.1889126300811768 acc= 0.623879611492157 auc= 0.9431111111111111\n",
      "\n",
      "Epoch 90/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0776\n",
      "\n",
      "Test on train set: loss= 0.11099904030561447 acc= 0.9595338106155396 auc= 0.999289253006222\n",
      "Test on valid set: loss= 2.3354134559631348 acc= 0.6458268761634827 auc= 0.9568888888888891\n",
      "\n",
      "Epoch 91/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0801\n",
      "\n",
      "Test on train set: loss= 0.07456916570663452 acc= 0.973292350769043 auc= 0.9994897608759199\n",
      "Test on valid set: loss= 1.7875334024429321 acc= 0.6582578420639038 auc= 0.9555555555555555\n",
      "\n",
      "Epoch 92/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0680\n",
      "\n",
      "Test on train set: loss= 0.07517401874065399 acc= 0.973049521446228 auc= 0.9996070155206154\n",
      "Test on valid set: loss= 2.123840093612671 acc= 0.6454688906669617 auc= 0.944\n",
      "\n",
      "Epoch 93/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0661\n",
      "\n",
      "Test on train set: loss= 0.09974595159292221 acc= 0.965522825717926 auc= 0.9995014129790732\n",
      "Test on valid set: loss= 1.7356895208358765 acc= 0.6429566144943237 auc= 0.9591111111111111\n",
      "\n",
      "Epoch 94/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0721\n",
      "\n",
      "Test on train set: loss= 0.07920276373624802 acc= 0.9721592664718628 auc= 0.9995442096989094\n",
      "Test on valid set: loss= 2.4212427139282227 acc= 0.62205970287323 auc= 0.9457777777777778\n",
      "\n",
      "Epoch 95/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0718\n",
      "\n",
      "Test on train set: loss= 0.08764543384313583 acc= 0.9705406427383423 auc= 0.9995607509736943\n",
      "Test on valid set: loss= 2.579341411590576 acc= 0.5687543749809265 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 96/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0597\n",
      "\n",
      "Test on train set: loss= 0.04537489265203476 acc= 0.9842991232872009 auc= 0.9998466747553015\n",
      "Test on valid set: loss= 1.9932153224945068 acc= 0.6120022535324097 auc= 0.9520000000000002\n",
      "\n",
      "Epoch 97/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0633\n",
      "\n",
      "Test on train set: loss= 0.09975343942642212 acc= 0.9645516276359558 auc= 0.9993972674439915\n",
      "Test on valid set: loss= 2.736067533493042 acc= 0.5843761563301086 auc= 0.9182222222222223\n",
      "\n",
      "Epoch 98/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0691\n",
      "\n",
      "Test on train set: loss= 0.054906148463487625 acc= 0.9815474152565002 auc= 0.9997184954661835\n",
      "Test on valid set: loss= 1.747647762298584 acc= 0.6161317825317383 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 99/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0622\n",
      "\n",
      "Test on train set: loss= 0.0727357417345047 acc= 0.973130464553833 auc= 0.9996851939663575\n",
      "Test on valid set: loss= 2.368896961212158 acc= 0.6158496141433716 auc= 0.9426666666666668\n",
      "\n",
      "Epoch 100/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0650\n",
      "\n",
      "Test on train set: loss= 0.0465925857424736 acc= 0.9851893782615662 auc= 0.9997989770830594\n",
      "Test on valid set: loss= 2.100325584411621 acc= 0.6073169112205505 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 101/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0566\n",
      "\n",
      "Test on train set: loss= 0.08447041362524033 acc= 0.9698122143745422 auc= 0.9996717480357258\n",
      "Test on valid set: loss= 1.907232642173767 acc= 0.6902161836624146 auc= 0.9479999999999998\n",
      "\n",
      "Epoch 102/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0622\n",
      "\n",
      "Test on train set: loss= 0.059551335871219635 acc= 0.9787148237228394 auc= 0.999770301600553\n",
      "Test on valid set: loss= 1.573588252067566 acc= 0.7073684930801392 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 103/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0579\n",
      "\n",
      "Test on train set: loss= 0.06081433966755867 acc= 0.9779054522514343 auc= 0.9997053003986605\n",
      "Test on valid set: loss= 2.618382453918457 acc= 0.6201888918876648 auc= 0.9204444444444444\n",
      "\n",
      "Epoch 104/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0626\n",
      "\n",
      "Test on train set: loss= 0.06145152822136879 acc= 0.9775817394256592 auc= 0.9996953508476857\n",
      "Test on valid set: loss= 1.8360601663589478 acc= 0.6938073635101318 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 105/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0581\n",
      "\n",
      "Test on train set: loss= 0.06692225486040115 acc= 0.9752346873283386 auc= 0.9997456238301773\n",
      "Test on valid set: loss= 2.0482962131500244 acc= 0.6457170844078064 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 106/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0653\n",
      "\n",
      "Test on train set: loss= 0.05976580083370209 acc= 0.9809808731079102 auc= 0.9996592910911918\n",
      "Test on valid set: loss= 1.7567505836486816 acc= 0.6844847202301025 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 107/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0601\n",
      "\n",
      "Test on train set: loss= 0.0560704842209816 acc= 0.9810618162155151 auc= 0.9996717871755834\n",
      "Test on valid set: loss= 2.372241258621216 acc= 0.5929412841796875 auc= 0.9324444444444444\n",
      "\n",
      "Epoch 108/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0573\n",
      "\n",
      "Test on train set: loss= 0.0562458261847496 acc= 0.9796859622001648 auc= 0.9997798093547402\n",
      "Test on valid set: loss= 1.5041943788528442 acc= 0.6566177606582642 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 109/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 0.0501\n",
      "\n",
      "Test on train set: loss= 0.03772394359111786 acc= 0.9863224625587463 auc= 0.9999013956848561\n",
      "Test on valid set: loss= 1.923274278640747 acc= 0.6047860383987427 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 110/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.0584\n",
      "\n",
      "Test on train set: loss= 0.05622008815407753 acc= 0.98089998960495 auc= 0.9997667158358123\n",
      "Test on valid set: loss= 2.372498035430908 acc= 0.5819162130355835 auc= 0.9395555555555555\n",
      "\n",
      "Epoch 111/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0464\n",
      "\n",
      "Test on train set: loss= 0.059297576546669006 acc= 0.9783910512924194 auc= 0.9997738176191389\n",
      "Test on valid set: loss= 1.868839979171753 acc= 0.620005190372467 auc= 0.9431111111111111\n",
      "\n",
      "Epoch 112/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.0473\n",
      "\n",
      "Test on train set: loss= 0.04003041610121727 acc= 0.9871317744255066 auc= 0.9998767272469415\n",
      "Test on valid set: loss= 1.7374340295791626 acc= 0.6867409944534302 auc= 0.9493333333333333\n",
      "\n",
      "Epoch 113/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0488\n",
      "\n",
      "Test on train set: loss= 0.03568528592586517 acc= 0.9886694550514221 auc= 0.9998875389835454\n",
      "Test on valid set: loss= 1.9055169820785522 acc= 0.6355667114257812 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 114/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0527\n",
      "\n",
      "Test on train set: loss= 0.03543791174888611 acc= 0.988426685333252 auc= 0.999896532779605\n",
      "Test on valid set: loss= 1.6469262838363647 acc= 0.7296723127365112 auc= 0.9528888888888888\n",
      "\n",
      "Epoch 115/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0453\n",
      "\n",
      "Test on train set: loss= 0.03780889883637428 acc= 0.9870508313179016 auc= 0.9998479156663681\n",
      "Test on valid set: loss= 1.9498226642608643 acc= 0.6687605381011963 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 116/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0493\n",
      "\n",
      "Test on train set: loss= 0.09086813032627106 acc= 0.9682745337486267 auc= 0.9994615872338135\n",
      "Test on valid set: loss= 2.339261054992676 acc= 0.6349829435348511 auc= 0.9328888888888889\n",
      "\n",
      "Epoch 117/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0493\n",
      "\n",
      "Test on train set: loss= 0.03361772373318672 acc= 0.988993227481842 auc= 0.9998938709169846\n",
      "Test on valid set: loss= 1.8426148891448975 acc= 0.6708676815032959 auc= 0.9591111111111111\n",
      "\n",
      "Epoch 118/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0402\n",
      "\n",
      "Test on train set: loss= 0.028769535943865776 acc= 0.9893169403076172 auc= 0.9999208464020517\n",
      "Test on valid set: loss= 1.7329907417297363 acc= 0.6867263317108154 auc= 0.9560000000000001\n",
      "\n",
      "Epoch 119/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0433\n",
      "\n",
      "Test on train set: loss= 0.04099982604384422 acc= 0.9852703213691711 auc= 0.9998879900992085\n",
      "Test on valid set: loss= 2.0305848121643066 acc= 0.6528613567352295 auc= 0.9542222222222222\n",
      "\n",
      "Epoch 120/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0422\n",
      "\n",
      "Test on train set: loss= 0.04186473414301872 acc= 0.9851893782615662 auc= 0.9998635715176929\n",
      "Test on valid set: loss= 2.521008253097534 acc= 0.6230577230453491 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 121/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0405\n",
      "\n",
      "Test on train set: loss= 0.04748830944299698 acc= 0.9812237024307251 auc= 0.9998552902450056\n",
      "Test on valid set: loss= 2.2336533069610596 acc= 0.6564525365829468 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 122/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0441\n",
      "\n",
      "Test on train set: loss= 0.03080892190337181 acc= 0.9887503981590271 auc= 0.999928835478903\n",
      "Test on valid set: loss= 2.37758207321167 acc= 0.6112853288650513 auc= 0.9417777777777779\n",
      "\n",
      "Epoch 123/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0453\n",
      "\n",
      "Test on train set: loss= 0.03983110934495926 acc= 0.984784722328186 auc= 0.9998968228529588\n",
      "Test on valid set: loss= 2.405790328979492 acc= 0.6094158887863159 auc= 0.9302222222222223\n",
      "\n",
      "Epoch 124/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0525\n",
      "\n",
      "Test on train set: loss= 0.0456056222319603 acc= 0.9843800663948059 auc= 0.9997750905109916\n",
      "Test on valid set: loss= 1.9206184148788452 acc= 0.6661660075187683 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 125/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0520\n",
      "\n",
      "Test on train set: loss= 0.07776360213756561 acc= 0.9705406427383423 auc= 0.9997509139875327\n",
      "Test on valid set: loss= 2.2921364307403564 acc= 0.6161521673202515 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 126/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0403\n",
      "\n",
      "Test on train set: loss= 0.02770673856139183 acc= 0.9908546209335327 auc= 0.9999407175324713\n",
      "Test on valid set: loss= 1.9996418952941895 acc= 0.621292769908905 auc= 0.9444444444444446\n",
      "\n",
      "Epoch 127/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0427\n",
      "\n",
      "Test on train set: loss= 0.025721289217472076 acc= 0.9919877052307129 auc= 0.9999378685129912\n",
      "Test on valid set: loss= 2.363722801208496 acc= 0.637791633605957 auc= 0.9413333333333334\n",
      "\n",
      "Epoch 128/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0366\n",
      "\n",
      "Test on train set: loss= 0.0333029143512249 acc= 0.9888313412666321 auc= 0.999919409403466\n",
      "Test on valid set: loss= 2.3456618785858154 acc= 0.6121970415115356 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 129/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0369\n",
      "\n",
      "Test on train set: loss= 0.02216610126197338 acc= 0.9931207299232483 auc= 0.9999545209744941\n",
      "Test on valid set: loss= 2.3531384468078613 acc= 0.604415237903595 auc= 0.936888888888889\n",
      "\n",
      "Epoch 130/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0378\n",
      "\n",
      "Test on train set: loss= 0.04497712478041649 acc= 0.9838944673538208 auc= 0.9998932083789194\n",
      "Test on valid set: loss= 1.89597487449646 acc= 0.6781982779502869 auc= 0.9493333333333333\n",
      "\n",
      "Epoch 131/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0495\n",
      "\n",
      "Test on train set: loss= 0.051303308457136154 acc= 0.9821949005126953 auc= 0.9997717839713104\n",
      "Test on valid set: loss= 1.9023351669311523 acc= 0.6728845834732056 auc= 0.955111111111111\n",
      "\n",
      "Epoch 132/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0383\n",
      "\n",
      "Test on train set: loss= 0.026035645976662636 acc= 0.9911783933639526 auc= 0.9999511905175995\n",
      "Test on valid set: loss= 1.7658569812774658 acc= 0.6645769476890564 auc= 0.9497777777777779\n",
      "\n",
      "Epoch 133/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0294\n",
      "\n",
      "Test on train set: loss= 0.02255251072347164 acc= 0.9916639924049377 auc= 0.9999509746500038\n",
      "Test on valid set: loss= 2.3660659790039062 acc= 0.6452392339706421 auc= 0.9448888888888888\n",
      "\n",
      "Epoch 134/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0284\n",
      "\n",
      "Test on train set: loss= 0.025108547881245613 acc= 0.9919067621231079 auc= 0.9999454588545434\n",
      "Test on valid set: loss= 2.1356728076934814 acc= 0.6196655631065369 auc= 0.9404444444444444\n",
      "\n",
      "Epoch 135/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0339\n",
      "\n",
      "Test on train set: loss= 0.039542071521282196 acc= 0.9851084351539612 auc= 0.9998823081361445\n",
      "Test on valid set: loss= 2.2335729598999023 acc= 0.6236647367477417 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 136/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0365\n",
      "\n",
      "Test on train set: loss= 0.03620784729719162 acc= 0.9877792000770569 auc= 0.9998902606243913\n",
      "Test on valid set: loss= 2.1528027057647705 acc= 0.6225012540817261 auc= 0.952\n",
      "\n",
      "Epoch 137/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0333\n",
      "\n",
      "Test on train set: loss= 0.03316621109843254 acc= 0.9891550540924072 auc= 0.999908347278685\n",
      "Test on valid set: loss= 2.069718360900879 acc= 0.664275586605072 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 138/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0339\n",
      "\n",
      "Test on train set: loss= 0.026508469134569168 acc= 0.9902881383895874 auc= 0.9999404677923197\n",
      "Test on valid set: loss= 2.1000468730926514 acc= 0.6563426852226257 auc= 0.9515555555555556\n",
      "\n",
      "Epoch 139/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0397\n",
      "\n",
      "Test on train set: loss= 0.07656706869602203 acc= 0.973211407661438 auc= 0.9996607538662559\n",
      "Test on valid set: loss= 2.230043411254883 acc= 0.6731744408607483 auc= 0.9497777777777779\n",
      "\n",
      "Epoch 140/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0387\n",
      "\n",
      "Test on train set: loss= 0.032205548137426376 acc= 0.9891550540924072 auc= 0.9999264279660185\n",
      "Test on valid set: loss= 1.8621634244918823 acc= 0.7176491022109985 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 141/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0306\n",
      "\n",
      "Test on train set: loss= 0.040285706520080566 acc= 0.9855940341949463 auc= 0.9998736445443696\n",
      "Test on valid set: loss= 2.2121546268463135 acc= 0.6085304617881775 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 142/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0291\n",
      "\n",
      "Test on train set: loss= 0.04160008206963539 acc= 0.9859177470207214 auc= 0.9999000523424234\n",
      "Test on valid set: loss= 1.466036319732666 acc= 0.7589464783668518 auc= 0.9622222222222222\n",
      "\n",
      "Epoch 143/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0289\n",
      "\n",
      "Test on train set: loss= 0.03908747434616089 acc= 0.9861605763435364 auc= 0.9999041274297614\n",
      "Test on valid set: loss= 1.857527732849121 acc= 0.678469181060791 auc= 0.9582222222222221\n",
      "\n",
      "Epoch 144/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0321\n",
      "\n",
      "Test on train set: loss= 0.045363131910562515 acc= 0.9845419526100159 auc= 0.9998573784755337\n",
      "Test on valid set: loss= 2.5205774307250977 acc= 0.6351456642150879 auc= 0.9373333333333334\n",
      "\n",
      "Epoch 145/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0297\n",
      "\n",
      "Test on train set: loss= 0.04015467315912247 acc= 0.9858368635177612 auc= 0.9998686248532103\n",
      "Test on valid set: loss= 2.1306052207946777 acc= 0.6762033700942993 auc= 0.9568888888888889\n",
      "\n",
      "Epoch 146/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0308\n",
      "\n",
      "Test on train set: loss= 0.04058101028203964 acc= 0.9853512644767761 auc= 0.9998944849960079\n",
      "Test on valid set: loss= 2.0284132957458496 acc= 0.6261426210403442 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 147/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0335\n",
      "\n",
      "Test on train set: loss= 0.022119801491498947 acc= 0.992554247379303 auc= 0.9999613883428863\n",
      "Test on valid set: loss= 1.860396385192871 acc= 0.6874894499778748 auc= 0.9671111111111111\n",
      "\n",
      "Epoch 148/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0303\n",
      "\n",
      "Test on train set: loss= 0.03030509687960148 acc= 0.9888313412666321 auc= 0.9999510088233861\n",
      "Test on valid set: loss= 2.1226110458374023 acc= 0.6503454446792603 auc= 0.9533333333333334\n",
      "\n",
      "Epoch 149/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0255\n",
      "\n",
      "Test on train set: loss= 0.026208646595478058 acc= 0.9912593364715576 auc= 0.9999300536723268\n",
      "Test on valid set: loss= 2.1780285835266113 acc= 0.6454540491104126 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 150/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0276\n",
      "\n",
      "Test on train set: loss= 0.01925141178071499 acc= 0.9933635592460632 auc= 0.9999768923463792\n",
      "Test on valid set: loss= 2.3174550533294678 acc= 0.6155785322189331 auc= 0.9444444444444443\n",
      "\n",
      "Epoch 151/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0245\n",
      "\n",
      "Test on train set: loss= 0.019723698496818542 acc= 0.9929589033126831 auc= 0.999948380538204\n",
      "Test on valid set: loss= 2.0584781169891357 acc= 0.6593266725540161 auc= 0.9551111111111112\n",
      "\n",
      "Epoch 152/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0238\n",
      "\n",
      "Test on train set: loss= 0.019470106810331345 acc= 0.9940109848976135 auc= 0.999981440880015\n",
      "Test on valid set: loss= 2.0735080242156982 acc= 0.6829525232315063 auc= 0.9573333333333333\n",
      "\n",
      "Epoch 153/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0330\n",
      "\n",
      "Test on train set: loss= 0.0202957633882761 acc= 0.9931207299232483 auc= 0.9999577247884229\n",
      "Test on valid set: loss= 1.8973078727722168 acc= 0.6842441558837891 auc= 0.9533333333333334\n",
      "\n",
      "Epoch 154/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0317\n",
      "\n",
      "Test on train set: loss= 0.020834896713495255 acc= 0.9927160739898682 auc= 0.999956687814781\n",
      "Test on valid set: loss= 1.7896335124969482 acc= 0.6574546694755554 auc= 0.9568888888888889\n",
      "\n",
      "Epoch 155/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0282\n",
      "\n",
      "Test on train set: loss= 0.020969195291399956 acc= 0.9921495914459229 auc= 0.9999585430673962\n",
      "Test on valid set: loss= 1.8220295906066895 acc= 0.6632446050643921 auc= 0.9564444444444444\n",
      "\n",
      "Epoch 156/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0292\n",
      "\n",
      "Test on train set: loss= 0.017498886212706566 acc= 0.9944156408309937 auc= 0.9999768293412685\n",
      "Test on valid set: loss= 2.0750625133514404 acc= 0.6657772660255432 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 157/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0318\n",
      "\n",
      "Test on train set: loss= 0.020778751000761986 acc= 0.9937682151794434 auc= 0.9999644882466756\n",
      "Test on valid set: loss= 2.2567107677459717 acc= 0.6443378925323486 auc= 0.9408888888888889\n",
      "\n",
      "Epoch 158/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0312\n",
      "\n",
      "Test on train set: loss= 0.015228092670440674 acc= 0.9956296682357788 auc= 0.9999822710555378\n",
      "Test on valid set: loss= 2.097165584564209 acc= 0.6439205408096313 auc= 0.9475555555555554\n",
      "\n",
      "Epoch 159/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0232\n",
      "\n",
      "Test on train set: loss= 0.01914437860250473 acc= 0.9936872720718384 auc= 0.9999717770607441\n",
      "Test on valid set: loss= 2.1737143993377686 acc= 0.6783848404884338 auc= 0.9395555555555555\n",
      "\n",
      "Epoch 160/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0203\n",
      "\n",
      "Test on train set: loss= 0.032740216702222824 acc= 0.9885076284408569 auc= 0.9999129695880274\n",
      "Test on valid set: loss= 2.0004665851593018 acc= 0.6560126543045044 auc= 0.9546666666666667\n",
      "\n",
      "Epoch 161/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0288\n",
      "\n",
      "Test on train set: loss= 0.02515908144414425 acc= 0.9906118512153625 auc= 0.9999443007768809\n",
      "Test on valid set: loss= 2.1502881050109863 acc= 0.643523633480072 auc= 0.9382222222222222\n",
      "\n",
      "Epoch 162/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0298\n",
      "\n",
      "Test on train set: loss= 0.029030846431851387 acc= 0.988426685333252 auc= 0.9999464962004192\n",
      "Test on valid set: loss= 2.475642204284668 acc= 0.6456059813499451 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 163/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0309\n",
      "\n",
      "Test on train set: loss= 0.025286663323640823 acc= 0.9927160739898682 auc= 0.9999303644229848\n",
      "Test on valid set: loss= 2.1198699474334717 acc= 0.7045021653175354 auc= 0.9537777777777778\n",
      "\n",
      "Epoch 164/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0274\n",
      "\n",
      "Test on train set: loss= 0.01968560367822647 acc= 0.9933635592460632 auc= 0.9999614655899103\n",
      "Test on valid set: loss= 2.2783823013305664 acc= 0.6758872866630554 auc= 0.9511111111111112\n",
      "\n",
      "Epoch 165/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0171\n",
      "\n",
      "Test on train set: loss= 0.015446470119059086 acc= 0.9953868389129639 auc= 0.9999720961937287\n",
      "Test on valid set: loss= 2.1705355644226074 acc= 0.6479891538619995 auc= 0.9515555555555556\n",
      "\n",
      "Epoch 166/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0244\n",
      "\n",
      "Test on train set: loss= 0.025014011189341545 acc= 0.9908546209335327 auc= 0.9999691161708414\n",
      "Test on valid set: loss= 2.096545457839966 acc= 0.6535874605178833 auc= 0.9502222222222221\n",
      "\n",
      "Epoch 167/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0190\n",
      "\n",
      "Test on train set: loss= 0.015258174389600754 acc= 0.9944965839385986 auc= 0.9999855494070331\n",
      "Test on valid set: loss= 1.9776006937026978 acc= 0.7218197584152222 auc= 0.9564444444444444\n",
      "\n",
      "Epoch 168/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0277\n",
      "\n",
      "Test on train set: loss= 0.019924458116292953 acc= 0.9927160739898682 auc= 0.9999689077256194\n",
      "Test on valid set: loss= 2.1414289474487305 acc= 0.6752275824546814 auc= 0.9542222222222223\n",
      "\n",
      "Epoch 169/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0232\n",
      "\n",
      "Test on train set: loss= 0.016109365969896317 acc= 0.9940919280052185 auc= 0.999979776878309\n",
      "Test on valid set: loss= 2.593998908996582 acc= 0.6378691792488098 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 170/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0306\n",
      "\n",
      "Test on train set: loss= 0.021091368049383163 acc= 0.9926351308822632 auc= 0.9999520824023136\n",
      "Test on valid set: loss= 2.450303316116333 acc= 0.6356210112571716 auc= 0.947111111111111\n",
      "\n",
      "Epoch 171/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0243\n",
      "\n",
      "Test on train set: loss= 0.02362140081822872 acc= 0.9915830492973328 auc= 0.999950204167021\n",
      "Test on valid set: loss= 2.245994806289673 acc= 0.6634151935577393 auc= 0.939111111111111\n",
      "\n",
      "Epoch 172/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0216\n",
      "\n",
      "Test on train set: loss= 0.015023092739284039 acc= 0.9948203563690186 auc= 0.9999859692848062\n",
      "Test on valid set: loss= 2.152693748474121 acc= 0.6899800300598145 auc= 0.9555555555555555\n",
      "\n",
      "Epoch 173/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0172\n",
      "\n",
      "Test on train set: loss= 0.01652510091662407 acc= 0.9940109848976135 auc= 0.9999830912082139\n",
      "Test on valid set: loss= 2.1782214641571045 acc= 0.6699692010879517 auc= 0.947111111111111\n",
      "\n",
      "Epoch 174/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0201\n",
      "\n",
      "Test on train set: loss= 0.014708207920193672 acc= 0.9950631260871887 auc= 0.9999817886593743\n",
      "Test on valid set: loss= 2.198704719543457 acc= 0.6649378538131714 auc= 0.944888888888889\n",
      "\n",
      "Epoch 175/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0201\n",
      "\n",
      "Test on train set: loss= 0.016748076304793358 acc= 0.9948203563690186 auc= 0.999981130854256\n",
      "Test on valid set: loss= 2.136154890060425 acc= 0.688097357749939 auc= 0.944\n",
      "\n",
      "Epoch 176/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 2s - loss: 0.0251\n",
      "\n",
      "Test on train set: loss= 0.04012470319867134 acc= 0.9857559204101562 auc= 0.9999526621497715\n",
      "Test on valid set: loss= 1.9196707010269165 acc= 0.6822082996368408 auc= 0.9555555555555555\n",
      "\n",
      "Epoch 177/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 2s - loss: 0.0212\n",
      "\n",
      "Test on train set: loss= 0.03202660381793976 acc= 0.9876173734664917 auc= 0.9999489162133415\n",
      "Test on valid set: loss= 2.2663674354553223 acc= 0.634140133857727 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 178/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0214\n",
      "\n",
      "Test on train set: loss= 0.00995372049510479 acc= 0.9966817498207092 auc= 0.9999909636856789\n",
      "Test on valid set: loss= 2.119050979614258 acc= 0.6494519710540771 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 179/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0157\n",
      "\n",
      "Test on train set: loss= 0.013426837511360645 acc= 0.9951440691947937 auc= 0.9999858555351893\n",
      "Test on valid set: loss= 2.174926996231079 acc= 0.6614739894866943 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 180/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0205\n",
      "\n",
      "Test on train set: loss= 0.015932608395814896 acc= 0.9951440691947937 auc= 0.9999817962143887\n",
      "Test on valid set: loss= 2.2428438663482666 acc= 0.6663571000099182 auc= 0.9382222222222222\n",
      "\n",
      "Epoch 181/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 0.0269\n",
      "\n",
      "Test on train set: loss= 0.019623657688498497 acc= 0.9929589033126831 auc= 0.9999622176193934\n",
      "Test on valid set: loss= 2.1162619590759277 acc= 0.7030616402626038 auc= 0.9466666666666665\n",
      "\n",
      "Epoch 182/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 0.0232\n",
      "\n",
      "Test on train set: loss= 0.016920851543545723 acc= 0.9947394132614136 auc= 0.9999785328458948\n",
      "Test on valid set: loss= 2.080864429473877 acc= 0.6526232361793518 auc= 0.9404444444444444\n",
      "\n",
      "Epoch 183/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 0.0227\n",
      "\n",
      "Test on train set: loss= 0.01473916508257389 acc= 0.9949012398719788 auc= 0.9999769017519211\n",
      "Test on valid set: loss= 1.8709756135940552 acc= 0.6938472986221313 auc= 0.9431111111111111\n",
      "\n",
      "Epoch 184/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0225\n",
      "\n",
      "Test on train set: loss= 0.026945296674966812 acc= 0.9910165071487427 auc= 0.999941590629281\n",
      "Test on valid set: loss= 2.4112138748168945 acc= 0.6095492243766785 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 185/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.0229\n",
      "\n",
      "Test on train set: loss= 0.012355819344520569 acc= 0.995953381061554 auc= 0.9999873876996462\n",
      "Test on valid set: loss= 2.5552759170532227 acc= 0.5981770157814026 auc= 0.9422222222222223\n",
      "\n",
      "Epoch 186/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 0.0281\n",
      "\n",
      "Test on train set: loss= 0.028292115777730942 acc= 0.9899643659591675 auc= 0.999960746596223\n",
      "Test on valid set: loss= 1.8935760259628296 acc= 0.665185809135437 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 187/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0192\n",
      "\n",
      "Test on train set: loss= 0.014147058129310608 acc= 0.9956296682357788 auc= 0.9999765702301321\n",
      "Test on valid set: loss= 2.010768175125122 acc= 0.656195878982544 auc= 0.9511111111111111\n",
      "\n",
      "Epoch 188/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0195\n",
      "\n",
      "Test on train set: loss= 0.016852252185344696 acc= 0.9940919280052185 auc= 0.9999864864266277\n",
      "Test on valid set: loss= 2.589050531387329 acc= 0.6392248868942261 auc= 0.9377777777777778\n",
      "\n",
      "Epoch 189/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0124\n",
      "\n",
      "Test on train set: loss= 0.006881144363433123 acc= 0.9979767203330994 auc= 0.999996999337176\n",
      "Test on valid set: loss= 2.649843692779541 acc= 0.632552981376648 auc= 0.9408888888888889\n",
      "\n",
      "Epoch 190/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0161\n",
      "\n",
      "Test on train set: loss= 0.013466567732393742 acc= 0.9961961507797241 auc= 0.9999861832742957\n",
      "Test on valid set: loss= 2.4955437183380127 acc= 0.6402766108512878 auc= 0.9342222222222223\n",
      "\n",
      "Epoch 191/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0160\n",
      "\n",
      "Test on train set: loss= 0.008960939012467861 acc= 0.9972482919692993 auc= 0.999994619578674\n",
      "Test on valid set: loss= 2.513005256652832 acc= 0.6552198529243469 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 192/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0127\n",
      "\n",
      "Test on train set: loss= 0.01454033050686121 acc= 0.9946584701538086 auc= 0.9999911467448989\n",
      "Test on valid set: loss= 2.21879243850708 acc= 0.6839064359664917 auc= 0.9524444444444444\n",
      "\n",
      "Epoch 193/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0155\n",
      "\n",
      "Test on train set: loss= 0.00810410175472498 acc= 0.9976529479026794 auc= 0.9999944574103674\n",
      "Test on valid set: loss= 2.1123602390289307 acc= 0.6541944742202759 auc= 0.9515555555555556\n",
      "\n",
      "Epoch 194/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0128\n",
      "\n",
      "Test on train set: loss= 0.008013194426894188 acc= 0.9978957772254944 auc= 0.9999882766462171\n",
      "Test on valid set: loss= 2.389631509780884 acc= 0.6459484100341797 auc= 0.947111111111111\n",
      "\n",
      "Epoch 195/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0118\n",
      "\n",
      "Test on train set: loss= 0.005827271845191717 acc= 0.9984622597694397 auc= 0.9999970077196716\n",
      "Test on valid set: loss= 1.983027696609497 acc= 0.6906059980392456 auc= 0.9533333333333334\n",
      "\n",
      "Epoch 196/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0142\n",
      "\n",
      "Test on train set: loss= 0.009249628521502018 acc= 0.9970055222511292 auc= 0.999992826950319\n",
      "Test on valid set: loss= 2.576164484024048 acc= 0.6237061619758606 auc= 0.9400000000000001\n",
      "\n",
      "Epoch 197/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0145\n",
      "\n",
      "Test on train set: loss= 0.01250899862498045 acc= 0.995953381061554 auc= 0.9999902552275785\n",
      "Test on valid set: loss= 2.189481496810913 acc= 0.6677676439285278 auc= 0.944888888888889\n",
      "\n",
      "Epoch 198/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0167\n",
      "\n",
      "Test on train set: loss= 0.007925314828753471 acc= 0.9975720047950745 auc= 0.999996441777175\n",
      "Test on valid set: loss= 2.5445573329925537 acc= 0.6460593342781067 auc= 0.9533333333333334\n",
      "\n",
      "Epoch 199/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0132\n",
      "\n",
      "Test on train set: loss= 0.010424034669995308 acc= 0.9973292350769043 auc= 0.999988628591369\n",
      "Test on valid set: loss= 2.6720144748687744 acc= 0.639496922492981 auc= 0.939111111111111\n",
      "\n",
      "Epoch 200/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 0.0140\n",
      "\n",
      "Test on train set: loss= 0.019213486462831497 acc= 0.9932826161384583 auc= 0.9999817273641038\n",
      "Test on valid set: loss= 2.9890105724334717 acc= 0.6542731523513794 auc= 0.9333333333333332\n",
      "\n",
      "Epoch 201/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0141\n",
      "\n",
      "Test on train set: loss= 0.004729911684989929 acc= 0.9989478588104248 auc= 0.9999987042056674\n",
      "Test on valid set: loss= 2.436788558959961 acc= 0.6969214677810669 auc= 0.9426666666666665\n",
      "\n",
      "Epoch 202/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0083\n",
      "\n",
      "Test on train set: loss= 0.003393820719793439 acc= 0.9992716312408447 auc= 0.9999995839197675\n",
      "Test on valid set: loss= 2.4452157020568848 acc= 0.6926208734512329 auc= 0.9435555555555556\n",
      "\n",
      "Epoch 203/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: 0.0065\n",
      "\n",
      "Test on train set: loss= 0.0027012997306883335 acc= 0.9995144009590149 auc= 0.9999999056823947\n",
      "Test on valid set: loss= 2.466439723968506 acc= 0.6827645897865295 auc= 0.9426666666666665\n",
      "\n",
      "Epoch 204/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0052\n",
      "\n",
      "Test on train set: loss= 0.0025572150480002165 acc= 0.9995953440666199 auc= 0.9999999099351914\n",
      "Test on valid set: loss= 2.488934278488159 acc= 0.6897351145744324 auc= 0.9408888888888889\n",
      "\n",
      "Epoch 205/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0049\n",
      "\n",
      "Test on train set: loss= 0.002074302639812231 acc= 0.9997572302818298 auc= 0.9999999839907616\n",
      "Test on valid set: loss= 2.4076452255249023 acc= 0.6922073364257812 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 206/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0035\n",
      "\n",
      "Test on train set: loss= 0.0018387119052931666 acc= 0.99983811378479 auc= 0.9999999760937823\n",
      "Test on valid set: loss= 2.4795522689819336 acc= 0.6812917590141296 auc= 0.9440000000000002\n",
      "\n",
      "Epoch 207/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0043\n",
      "\n",
      "Test on train set: loss= 0.0019288413459435105 acc= 0.9997572302818298 auc= 0.9999999892756388\n",
      "Test on valid set: loss= 2.5002386569976807 acc= 0.6774784326553345 auc= 0.9417777777777779\n",
      "\n",
      "Epoch 208/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0037\n",
      "\n",
      "Test on train set: loss= 0.0015503333415836096 acc= 0.99983811378479 auc= 0.9999999813786598\n",
      "Test on valid set: loss= 2.4500327110290527 acc= 0.6803314089775085 auc= 0.9426666666666665\n",
      "\n",
      "Epoch 209/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0050\n",
      "\n",
      "Test on train set: loss= 0.0015165950171649456 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.471320867538452 acc= 0.6741496324539185 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 210/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0043\n",
      "\n",
      "Test on train set: loss= 0.001466388232074678 acc= 0.99983811378479 auc= 1.0\n",
      "Test on valid set: loss= 2.4936273097991943 acc= 0.6824008822441101 auc= 0.9417777777777777\n",
      "\n",
      "Epoch 211/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0042\n",
      "\n",
      "Test on train set: loss= 0.0014391775475814939 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.4114601612091064 acc= 0.6794271469116211 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 212/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0036\n",
      "\n",
      "Test on train set: loss= 0.0012839939445257187 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.417907953262329 acc= 0.6827297806739807 auc= 0.9440000000000002\n",
      "\n",
      "Epoch 213/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0038\n",
      "\n",
      "Test on train set: loss= 0.0012518101138994098 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3876569271087646 acc= 0.6865555047988892 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 214/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0027\n",
      "\n",
      "Test on train set: loss= 0.0012087745126336813 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.414569616317749 acc= 0.6817753911018372 auc= 0.9448888888888888\n",
      "\n",
      "Epoch 215/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0036\n",
      "\n",
      "Test on train set: loss= 0.0012276151683181524 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3842613697052 acc= 0.6939657926559448 auc= 0.9444444444444444\n",
      "\n",
      "Epoch 216/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0028\n",
      "\n",
      "Test on train set: loss= 0.0011895631905645132 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.440749168395996 acc= 0.674941897392273 auc= 0.9448888888888888\n",
      "\n",
      "Epoch 217/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0033\n",
      "\n",
      "Test on train set: loss= 0.0011529973708093166 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.360314130783081 acc= 0.6839138865470886 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 218/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0025\n",
      "\n",
      "Test on train set: loss= 0.0010728962952271104 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3905770778656006 acc= 0.6859862208366394 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 219/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0035\n",
      "\n",
      "Test on train set: loss= 0.0010392925469204783 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.374325752258301 acc= 0.6829029321670532 auc= 0.9457777777777778\n",
      "\n",
      "Epoch 220/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0026\n",
      "\n",
      "Test on train set: loss= 0.001050477847456932 acc= 0.99983811378479 auc= 1.0\n",
      "Test on valid set: loss= 2.367546319961548 acc= 0.6826825737953186 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 221/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0032\n",
      "\n",
      "Test on train set: loss= 0.0009790031472221017 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3696792125701904 acc= 0.6777814030647278 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 222/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0024\n",
      "\n",
      "Test on train set: loss= 0.0008924524299800396 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.313141107559204 acc= 0.6860376596450806 auc= 0.9453333333333334\n",
      "\n",
      "Epoch 223/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0032\n",
      "\n",
      "Test on train set: loss= 0.0009268164285458624 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3785431385040283 acc= 0.6787868142127991 auc= 0.947111111111111\n",
      "\n",
      "Epoch 224/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0030\n",
      "\n",
      "Test on train set: loss= 0.0009103932534344494 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.364485740661621 acc= 0.6891363263130188 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 225/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0027\n",
      "\n",
      "Test on train set: loss= 0.0009884757455438375 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3686773777008057 acc= 0.6875763535499573 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 226/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 2s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0008620087173767388 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3622608184814453 acc= 0.6731460094451904 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 227/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0026\n",
      "\n",
      "Test on train set: loss= 0.0009723507682792842 acc= 0.99983811378479 auc= 1.0\n",
      "Test on valid set: loss= 2.3844375610351562 acc= 0.6800943613052368 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 228/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0029\n",
      "\n",
      "Test on train set: loss= 0.0009065704070962965 acc= 0.999919056892395 auc= 0.999999997280258\n",
      "Test on valid set: loss= 2.4378740787506104 acc= 0.6645238399505615 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 229/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0029\n",
      "\n",
      "Test on train set: loss= 0.0008986701141111553 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.378262996673584 acc= 0.6768200993537903 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 230/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0031\n",
      "\n",
      "Test on train set: loss= 0.0008873797487467527 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3269598484039307 acc= 0.6756199598312378 auc= 0.9506666666666665\n",
      "\n",
      "Epoch 231/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0009344209684059024 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3399829864501953 acc= 0.6768309473991394 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 232/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0008490014588460326 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3302817344665527 acc= 0.6809219121932983 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 233/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0029\n",
      "\n",
      "Test on train set: loss= 0.0008097143145278096 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.3532750606536865 acc= 0.6803576946258545 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 234/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0026\n",
      "\n",
      "Test on train set: loss= 0.000758893380407244 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3572545051574707 acc= 0.6791934967041016 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 235/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0025\n",
      "\n",
      "Test on train set: loss= 0.000708275125361979 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3669986724853516 acc= 0.6693297624588013 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 236/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0007330478401854634 acc= 0.999919056892395 auc= 1.0\n",
      "Test on valid set: loss= 2.394820213317871 acc= 0.6657817363739014 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 237/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.0006859485292807221 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3312675952911377 acc= 0.6760174632072449 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 238/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: 0.0026\n",
      "\n",
      "Test on train set: loss= 0.0006674994947388768 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.395240068435669 acc= 0.6656745672225952 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 239/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0029\n",
      "\n",
      "Test on train set: loss= 0.0007401803159154952 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3885445594787598 acc= 0.6746698021888733 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 240/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.0006315195932984352 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3409621715545654 acc= 0.6743291616439819 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 241/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0024\n",
      "\n",
      "Test on train set: loss= 0.0006028759526088834 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.314615249633789 acc= 0.67616206407547 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 242/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.0006324907881207764 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3288767337799072 acc= 0.674240231513977 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 243/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0025\n",
      "\n",
      "Test on train set: loss= 0.0005418675718829036 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.35735821723938 acc= 0.6735478639602661 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 244/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0020\n",
      "\n",
      "Test on train set: loss= 0.0005734174628742039 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3310985565185547 acc= 0.665081799030304 auc= 0.9462222222222223\n",
      "\n",
      "Epoch 245/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0006302055553533137 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.352548599243164 acc= 0.6726606488227844 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 246/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0005455462378449738 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.355059862136841 acc= 0.6674720048904419 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 247/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 0.0019\n",
      "\n",
      "Test on train set: loss= 0.0005494214128702879 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3794243335723877 acc= 0.6704331636428833 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 248/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0005469417083077133 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3869032859802246 acc= 0.6773890256881714 auc= 0.947111111111111\n",
      "\n",
      "Epoch 249/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.0005207645590417087 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.4296622276306152 acc= 0.6639239192008972 auc= 0.9457777777777776\n",
      "\n",
      "Epoch 250/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0005526563618332148 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.342346429824829 acc= 0.6770725250244141 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 251/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0005604300531558692 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3591411113739014 acc= 0.6732895970344543 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 252/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0006132528651505709 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3785738945007324 acc= 0.6696681380271912 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 253/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0005114352679811418 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.372129440307617 acc= 0.6761919260025024 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 254/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0026\n",
      "\n",
      "Test on train set: loss= 0.0005160405416972935 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3546700477600098 acc= 0.6664837598800659 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 255/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 6s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0005061292322352529 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3814377784729004 acc= 0.6665412187576294 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 256/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 6s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0005683210329152644 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3778109550476074 acc= 0.6679426431655884 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 257/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0004951473092660308 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.359523057937622 acc= 0.6684699654579163 auc= 0.9479999999999998\n",
      "\n",
      "Epoch 258/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0005090259946882725 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3728444576263428 acc= 0.671068012714386 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 259/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0005118556437082589 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.345346689224243 acc= 0.6770947575569153 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 260/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.00048665975918993354 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3455562591552734 acc= 0.6702232360839844 auc= 0.9493333333333333\n",
      "\n",
      "Epoch 261/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0019\n",
      "\n",
      "Test on train set: loss= 0.0004942026571370661 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.390000581741333 acc= 0.6655830144882202 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 262/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0015\n",
      "\n",
      "Test on train set: loss= 0.0005217745201662183 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.377549648284912 acc= 0.6713853478431702 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 263/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 6s - loss: 0.0019\n",
      "\n",
      "Test on train set: loss= 0.0004911090363748372 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.349764347076416 acc= 0.6680654287338257 auc= 0.9480000000000001\n",
      "\n",
      "Epoch 264/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0005611146916635334 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3343687057495117 acc= 0.6841289401054382 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 265/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0005044603603892028 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3190245628356934 acc= 0.6754352450370789 auc= 0.9515555555555556\n",
      "\n",
      "Epoch 266/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0004860774497501552 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3729069232940674 acc= 0.6667182445526123 auc= 0.9484444444444445\n",
      "\n",
      "Epoch 267/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0005182172753848135 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3166379928588867 acc= 0.6819806098937988 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 268/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0019\n",
      "\n",
      "Test on train set: loss= 0.0004756989364977926 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.393906354904175 acc= 0.6652310490608215 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 269/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0005453951307572424 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3320746421813965 acc= 0.6675196290016174 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 270/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.000499061425216496 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.371323347091675 acc= 0.6669157147407532 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 271/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0014\n",
      "\n",
      "Test on train set: loss= 0.0005036764778196812 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3379933834075928 acc= 0.672355592250824 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 272/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0004888151888735592 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.424741268157959 acc= 0.6679221391677856 auc= 0.9471111111111112\n",
      "\n",
      "Epoch 273/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0020\n",
      "\n",
      "Test on train set: loss= 0.0005603693425655365 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3406355381011963 acc= 0.6774031519889832 auc= 0.9502222222222221\n",
      "\n",
      "Epoch 274/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0004733205714728683 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.375624179840088 acc= 0.6690813302993774 auc= 0.9506666666666665\n",
      "\n",
      "Epoch 275/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.0005077786627225578 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.372581720352173 acc= 0.6650732755661011 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 276/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0005180355510674417 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3309860229492188 acc= 0.676829993724823 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 277/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.0004844319773837924 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3447604179382324 acc= 0.6748028993606567 auc= 0.952\n",
      "\n",
      "Epoch 278/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0004938492202199996 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3951077461242676 acc= 0.669364869594574 auc= 0.9484444444444444\n",
      "\n",
      "Epoch 279/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0006102485349401832 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3207242488861084 acc= 0.6800973415374756 auc= 0.9497777777777779\n",
      "\n",
      "Epoch 280/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: 0.0015\n",
      "\n",
      "Test on train set: loss= 0.0004856489540543407 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.4068796634674072 acc= 0.6753726005554199 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 281/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0022\n",
      "\n",
      "Test on train set: loss= 0.0005101257702335715 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3262224197387695 acc= 0.6803296804428101 auc= 0.9515555555555556\n",
      "\n",
      "Epoch 282/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0005276366136968136 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.35711669921875 acc= 0.6727229356765747 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 283/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: 0.0023\n",
      "\n",
      "Test on train set: loss= 0.00046998009202070534 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.347135305404663 acc= 0.6768458485603333 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 284/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.00047586552682332695 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.368147611618042 acc= 0.6765463352203369 auc= 0.9475555555555555\n",
      "\n",
      "Epoch 285/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.0004411761765368283 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3624162673950195 acc= 0.65962153673172 auc= 0.9506666666666665\n",
      "\n",
      "Epoch 286/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0004811095423065126 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3665642738342285 acc= 0.669880747795105 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 287/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 4s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.0004926977562718093 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3185830116271973 acc= 0.6785266399383545 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 288/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.00047956599155440927 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3314058780670166 acc= 0.6737685203552246 auc= 0.9493333333333334\n",
      "\n",
      "Epoch 289/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0004966038977727294 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.422717332839966 acc= 0.6595442295074463 auc= 0.947111111111111\n",
      "\n",
      "Epoch 290/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0018\n",
      "\n",
      "Test on train set: loss= 0.0004778061411343515 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3695342540740967 acc= 0.6715062260627747 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 291/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0021\n",
      "\n",
      "Test on train set: loss= 0.0004756821144837886 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.289172410964966 acc= 0.6789928674697876 auc= 0.9506666666666668\n",
      "\n",
      "Epoch 292/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.0005235144635662436 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3271682262420654 acc= 0.6777113080024719 auc= 0.9502222222222223\n",
      "\n",
      "Epoch 293/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.0004999815719202161 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3226964473724365 acc= 0.6798643469810486 auc= 0.9497777777777777\n",
      "\n",
      "Epoch 294/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0016\n",
      "\n",
      "Test on train set: loss= 0.00047466703108511865 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.382283926010132 acc= 0.669516384601593 auc= 0.9462222222222222\n",
      "\n",
      "Epoch 295/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0017\n",
      "\n",
      "Test on train set: loss= 0.00048587765195406973 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.368070602416992 acc= 0.6723238825798035 auc= 0.9457777777777778\n",
      "\n",
      "Epoch 296/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0015\n",
      "\n",
      "Test on train set: loss= 0.0004903743974864483 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.385321617126465 acc= 0.6806924343109131 auc= 0.9466666666666667\n",
      "\n",
      "Epoch 297/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0012\n",
      "\n",
      "Test on train set: loss= 0.0004824854258913547 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.3579835891723633 acc= 0.6848098635673523 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 298/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0019\n",
      "\n",
      "Test on train set: loss= 0.0004716991097666323 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.344531297683716 acc= 0.6734985709190369 auc= 0.9488888888888889\n",
      "\n",
      "Epoch 299/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0015\n",
      "\n",
      "Test on train set: loss= 0.0005153180100023746 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.379438877105713 acc= 0.6652653813362122 auc= 0.944888888888889\n",
      "\n",
      "Epoch 300/300\n",
      "\n",
      "Baseline\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 0.0013\n",
      "\n",
      "Test on train set: loss= 0.0004420322075020522 acc= 1.0 auc= 1.0\n",
      "Test on valid set: loss= 2.33682918548584 acc= 0.6719702482223511 auc= 0.9488888888888889\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "encoding_matrix = tf.Variable(tf.eye(10), trainable=False)\n",
    "trainGen = train_generator(epochs, batch_size, encoding_matrix)\n",
    "model.set_weights(pretrainedWeights)\n",
    "model.compile(optimizer=copy.deepcopy(optimizer), loss = loss_fn)\n",
    "\n",
    "metric_idx = 0\n",
    "trainMetrics = (softConfusionMatrix_train[metric_idx], \n",
    "                confusionMatrix_train[metric_idx],loss_train[metric_idx], \n",
    "                acc_train[metric_idx], auc_train[metric_idx])\n",
    "\n",
    "validMetrics = (softConfusionMatrix_valid[metric_idx], \n",
    "                loss_valid[metric_idx], acc_valid[metric_idx], auc_valid[metric_idx])\n",
    "\n",
    "adjust_lr = AdjustLR(\n",
    "      schedule = lr_schedule,\n",
    "      base_learning_rate = lr,\n",
    "  )\n",
    "\n",
    "uemgm = UpdateEncodingMatrixAndGetMetrics_Base(train_x_no_valid, train_y_no_valid,\n",
    "                                               valid_x, valid_y, trainMetrics, \n",
    "                                               validMetrics, 'Baseline')\n",
    "                        \n",
    "_ = model.fit(trainGen, \n",
    "              initial_epoch = beginEncodingEpoch, \n",
    "              epochs = epochs, verbose = 2,\n",
    "              steps_per_epoch = steps, callbacks=[uemgm,\n",
    "                                             adjust_lr,\n",
    "                                            ])\n",
    "baselineWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancement Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.016666668>\n",
      "97/97 - 5s - loss: 1.5951\n",
      "\n",
      "Test on train set: loss= 1.359507441520691 acc= 0.5399805903434753 auc= 0.7587268189365088\n",
      "Test on valid set: loss= 2.6394708156585693 acc= 0.16903360188007355 auc= 0.6835555555555556\n",
      "\n",
      "Epoch 2/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.033333335>\n",
      "97/97 - 3s - loss: -2.2513e+00\n",
      "\n",
      "Test on train set: loss= 2.1589791774749756 acc= 0.6107154488563538 auc= 0.7569326090779969\n",
      "Test on valid set: loss= 4.848855495452881 acc= 0.20227551460266113 auc= 0.6364444444444445\n",
      "\n",
      "Epoch 3/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.05>\n",
      "97/97 - 3s - loss: -5.0912e+00\n",
      "\n",
      "Test on train set: loss= 3.2059710025787354 acc= 0.5568954348564148 auc= 0.707717675944941\n",
      "Test on valid set: loss= 7.163579940795898 acc= 0.21161016821861267 auc= 0.6344444444444444\n",
      "\n",
      "Epoch 4/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.06666667>\n",
      "97/97 - 3s - loss: -5.9139e+00\n",
      "\n",
      "Test on train set: loss= 3.1150240898132324 acc= 0.6370993852615356 auc= 0.7851405083194986\n",
      "Test on valid set: loss= 6.784022331237793 acc= 0.2713744342327118 auc= 0.6653333333333333\n",
      "\n",
      "Epoch 5/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.083333336>\n",
      "97/97 - 3s - loss: -8.4933e+00\n",
      "\n",
      "Test on train set: loss= 5.2587995529174805 acc= 0.5945289731025696 auc= 0.6890757980470006\n",
      "Test on valid set: loss= 11.850358963012695 acc= 0.18041051924228668 auc= 0.6315555555555555\n",
      "\n",
      "Epoch 6/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.1011e+00\n",
      "\n",
      "Test on train set: loss= 3.0781538486480713 acc= 0.6870346665382385 auc= 0.8214965219115073\n",
      "Test on valid set: loss= 7.728687763214111 acc= 0.2604927122592926 auc= 0.7273333333333333\n",
      "\n",
      "Epoch 7/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0999e+01\n",
      "\n",
      "Test on train set: loss= 4.013321399688721 acc= 0.6941567063331604 auc= 0.7787577022899083\n",
      "Test on valid set: loss= 10.484972953796387 acc= 0.29659125208854675 auc= 0.7295555555555555\n",
      "\n",
      "Epoch 8/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5825e+01\n",
      "\n",
      "Test on train set: loss= 7.8254852294921875 acc= 0.47232115268707275 auc= 0.7059772717052387\n",
      "Test on valid set: loss= 12.914258003234863 acc= 0.16281670331954956 auc= 0.6326666666666667\n",
      "\n",
      "Epoch 9/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.6409e+00\n",
      "\n",
      "Test on train set: loss= 4.530068397521973 acc= 0.6175137758255005 auc= 0.7530481697077576\n",
      "Test on valid set: loss= 11.305925369262695 acc= 0.23622441291809082 auc= 0.6526666666666666\n",
      "\n",
      "Epoch 10/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.4030e+01\n",
      "\n",
      "Test on train set: loss= 3.683117628097534 acc= 0.6884914040565491 auc= 0.7898528051425774\n",
      "Test on valid set: loss= 9.079429626464844 acc= 0.2740614712238312 auc= 0.67\n",
      "\n",
      "Epoch 11/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.3372e+01\n",
      "\n",
      "Test on train set: loss= 3.174161672592163 acc= 0.723292350769043 auc= 0.8468105595992302\n",
      "Test on valid set: loss= 8.281837463378906 acc= 0.34918004274368286 auc= 0.7415555555555555\n",
      "\n",
      "Epoch 12/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0532e+01\n",
      "\n",
      "Test on train set: loss= 4.1191630363464355 acc= 0.6931855082511902 auc= 0.823115803188575\n",
      "Test on valid set: loss= 8.960713386535645 acc= 0.35989513993263245 auc= 0.7895555555555556\n",
      "\n",
      "Epoch 13/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.2299e+01\n",
      "\n",
      "Test on train set: loss= 5.0835700035095215 acc= 0.6317578554153442 auc= 0.7191939910574303\n",
      "Test on valid set: loss= 8.367973327636719 acc= 0.40274548530578613 auc= 0.7497777777777779\n",
      "\n",
      "Epoch 14/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.9973e+01\n",
      "\n",
      "Test on train set: loss= 4.310064315795898 acc= 0.6930236220359802 auc= 0.8073499613534892\n",
      "Test on valid set: loss= 9.587732315063477 acc= 0.3388497233390808 auc= 0.7544444444444445\n",
      "\n",
      "Epoch 15/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1810e+01\n",
      "\n",
      "Test on train set: loss= 3.8109800815582275 acc= 0.73089998960495 auc= 0.8103678638536008\n",
      "Test on valid set: loss= 10.77120590209961 acc= 0.30000606179237366 auc= 0.723111111111111\n",
      "\n",
      "Epoch 16/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.1181e+01\n",
      "\n",
      "Test on train set: loss= 3.5787580013275146 acc= 0.7353512644767761 auc= 0.8633767210743271\n",
      "Test on valid set: loss= 7.5785675048828125 acc= 0.4300466477870941 auc= 0.7857777777777778\n",
      "\n",
      "Epoch 17/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.1359e+01\n",
      "\n",
      "Test on train set: loss= 3.9737470149993896 acc= 0.7158465385437012 auc= 0.8448259394007815\n",
      "Test on valid set: loss= 7.9441094398498535 acc= 0.4028891921043396 auc= 0.7955555555555556\n",
      "\n",
      "Epoch 18/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6495e+01\n",
      "\n",
      "Test on train set: loss= 3.5436477661132812 acc= 0.7474911212921143 auc= 0.8556113469472983\n",
      "Test on valid set: loss= 9.255898475646973 acc= 0.34567689895629883 auc= 0.7786666666666667\n",
      "\n",
      "Epoch 19/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0028e+01\n",
      "\n",
      "Test on train set: loss= 3.8989744186401367 acc= 0.7300906181335449 auc= 0.8314617780452986\n",
      "Test on valid set: loss= 9.806690216064453 acc= 0.3569081127643585 auc= 0.7428888888888888\n",
      "\n",
      "Epoch 20/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -2.7163e+01\n",
      "\n",
      "Test on train set: loss= 3.563887119293213 acc= 0.7309808731079102 auc= 0.8550560459703955\n",
      "Test on valid set: loss= 7.307285308837891 acc= 0.4515171945095062 auc= 0.8506666666666666\n",
      "\n",
      "Epoch 21/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: -4.5807e+01\n",
      "\n",
      "Test on train set: loss= 4.763468265533447 acc= 0.6784558296203613 auc= 0.777435090112377\n",
      "Test on valid set: loss= 8.538769721984863 acc= 0.43696022033691406 auc= 0.7597777777777778\n",
      "\n",
      "Epoch 22/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -4.8777e+01\n",
      "\n",
      "Test on train set: loss= 3.2002382278442383 acc= 0.7751699686050415 auc= 0.840172921063355\n",
      "Test on valid set: loss= 8.775269508361816 acc= 0.4126911759376526 auc= 0.7917777777777778\n",
      "\n",
      "Epoch 23/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.9479e+01\n",
      "\n",
      "Test on train set: loss= 3.4067370891571045 acc= 0.7724182605743408 auc= 0.8000307770772631\n",
      "Test on valid set: loss= 9.165860176086426 acc= 0.4192731976509094 auc= 0.7524444444444445\n",
      "\n",
      "Epoch 24/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -3.1958e+01\n",
      "\n",
      "Test on train set: loss= 2.9990718364715576 acc= 0.7864195704460144 auc= 0.8604311095756758\n",
      "Test on valid set: loss= 7.6578049659729 acc= 0.44080036878585815 auc= 0.7811111111111112\n",
      "\n",
      "Epoch 25/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -3.3658e+01\n",
      "\n",
      "Test on train set: loss= 3.232100248336792 acc= 0.7648106217384338 auc= 0.868035587655044\n",
      "Test on valid set: loss= 9.341824531555176 acc= 0.3794143497943878 auc= 0.7937777777777777\n",
      "\n",
      "Epoch 26/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5900e+01\n",
      "\n",
      "Test on train set: loss= 3.6367950439453125 acc= 0.7479767203330994 auc= 0.8540801226307748\n",
      "Test on valid set: loss= 10.284043312072754 acc= 0.35987982153892517 auc= 0.823111111111111\n",
      "\n",
      "Epoch 27/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.4883e+01\n",
      "\n",
      "Test on train set: loss= 3.005033254623413 acc= 0.7895759344100952 auc= 0.8847556392872086\n",
      "Test on valid set: loss= 8.470800399780273 acc= 0.43182143568992615 auc= 0.8164444444444445\n",
      "\n",
      "Epoch 28/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1347e+01\n",
      "\n",
      "Test on train set: loss= 5.943039894104004 acc= 0.6141145825386047 auc= 0.780742924700198\n",
      "Test on valid set: loss= 8.703789710998535 acc= 0.4599820077419281 auc= 0.7691111111111111\n",
      "\n",
      "Epoch 29/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9358e+01\n",
      "\n",
      "Test on train set: loss= 3.705188512802124 acc= 0.7476529479026794 auc= 0.8155777562974105\n",
      "Test on valid set: loss= 8.892226219177246 acc= 0.4034918248653412 auc= 0.7524444444444445\n",
      "\n",
      "Epoch 30/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.6309e+01\n",
      "\n",
      "Test on train set: loss= 3.2227680683135986 acc= 0.784477174282074 auc= 0.8304884040959564\n",
      "Test on valid set: loss= 7.146063804626465 acc= 0.5201743841171265 auc= 0.7868888888888889\n",
      "\n",
      "Epoch 31/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9360e+01\n",
      "\n",
      "Test on train set: loss= 3.0268115997314453 acc= 0.7972645163536072 auc= 0.8659991355707561\n",
      "Test on valid set: loss= 6.657810688018799 acc= 0.5599308013916016 auc= 0.8391111111111111\n",
      "\n",
      "Epoch 32/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.7465e+01\n",
      "\n",
      "Test on train set: loss= 3.968796730041504 acc= 0.7364842891693115 auc= 0.8437186662972292\n",
      "Test on valid set: loss= 7.710902214050293 acc= 0.508231520652771 auc= 0.7848888888888889\n",
      "\n",
      "Epoch 33/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.8094e+01\n",
      "\n",
      "Test on train set: loss= 3.015165328979492 acc= 0.7970216870307922 auc= 0.8433234132691012\n",
      "Test on valid set: loss= 9.118823051452637 acc= 0.40096211433410645 auc= 0.7588888888888888\n",
      "\n",
      "Epoch 34/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.1395e+01\n",
      "\n",
      "Test on train set: loss= 3.7624053955078125 acc= 0.7357559204101562 auc= 0.8875802383055353\n",
      "Test on valid set: loss= 6.091330528259277 acc= 0.5891314744949341 auc= 0.8855555555555557\n",
      "\n",
      "Epoch 35/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.2898e+01\n",
      "\n",
      "Test on train set: loss= 3.304939031600952 acc= 0.7798640131950378 auc= 0.8466433331710898\n",
      "Test on valid set: loss= 6.701752185821533 acc= 0.555345356464386 auc= 0.8093333333333333\n",
      "\n",
      "Epoch 36/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.1049e+01\n",
      "\n",
      "Test on train set: loss= 2.4642131328582764 acc= 0.8365976214408875 auc= 0.8528497141153091\n",
      "Test on valid set: loss= 7.996348857879639 acc= 0.46209582686424255 auc= 0.8117777777777778\n",
      "\n",
      "Epoch 37/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.5941e+01\n",
      "\n",
      "Test on train set: loss= 3.1909148693084717 acc= 0.7875525951385498 auc= 0.8839405377636238\n",
      "Test on valid set: loss= 7.7411909103393555 acc= 0.4608938694000244 auc= 0.8406666666666667\n",
      "\n",
      "Epoch 38/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.3423e+01\n",
      "\n",
      "Test on train set: loss= 2.4296274185180664 acc= 0.8394302129745483 auc= 0.8476359533156221\n",
      "Test on valid set: loss= 8.718544006347656 acc= 0.44955530762672424 auc= 0.7935555555555556\n",
      "\n",
      "Epoch 39/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0095e+02\n",
      "\n",
      "Test on train set: loss= 2.7487497329711914 acc= 0.8210585713386536 auc= 0.8633256114994236\n",
      "Test on valid set: loss= 7.7623701095581055 acc= 0.49650803208351135 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 40/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.7176e+01\n",
      "\n",
      "Test on train set: loss= 3.8517496585845947 acc= 0.7483813762664795 auc= 0.8346821889871668\n",
      "Test on valid set: loss= 8.713606834411621 acc= 0.4201904833316803 auc= 0.7708888888888888\n",
      "\n",
      "Epoch 41/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.1394e+01\n",
      "\n",
      "Test on train set: loss= 2.5596768856048584 acc= 0.8329556584358215 auc= 0.873645096169483\n",
      "Test on valid set: loss= 7.735013484954834 acc= 0.5199999809265137 auc= 0.7806666666666668\n",
      "\n",
      "Epoch 42/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.4392e+01\n",
      "\n",
      "Test on train set: loss= 2.303379774093628 acc= 0.8501133322715759 auc= 0.8553098516408028\n",
      "Test on valid set: loss= 7.470074653625488 acc= 0.5212313532829285 auc= 0.8100000000000002\n",
      "\n",
      "Epoch 43/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0031e+02\n",
      "\n",
      "Test on train set: loss= 2.5416359901428223 acc= 0.8341696262359619 auc= 0.8689188184612074\n",
      "Test on valid set: loss= 6.622137546539307 acc= 0.5608550906181335 auc= 0.818888888888889\n",
      "\n",
      "Epoch 44/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -7.5487e+01\n",
      "\n",
      "Test on train set: loss= 3.5017788410186768 acc= 0.7737131714820862 auc= 0.8347032464124812\n",
      "Test on valid set: loss= 6.800329685211182 acc= 0.564287543296814 auc= 0.804888888888889\n",
      "\n",
      "Epoch 45/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -7.0739e+01\n",
      "\n",
      "Test on train set: loss= 3.1259212493896484 acc= 0.7928131818771362 auc= 0.8775122287521139\n",
      "Test on valid set: loss= 6.046092510223389 acc= 0.6195419430732727 auc= 0.8453333333333333\n",
      "\n",
      "Epoch 46/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -8.0505e+01\n",
      "\n",
      "Test on train set: loss= 2.343186616897583 acc= 0.8440433740615845 auc= 0.896651151148047\n",
      "Test on valid set: loss= 6.450170993804932 acc= 0.5972724556922913 auc= 0.8413333333333334\n",
      "\n",
      "Epoch 47/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 7s - loss: -7.1750e+01\n",
      "\n",
      "Test on train set: loss= 2.6502585411071777 acc= 0.8253480195999146 auc= 0.8803328495500029\n",
      "Test on valid set: loss= 7.230108737945557 acc= 0.5400199890136719 auc= 0.8126666666666666\n",
      "\n",
      "Epoch 48/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -8.9444e+01\n",
      "\n",
      "Test on train set: loss= 2.3241567611694336 acc= 0.8472806811332703 auc= 0.8618433263014227\n",
      "Test on valid set: loss= 5.938702583312988 acc= 0.5871606469154358 auc= 0.8655555555555556\n",
      "\n",
      "Epoch 49/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -1.1590e+02\n",
      "\n",
      "Test on train set: loss= 3.8829402923583984 acc= 0.7416639924049377 auc= 0.8628915748085276\n",
      "Test on valid set: loss= 6.17624568939209 acc= 0.5999818444252014 auc= 0.8648888888888889\n",
      "\n",
      "Epoch 50/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1658e+02\n",
      "\n",
      "Test on train set: loss= 4.491383075714111 acc= 0.7122855186462402 auc= 0.7579421033458471\n",
      "Test on valid set: loss= 7.736685752868652 acc= 0.5199999809265137 auc= 0.7775555555555556\n",
      "\n",
      "Epoch 51/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2368e+02\n",
      "\n",
      "Test on train set: loss= 2.222738027572632 acc= 0.8553739190101624 auc= 0.8525129346404426\n",
      "Test on valid set: loss= 5.836355209350586 acc= 0.6042320728302002 auc= 0.8197777777777778\n",
      "\n",
      "Epoch 52/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2178e+02\n",
      "\n",
      "Test on train set: loss= 1.9328583478927612 acc= 0.8739883303642273 auc= 0.8780911407428909\n",
      "Test on valid set: loss= 5.954607963562012 acc= 0.6200098991394043 auc= 0.852888888888889\n",
      "\n",
      "Epoch 53/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1200e+02\n",
      "\n",
      "Test on train set: loss= 1.8973667621612549 acc= 0.876659095287323 auc= 0.8765339544483108\n",
      "Test on valid set: loss= 4.950440406799316 acc= 0.676172137260437 auc= 0.834\n",
      "\n",
      "Epoch 54/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1439e+02\n",
      "\n",
      "Test on train set: loss= 2.2098827362060547 acc= 0.8569925427436829 auc= 0.8770373249630605\n",
      "Test on valid set: loss= 6.259756088256836 acc= 0.6000235676765442 auc= 0.833777777777778\n",
      "\n",
      "Epoch 55/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.0660e+01\n",
      "\n",
      "Test on train set: loss= 2.08392071723938 acc= 0.8635480999946594 auc= 0.8961427070999696\n",
      "Test on valid set: loss= 5.305323600769043 acc= 0.6600035429000854 auc= 0.8342222222222222\n",
      "\n",
      "Epoch 56/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.4096e+01\n",
      "\n",
      "Test on train set: loss= 2.139069080352783 acc= 0.8612010478973389 auc= 0.8707850060905313\n",
      "Test on valid set: loss= 6.431851863861084 acc= 0.5283374190330505 auc= 0.8213333333333335\n",
      "\n",
      "Epoch 57/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2114e+02\n",
      "\n",
      "Test on train set: loss= 2.5914666652679443 acc= 0.8307704925537109 auc= 0.9046380248877256\n",
      "Test on valid set: loss= 5.480363845825195 acc= 0.6597890853881836 auc= 0.861111111111111\n",
      "\n",
      "Epoch 58/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1290e+02\n",
      "\n",
      "Test on train set: loss= 2.2112185955047607 acc= 0.8529459238052368 auc= 0.8946593567835828\n",
      "Test on valid set: loss= 5.939296722412109 acc= 0.6121893525123596 auc= 0.8455555555555556\n",
      "\n",
      "Epoch 59/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4872e+02\n",
      "\n",
      "Test on train set: loss= 2.279573440551758 acc= 0.8521366119384766 auc= 0.8371536488624487\n",
      "Test on valid set: loss= 7.321321487426758 acc= 0.5241128206253052 auc= 0.8144444444444444\n",
      "\n",
      "Epoch 60/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5602e+02\n",
      "\n",
      "Test on train set: loss= 1.9806318283081055 acc= 0.873179018497467 auc= 0.8338585955691279\n",
      "Test on valid set: loss= 7.0134053230285645 acc= 0.5599707365036011 auc= 0.8113333333333334\n",
      "\n",
      "Epoch 61/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5654e+02\n",
      "\n",
      "Test on train set: loss= 1.8277820348739624 acc= 0.8824052810668945 auc= 0.8672291557179058\n",
      "Test on valid set: loss= 5.736098766326904 acc= 0.6400001049041748 auc= 0.8448888888888888\n",
      "\n",
      "Epoch 62/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4824e+02\n",
      "\n",
      "Test on train set: loss= 2.1539223194122314 acc= 0.8618484735488892 auc= 0.8600086801697693\n",
      "Test on valid set: loss= 6.031476974487305 acc= 0.5948914885520935 auc= 0.8213333333333335\n",
      "\n",
      "Epoch 63/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1991e+02\n",
      "\n",
      "Test on train set: loss= 1.8258392810821533 acc= 0.8826481103897095 auc= 0.874536578084131\n",
      "Test on valid set: loss= 5.695181846618652 acc= 0.6400004029273987 auc= 0.8633333333333333\n",
      "\n",
      "Epoch 64/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6734e+02\n",
      "\n",
      "Test on train set: loss= 1.6772456169128418 acc= 0.891874372959137 auc= 0.8731406112482645\n",
      "Test on valid set: loss= 5.855607986450195 acc= 0.6214030981063843 auc= 0.8397777777777777\n",
      "\n",
      "Epoch 65/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0989e+02\n",
      "\n",
      "Test on train set: loss= 2.262563943862915 acc= 0.8492230772972107 auc= 0.8981357272615537\n",
      "Test on valid set: loss= 5.318281173706055 acc= 0.6257398128509521 auc= 0.8628888888888889\n",
      "\n",
      "Epoch 66/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2653e+02\n",
      "\n",
      "Test on train set: loss= 2.0778419971466064 acc= 0.8659760355949402 auc= 0.872689512205973\n",
      "Test on valid set: loss= 6.1313157081604 acc= 0.6144943237304688 auc= 0.8011111111111111\n",
      "\n",
      "Epoch 67/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4078e+02\n",
      "\n",
      "Test on train set: loss= 2.11503005027771 acc= 0.8632243275642395 auc= 0.8757621532093658\n",
      "Test on valid set: loss= 4.867390155792236 acc= 0.6828587055206299 auc= 0.8475555555555555\n",
      "\n",
      "Epoch 68/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5821e+02\n",
      "\n",
      "Test on train set: loss= 2.690457820892334 acc= 0.8255098462104797 auc= 0.9046550870063321\n",
      "Test on valid set: loss= 4.646814823150635 acc= 0.6989883184432983 auc= 0.9066666666666666\n",
      "\n",
      "Epoch 69/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2714e+02\n",
      "\n",
      "Test on train set: loss= 2.225343704223633 acc= 0.8553739190101624 auc= 0.895470155051661\n",
      "Test on valid set: loss= 5.431032657623291 acc= 0.6600000262260437 auc= 0.8604444444444445\n",
      "\n",
      "Epoch 70/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2904e+02\n",
      "\n",
      "Test on train set: loss= 2.3214194774627686 acc= 0.849870502948761 auc= 0.8918485660678257\n",
      "Test on valid set: loss= 4.320146083831787 acc= 0.7169215083122253 auc= 0.8635555555555557\n",
      "\n",
      "Epoch 71/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.8000e+01\n",
      "\n",
      "Test on train set: loss= 2.429981231689453 acc= 0.8437196612358093 auc= 0.8573105331059011\n",
      "Test on valid set: loss= 6.539472579956055 acc= 0.5618943572044373 auc= 0.8337777777777777\n",
      "\n",
      "Epoch 72/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2822e+02\n",
      "\n",
      "Test on train set: loss= 1.7089349031448364 acc= 0.888475239276886 auc= 0.9042895696558231\n",
      "Test on valid set: loss= 5.674679756164551 acc= 0.6261937618255615 auc= 0.8448888888888888\n",
      "\n",
      "Epoch 73/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6811e+02\n",
      "\n",
      "Test on train set: loss= 1.8810538053512573 acc= 0.8780349493026733 auc= 0.86163698973986\n",
      "Test on valid set: loss= 6.4041032791137695 acc= 0.5999997854232788 auc= 0.8457777777777779\n",
      "\n",
      "Epoch 74/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.7925e+02\n",
      "\n",
      "Test on train set: loss= 2.4248361587524414 acc= 0.8435577750205994 auc= 0.8919246531193069\n",
      "Test on valid set: loss= 5.157791614532471 acc= 0.679999053478241 auc= 0.8406666666666667\n",
      "\n",
      "Epoch 75/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6689e+02\n",
      "\n",
      "Test on train set: loss= 4.844183921813965 acc= 0.6795888543128967 auc= 0.8755271195825756\n",
      "Test on valid set: loss= 7.745962142944336 acc= 0.5125781297683716 auc= 0.8315555555555557\n",
      "\n",
      "Epoch 76/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.7952e+02\n",
      "\n",
      "Test on train set: loss= 2.024534225463867 acc= 0.8709129095077515 auc= 0.8978633930447083\n",
      "Test on valid set: loss= 6.168673038482666 acc= 0.5801146626472473 auc= 0.8191111111111111\n",
      "\n",
      "Epoch 77/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5919e+02\n",
      "\n",
      "Test on train set: loss= 1.732150673866272 acc= 0.8896082639694214 auc= 0.8608972576299718\n",
      "Test on valid set: loss= 5.635207653045654 acc= 0.6398456692695618 auc= 0.8384444444444444\n",
      "\n",
      "Epoch 78/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.2948e+02\n",
      "\n",
      "Test on train set: loss= 2.0475618839263916 acc= 0.8701845407485962 auc= 0.8411054539768539\n",
      "Test on valid set: loss= 6.125019073486328 acc= 0.6198579668998718 auc= 0.7946666666666666\n",
      "\n",
      "Epoch 79/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.9366e+02\n",
      "\n",
      "Test on train set: loss= 1.635174036026001 acc= 0.896082878112793 auc= 0.8825605765846276\n",
      "Test on valid set: loss= 7.284571647644043 acc= 0.5400012731552124 auc= 0.7806666666666666\n",
      "\n",
      "Epoch 80/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8398e+02\n",
      "\n",
      "Test on train set: loss= 1.7849903106689453 acc= 0.8873421549797058 auc= 0.8512771602549005\n",
      "Test on valid set: loss= 5.565276622772217 acc= 0.6400274038314819 auc= 0.8317777777777777\n",
      "\n",
      "Epoch 81/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3334e+02\n",
      "\n",
      "Test on train set: loss= 1.774013638496399 acc= 0.8872612714767456 auc= 0.8905847752020681\n",
      "Test on valid set: loss= 5.621783256530762 acc= 0.6288360357284546 auc= 0.8384444444444444\n",
      "\n",
      "Epoch 82/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6912e+02\n",
      "\n",
      "Test on train set: loss= 1.7896249294281006 acc= 0.8853188753128052 auc= 0.9031994053072434\n",
      "Test on valid set: loss= 4.986489295959473 acc= 0.6775345206260681 auc= 0.8620000000000001\n",
      "\n",
      "Epoch 83/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8387e+02\n",
      "\n",
      "Test on train set: loss= 2.0798423290252686 acc= 0.8631433844566345 auc= 0.9152536717560483\n",
      "Test on valid set: loss= 5.245126247406006 acc= 0.658106803894043 auc= 0.8622222222222223\n",
      "\n",
      "Epoch 84/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5012e+02\n",
      "\n",
      "Test on train set: loss= 1.9494985342025757 acc= 0.8742311596870422 auc= 0.8980423804204539\n",
      "Test on valid set: loss= 6.211337089538574 acc= 0.6002652049064636 auc= 0.8357777777777777\n",
      "\n",
      "Epoch 85/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8993e+02\n",
      "\n",
      "Test on train set: loss= 1.543020248413086 acc= 0.9011816382408142 auc= 0.9209340343864783\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.5999999642372131 auc= 0.8613333333333333\n",
      "\n",
      "Epoch 86/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0328e+02\n",
      "\n",
      "Test on train set: loss= 1.6531187295913696 acc= 0.8955163359642029 auc= 0.865887346616079\n",
      "Test on valid set: loss= 5.480747222900391 acc= 0.6594133973121643 auc= 0.8284444444444444\n",
      "\n",
      "Epoch 87/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.4097e+02\n",
      "\n",
      "Test on train set: loss= 1.7369098663330078 acc= 0.8878277540206909 auc= 0.9037642259316565\n",
      "Test on valid set: loss= 5.858242034912109 acc= 0.6185193657875061 auc= 0.8146666666666667\n",
      "\n",
      "Epoch 88/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.2243e+02\n",
      "\n",
      "Test on train set: loss= 1.64725923538208 acc= 0.8944642543792725 auc= 0.8946978291587915\n",
      "Test on valid set: loss= 6.102176666259766 acc= 0.6200000047683716 auc= 0.836\n",
      "\n",
      "Epoch 89/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5325e+02\n",
      "\n",
      "Test on train set: loss= 1.7923368215560913 acc= 0.8835383653640747 auc= 0.9135383179408805\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8675555555555554\n",
      "\n",
      "Epoch 90/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5617e+02\n",
      "\n",
      "Test on train set: loss= 1.4141156673431396 acc= 0.9101651310920715 auc= 0.8993153172664323\n",
      "Test on valid set: loss= 5.131627082824707 acc= 0.6800000071525574 auc= 0.85\n",
      "\n",
      "Epoch 91/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1948e+02\n",
      "\n",
      "Test on train set: loss= 1.8686890602111816 acc= 0.880705714225769 auc= 0.8768722330477097\n",
      "Test on valid set: loss= 6.235886096954346 acc= 0.5997812151908875 auc= 0.8253333333333334\n",
      "\n",
      "Epoch 92/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3700e+02\n",
      "\n",
      "Test on train set: loss= 1.4597737789154053 acc= 0.9067659378051758 auc= 0.8836790715869058\n",
      "Test on valid set: loss= 5.66389274597168 acc= 0.6400020122528076 auc= 0.828888888888889\n",
      "\n",
      "Epoch 93/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.9985e+02\n",
      "\n",
      "Test on train set: loss= 1.5809077024459839 acc= 0.899482011795044 auc= 0.9007071989237065\n",
      "Test on valid set: loss= 6.058596134185791 acc= 0.600082516670227 auc= 0.8068888888888889\n",
      "\n",
      "Epoch 94/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3563e+02\n",
      "\n",
      "Test on train set: loss= 1.4961591958999634 acc= 0.9044188857078552 auc= 0.8988225098125735\n",
      "Test on valid set: loss= 4.877579212188721 acc= 0.6800117492675781 auc= 0.8791111111111111\n",
      "\n",
      "Epoch 95/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5741e+02\n",
      "\n",
      "Test on train set: loss= 1.536814570426941 acc= 0.9011006951332092 auc= 0.9146472989963049\n",
      "Test on valid set: loss= 6.2252278327941895 acc= 0.600132405757904 auc= 0.829111111111111\n",
      "\n",
      "Epoch 96/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0358e+02\n",
      "\n",
      "Test on train set: loss= 2.0776145458221436 acc= 0.8679184317588806 auc= 0.900236193670783\n",
      "Test on valid set: loss= 4.631990432739258 acc= 0.699741542339325 auc= 0.8622222222222223\n",
      "\n",
      "Epoch 97/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1404e+02\n",
      "\n",
      "Test on train set: loss= 1.5983021259307861 acc= 0.8970540761947632 auc= 0.9004287915084739\n",
      "Test on valid set: loss= 5.726473331451416 acc= 0.64000004529953 auc= 0.828\n",
      "\n",
      "Epoch 98/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.7773e+02\n",
      "\n",
      "Test on train set: loss= 1.8555474281311035 acc= 0.8800582885742188 auc= 0.9001332597699415\n",
      "Test on valid set: loss= 6.231317520141602 acc= 0.5999873280525208 auc= 0.8433333333333334\n",
      "\n",
      "Epoch 99/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3793e+02\n",
      "\n",
      "Test on train set: loss= 1.5337889194488525 acc= 0.9010197520256042 auc= 0.9185780345228658\n",
      "Test on valid set: loss= 7.091961860656738 acc= 0.5600000023841858 auc= 0.8113333333333334\n",
      "\n",
      "Epoch 100/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.3653e+02\n",
      "\n",
      "Test on train set: loss= 1.3132715225219727 acc= 0.915425717830658 auc= 0.91333221838242\n",
      "Test on valid set: loss= 6.261178016662598 acc= 0.6000219583511353 auc= 0.7962222222222222\n",
      "\n",
      "Epoch 101/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6428e+02\n",
      "\n",
      "Test on train set: loss= 1.6385434865951538 acc= 0.8943023681640625 auc= 0.8968886971280716\n",
      "Test on valid set: loss= 7.00706672668457 acc= 0.5470719337463379 auc= 0.7924444444444444\n",
      "\n",
      "Epoch 102/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6538e+02\n",
      "\n",
      "Test on train set: loss= 1.5493197441101074 acc= 0.9019909501075745 auc= 0.8919063212496063\n",
      "Test on valid set: loss= 7.092193603515625 acc= 0.5597695708274841 auc= 0.7902222222222223\n",
      "\n",
      "Epoch 103/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.4930e+02\n",
      "\n",
      "Test on train set: loss= 1.8491261005401611 acc= 0.8836193084716797 auc= 0.8607905000139283\n",
      "Test on valid set: loss= 6.57602071762085 acc= 0.5800319910049438 auc= 0.7882222222222222\n",
      "\n",
      "Epoch 104/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.1134e+02\n",
      "\n",
      "Test on train set: loss= 1.9117780923843384 acc= 0.8784396052360535 auc= 0.9063557147532102\n",
      "Test on valid set: loss= 6.7696003913879395 acc= 0.5799999833106995 auc= 0.8042222222222222\n",
      "\n",
      "Epoch 105/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0826e+02\n",
      "\n",
      "Test on train set: loss= 1.4936158657073975 acc= 0.9053091406822205 auc= 0.8954055687717506\n",
      "Test on valid set: loss= 5.802515983581543 acc= 0.6399986743927002 auc= 0.8342222222222222\n",
      "\n",
      "Epoch 106/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.3810e+02\n",
      "\n",
      "Test on train set: loss= 1.2964191436767578 acc= 0.9180964827537537 auc= 0.9128204700199504\n",
      "Test on valid set: loss= 4.168276786804199 acc= 0.7254732847213745 auc= 0.8751111111111112\n",
      "\n",
      "Epoch 107/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5552e+02\n",
      "\n",
      "Test on train set: loss= 1.4545549154281616 acc= 0.9061993956565857 auc= 0.9134077754468659\n",
      "Test on valid set: loss= 3.5461084842681885 acc= 0.7798728942871094 auc= 0.8775555555555556\n",
      "\n",
      "Epoch 108/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0968e+02\n",
      "\n",
      "Test on train set: loss= 1.5455784797668457 acc= 0.9019100069999695 auc= 0.9100618954684023\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8320000000000001\n",
      "\n",
      "Epoch 109/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1666e+02\n",
      "\n",
      "Test on train set: loss= 1.2354520559310913 acc= 0.9200388193130493 auc= 0.9323807084595431\n",
      "Test on valid set: loss= 5.275968074798584 acc= 0.6600543260574341 auc= 0.8497777777777777\n",
      "\n",
      "Epoch 110/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.7118e+02\n",
      "\n",
      "Test on train set: loss= 1.8742374181747437 acc= 0.881029486656189 auc= 0.8924460737666058\n",
      "Test on valid set: loss= 5.904138088226318 acc= 0.6201242804527283 auc= 0.7986666666666666\n",
      "\n",
      "Epoch 111/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.4318e+02\n",
      "\n",
      "Test on train set: loss= 1.3101578950881958 acc= 0.9162350296974182 auc= 0.9201408322884417\n",
      "Test on valid set: loss= 6.534744739532471 acc= 0.5800016522407532 auc= 0.8037777777777778\n",
      "\n",
      "Epoch 112/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6287e+02\n",
      "\n",
      "Test on train set: loss= 1.7071216106414795 acc= 0.8904176354408264 auc= 0.9149996195763916\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8413333333333334\n",
      "\n",
      "Epoch 113/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1045e+02\n",
      "\n",
      "Test on train set: loss= 1.3402125835418701 acc= 0.9147782325744629 auc= 0.902403515636002\n",
      "Test on valid set: loss= 6.769618988037109 acc= 0.5799808502197266 auc= 0.7915555555555556\n",
      "\n",
      "Epoch 114/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6059e+02\n",
      "\n",
      "Test on train set: loss= 1.7615209817886353 acc= 0.8891226649284363 auc= 0.9153184872771156\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8422222222222222\n",
      "\n",
      "Epoch 115/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -3.7390e+02\n",
      "\n",
      "Test on train set: loss= 1.4752185344696045 acc= 0.9061993956565857 auc= 0.8813521537354202\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8291111111111112\n",
      "\n",
      "Epoch 116/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -4.1277e+02\n",
      "\n",
      "Test on train set: loss= 1.4773781299591064 acc= 0.9070087671279907 auc= 0.8967822765181337\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8388888888888889\n",
      "\n",
      "Epoch 117/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -4.0989e+02\n",
      "\n",
      "Test on train set: loss= 1.4992570877075195 acc= 0.9056329131126404 auc= 0.8673121286710552\n",
      "Test on valid set: loss= 7.091961860656738 acc= 0.5600000619888306 auc= 0.772888888888889\n",
      "\n",
      "Epoch 118/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1049e+02\n",
      "\n",
      "Test on train set: loss= 1.1630034446716309 acc= 0.9257850646972656 auc= 0.936883921493916\n",
      "Test on valid set: loss= 5.003376483917236 acc= 0.6606024503707886 auc= 0.8400000000000001\n",
      "\n",
      "Epoch 119/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -4.7389e+02\n",
      "\n",
      "Test on train set: loss= 1.4467167854309082 acc= 0.9084655046463013 auc= 0.8934320883132166\n",
      "Test on valid set: loss= 5.818259239196777 acc= 0.6290320754051208 auc= 0.8084444444444445\n",
      "\n",
      "Epoch 120/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -4.2164e+02\n",
      "\n",
      "Test on train set: loss= 1.3409074544906616 acc= 0.9145354628562927 auc= 0.8948161064437947\n",
      "Test on valid set: loss= 6.758695125579834 acc= 0.5799999237060547 auc= 0.7771111111111111\n",
      "\n",
      "Epoch 121/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6788e+02\n",
      "\n",
      "Test on train set: loss= 1.5473822355270386 acc= 0.9020718932151794 auc= 0.8842618390901091\n",
      "Test on valid set: loss= 5.8033013343811035 acc= 0.6392284631729126 auc= 0.8173333333333332\n",
      "\n",
      "Epoch 122/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.4319e+02\n",
      "\n",
      "Test on train set: loss= 1.7840030193328857 acc= 0.8876659274101257 auc= 0.8491896122249344\n",
      "Test on valid set: loss= 7.414323806762695 acc= 0.5399999618530273 auc= 0.7508888888888888\n",
      "\n",
      "Epoch 123/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6762e+02\n",
      "\n",
      "Test on train set: loss= 1.5553067922592163 acc= 0.9011006951332092 auc= 0.9083937975778875\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6199994087219238 auc= 0.7957777777777778\n",
      "\n",
      "Epoch 124/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5279e+02\n",
      "\n",
      "Test on train set: loss= 1.3457783460617065 acc= 0.9149401187896729 auc= 0.9100748091789164\n",
      "Test on valid set: loss= 4.8354291915893555 acc= 0.6999994516372681 auc= 0.8528888888888888\n",
      "\n",
      "Epoch 125/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.0761e+02\n",
      "\n",
      "Test on train set: loss= 1.3919785022735596 acc= 0.911864697933197 auc= 0.899495252028484\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6199997663497925 auc= 0.8244444444444443\n",
      "\n",
      "Epoch 126/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 2s - loss: -4.0352e+02\n",
      "\n",
      "Test on train set: loss= 1.0638309717178345 acc= 0.9326642751693726 auc= 0.9162984060317155\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7200000286102295 auc= 0.8522222222222222\n",
      "\n",
      "Epoch 127/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.7598e+02\n",
      "\n",
      "Test on train set: loss= 1.5641239881515503 acc= 0.9015053510665894 auc= 0.8612365077160475\n",
      "Test on valid set: loss= 6.769599437713623 acc= 0.5800000429153442 auc= 0.7762222222222224\n",
      "\n",
      "Epoch 128/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.2772e+02\n",
      "\n",
      "Test on train set: loss= 1.129899263381958 acc= 0.9284558296203613 auc= 0.9174421027559736\n",
      "Test on valid set: loss= 5.620031356811523 acc= 0.621255099773407 auc= 0.8286666666666667\n",
      "\n",
      "Epoch 129/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1299e+02\n",
      "\n",
      "Test on train set: loss= 1.232324481010437 acc= 0.9217384457588196 auc= 0.906785811261947\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8073333333333332\n",
      "\n",
      "Epoch 130/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.0494e+02\n",
      "\n",
      "Test on train set: loss= 1.4807785749435425 acc= 0.9066040515899658 auc= 0.8924763566537239\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8268888888888888\n",
      "\n",
      "Epoch 131/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.2282e+02\n",
      "\n",
      "Test on train set: loss= 1.3204329013824463 acc= 0.9167206287384033 auc= 0.9120928453837749\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000858306885 auc= 0.8286666666666667\n",
      "\n",
      "Epoch 132/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.8556e+02\n",
      "\n",
      "Test on train set: loss= 1.2679219245910645 acc= 0.9202007055282593 auc= 0.8993025494301282\n",
      "Test on valid set: loss= 6.447238922119141 acc= 0.6000000238418579 auc= 0.7946666666666667\n",
      "\n",
      "Epoch 133/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.2827e+02\n",
      "\n",
      "Test on train set: loss= 1.2869441509246826 acc= 0.9182583093643188 auc= 0.916637119875717\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8408888888888889\n",
      "\n",
      "Epoch 134/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.4841e+02\n",
      "\n",
      "Test on train set: loss= 1.2184102535247803 acc= 0.9231951832771301 auc= 0.9201915251423773\n",
      "Test on valid set: loss= 4.513067722320557 acc= 0.7199993133544922 auc= 0.8535555555555556\n",
      "\n",
      "Epoch 135/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5008e+02\n",
      "\n",
      "Test on train set: loss= 1.6660889387130737 acc= 0.8943833112716675 auc= 0.9246944191060867\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8195555555555556\n",
      "\n",
      "Epoch 136/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0528e+02\n",
      "\n",
      "Test on train set: loss= 1.2341734170913696 acc= 0.9198769927024841 auc= 0.9364521958370204\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8197777777777777\n",
      "\n",
      "Epoch 137/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2518e+02\n",
      "\n",
      "Test on train set: loss= 1.6187154054641724 acc= 0.8965684771537781 auc= 0.9107622660512634\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.64000004529953 auc= 0.8184444444444445\n",
      "\n",
      "Epoch 138/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.2657e+02\n",
      "\n",
      "Test on train set: loss= 1.1455817222595215 acc= 0.9263515472412109 auc= 0.9124303014427666\n",
      "Test on valid set: loss= 6.124876022338867 acc= 0.6200000047683716 auc= 0.8166666666666667\n",
      "\n",
      "Epoch 139/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.0588e+02\n",
      "\n",
      "Test on train set: loss= 1.2500265836715698 acc= 0.9181774258613586 auc= 0.9229857529804713\n",
      "Test on valid set: loss= 5.802750110626221 acc= 0.6397656202316284 auc= 0.8175555555555556\n",
      "\n",
      "Epoch 140/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -3.8531e+02\n",
      "\n",
      "Test on train set: loss= 1.3409658670425415 acc= 0.915182888507843 auc= 0.8966692823074573\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399998068809509 auc= 0.8164444444444445\n",
      "\n",
      "Epoch 141/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -3.5561e+02\n",
      "\n",
      "Test on train set: loss= 1.2408010959625244 acc= 0.9209290742874146 auc= 0.9210240029014368\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8173333333333334\n",
      "\n",
      "Epoch 142/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5225e+02\n",
      "\n",
      "Test on train set: loss= 2.0095813274383545 acc= 0.8662188649177551 auc= 0.9239998851289661\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.6000000238418579 auc= 0.8062222222222222\n",
      "\n",
      "Epoch 143/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: -4.3252e+02\n",
      "\n",
      "Test on train set: loss= 1.1609649658203125 acc= 0.9267562031745911 auc= 0.928683544963379\n",
      "Test on valid set: loss= 5.157811164855957 acc= 0.6799789667129517 auc= 0.8295555555555556\n",
      "\n",
      "Epoch 144/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1371e+02\n",
      "\n",
      "Test on train set: loss= 1.2515418529510498 acc= 0.9210100173950195 auc= 0.9063583898337944\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8315555555555555\n",
      "\n",
      "Epoch 145/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.2989e+02\n",
      "\n",
      "Test on train set: loss= 1.154299020767212 acc= 0.926918089389801 auc= 0.9017541663390419\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.808\n",
      "\n",
      "Epoch 146/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.6576e+02\n",
      "\n",
      "Test on train set: loss= 1.1595344543457031 acc= 0.9267562031745911 auc= 0.8883674539717397\n",
      "Test on valid set: loss= 6.124876022338867 acc= 0.6200000047683716 auc= 0.7999999999999999\n",
      "\n",
      "Epoch 147/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.7219e+02\n",
      "\n",
      "Test on train set: loss= 1.0378996133804321 acc= 0.934687614440918 auc= 0.9330050746859915\n",
      "Test on valid set: loss= 4.195699691772461 acc= 0.7355802059173584 auc= 0.8642222222222223\n",
      "\n",
      "Epoch 148/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.3642e+02\n",
      "\n",
      "Test on train set: loss= 1.3537824153900146 acc= 0.9145354628562927 auc= 0.8934739243531032\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.64000004529953 auc= 0.8084444444444445\n",
      "\n",
      "Epoch 149/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.3583e+02\n",
      "\n",
      "Test on train set: loss= 1.4131447076797485 acc= 0.9091129899024963 auc= 0.9375978739176187\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8726666666666667\n",
      "\n",
      "Epoch 150/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1051e+02\n",
      "\n",
      "Test on train set: loss= 1.2450591325759888 acc= 0.9215765595436096 auc= 0.9034684771422681\n",
      "Test on valid set: loss= 5.480156898498535 acc= 0.6599958539009094 auc= 0.8415555555555555\n",
      "\n",
      "Epoch 151/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6360e+02\n",
      "\n",
      "Test on train set: loss= 1.2108166217803955 acc= 0.9241663813591003 auc= 0.8762480795250658\n",
      "Test on valid set: loss= 6.7696003913879395 acc= 0.5800000429153442 auc= 0.7762222222222224\n",
      "\n",
      "Epoch 152/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2871e+02\n",
      "\n",
      "Test on train set: loss= 1.103871464729309 acc= 0.9302363395690918 auc= 0.9275231452925186\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.8088888888888889\n",
      "\n",
      "Epoch 153/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.4606e+02\n",
      "\n",
      "Test on train set: loss= 1.0999068021774292 acc= 0.9305600523948669 auc= 0.9275581874181438\n",
      "Test on valid set: loss= 5.598294258117676 acc= 0.6400544047355652 auc= 0.8202222222222222\n",
      "\n",
      "Epoch 154/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1375e+02\n",
      "\n",
      "Test on train set: loss= 0.8780747056007385 acc= 0.9445613622665405 auc= 0.9319784448576222\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8542222222222222\n",
      "\n",
      "Epoch 155/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.7479e+02\n",
      "\n",
      "Test on train set: loss= 0.812649130821228 acc= 0.9484460949897766 auc= 0.9296543646767128\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.6999999284744263 auc= 0.8411111111111109\n",
      "\n",
      "Epoch 156/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9009e+02\n",
      "\n",
      "Test on train set: loss= 1.019374132156372 acc= 0.9352541565895081 auc= 0.9434349683409458\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8313333333333333\n",
      "\n",
      "Epoch 157/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.9492e+02\n",
      "\n",
      "Test on train set: loss= 0.9867208003997803 acc= 0.9378439784049988 auc= 0.9383121046666982\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8544444444444445\n",
      "\n",
      "Epoch 158/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.5226e+02\n",
      "\n",
      "Test on train set: loss= 0.9269199967384338 acc= 0.9414859414100647 auc= 0.9259209514045141\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8186666666666665\n",
      "\n",
      "Epoch 159/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.9497e+02\n",
      "\n",
      "Test on train set: loss= 0.926247239112854 acc= 0.9414049983024597 auc= 0.9419314823376336\n",
      "Test on valid set: loss= 5.039059638977051 acc= 0.6800007820129395 auc= 0.8422222222222222\n",
      "\n",
      "Epoch 160/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9659e+02\n",
      "\n",
      "Test on train set: loss= 0.899946391582489 acc= 0.9414859414100647 auc= 0.948249435855806\n",
      "Test on valid set: loss= 4.513067245483398 acc= 0.7199996709823608 auc= 0.8431111111111111\n",
      "\n",
      "Epoch 161/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.3338e+02\n",
      "\n",
      "Test on train set: loss= 1.0979466438293457 acc= 0.931207537651062 auc= 0.9133731071077535\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.8068888888888889\n",
      "\n",
      "Epoch 162/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: -4.0141e+02\n",
      "\n",
      "Test on train set: loss= 1.2154275178909302 acc= 0.9219002723693848 auc= 0.9078575644429682\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.8073333333333332\n",
      "\n",
      "Epoch 163/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0383e+02\n",
      "\n",
      "Test on train set: loss= 1.257438063621521 acc= 0.9207672476768494 auc= 0.9394618005287244\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8195555555555556\n",
      "\n",
      "Epoch 164/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0255e+02\n",
      "\n",
      "Test on train set: loss= 1.0821669101715088 acc= 0.9308837652206421 auc= 0.9241907582434228\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.699999988079071 auc= 0.8328888888888889\n",
      "\n",
      "Epoch 165/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.3465e+02\n",
      "\n",
      "Test on train set: loss= 1.18743097782135 acc= 0.9248138666152954 auc= 0.9085793211557851\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.7995555555555555\n",
      "\n",
      "Epoch 166/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.8358e+02\n",
      "\n",
      "Test on train set: loss= 1.0499626398086548 acc= 0.9336354732513428 auc= 0.9084630306087998\n",
      "Test on valid set: loss= 6.49604606628418 acc= 0.581742525100708 auc= 0.7931111111111112\n",
      "\n",
      "Epoch 167/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0630e+02\n",
      "\n",
      "Test on train set: loss= 1.1705487966537476 acc= 0.9258659482002258 auc= 0.9027863716536902\n",
      "Test on valid set: loss= 4.820987224578857 acc= 0.6999998688697815 auc= 0.8626666666666667\n",
      "\n",
      "Epoch 168/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.4246e+02\n",
      "\n",
      "Test on train set: loss= 1.3043628931045532 acc= 0.9168015718460083 auc= 0.8892454087505932\n",
      "Test on valid set: loss= 6.7696003913879395 acc= 0.5800000429153442 auc= 0.7864444444444445\n",
      "\n",
      "Epoch 169/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1591e+02\n",
      "\n",
      "Test on train set: loss= 1.4560532569885254 acc= 0.9067659378051758 auc= 0.9355665127431658\n",
      "Test on valid set: loss= 5.066522598266602 acc= 0.6800001859664917 auc= 0.8315555555555555\n",
      "\n",
      "Epoch 170/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.2564e+02\n",
      "\n",
      "Test on train set: loss= 1.0216723680496216 acc= 0.9354159832000732 auc= 0.9062222209681448\n",
      "Test on valid set: loss= 7.378654956817627 acc= 0.5399999618530273 auc= 0.774\n",
      "\n",
      "Epoch 171/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1975e+02\n",
      "\n",
      "Test on train set: loss= 0.9868277907371521 acc= 0.9378439784049988 auc= 0.9389900138209557\n",
      "Test on valid set: loss= 6.449771881103516 acc= 0.5976203083992004 auc= 0.7948888888888889\n",
      "\n",
      "Epoch 172/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.8889e+02\n",
      "\n",
      "Test on train set: loss= 1.2380328178405762 acc= 0.9215765595436096 auc= 0.9023432868347696\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8008888888888889\n",
      "\n",
      "Epoch 173/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.2450e+02\n",
      "\n",
      "Test on train set: loss= 0.9222846627235413 acc= 0.94205242395401 auc= 0.9340328176096536\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8104444444444445\n",
      "\n",
      "Epoch 174/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.4229e+02\n",
      "\n",
      "Test on train set: loss= 1.0348443984985352 acc= 0.934525728225708 auc= 0.9090874930867694\n",
      "Test on valid set: loss= 5.802526950836182 acc= 0.6399871110916138 auc= 0.8300000000000001\n",
      "\n",
      "Epoch 175/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9209e+02\n",
      "\n",
      "Test on train set: loss= 1.190057396888733 acc= 0.9250566363334656 auc= 0.913172872629197\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.7984444444444444\n",
      "\n",
      "Epoch 176/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.7780e+02\n",
      "\n",
      "Test on train set: loss= 1.0348222255706787 acc= 0.934525728225708 auc= 0.9166851175052212\n",
      "Test on valid set: loss= 6.1177778244018555 acc= 0.6000473499298096 auc= 0.7993333333333333\n",
      "\n",
      "Epoch 177/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: -5.3332e+02\n",
      "\n",
      "Test on train set: loss= 1.1154001951217651 acc= 0.9278892874717712 auc= 0.9484402064238301\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8328888888888889\n",
      "\n",
      "Epoch 178/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9685e+02\n",
      "\n",
      "Test on train set: loss= 0.942474365234375 acc= 0.9406765699386597 auc= 0.9291413093850462\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.699999988079071 auc= 0.8333333333333333\n",
      "\n",
      "Epoch 179/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0421e+02\n",
      "\n",
      "Test on train set: loss= 1.1693824529647827 acc= 0.9248138666152954 auc= 0.9403077012330945\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8651111111111109\n",
      "\n",
      "Epoch 180/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: -4.4197e+02\n",
      "\n",
      "Test on train set: loss= 0.9934150576591492 acc= 0.9368727803230286 auc= 0.9452461956945756\n",
      "Test on valid set: loss= 5.367331504821777 acc= 0.6402139067649841 auc= 0.8202222222222224\n",
      "\n",
      "Epoch 181/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9777e+02\n",
      "\n",
      "Test on train set: loss= 0.7416650652885437 acc= 0.9531401991844177 auc= 0.9277325996633063\n",
      "Test on valid set: loss= 6.663717269897461 acc= 0.5800003409385681 auc= 0.7873333333333333\n",
      "\n",
      "Epoch 182/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.7966e+02\n",
      "\n",
      "Test on train set: loss= 0.6810054779052734 acc= 0.9569439888000488 auc= 0.9496334267479629\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8422222222222222\n",
      "\n",
      "Epoch 183/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.1189e+02\n",
      "\n",
      "Test on train set: loss= 1.1453131437301636 acc= 0.9279702305793762 auc= 0.9397834283999715\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8226666666666667\n",
      "\n",
      "Epoch 184/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.2217e+02\n",
      "\n",
      "Test on train set: loss= 0.9862422347068787 acc= 0.9378439784049988 auc= 0.9237619872215849\n",
      "Test on valid set: loss= 5.802553653717041 acc= 0.6399610638618469 auc= 0.8088888888888889\n",
      "\n",
      "Epoch 185/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.5238e+02\n",
      "\n",
      "Test on train set: loss= 0.9628210663795471 acc= 0.9393007159233093 auc= 0.9460668482353574\n",
      "Test on valid set: loss= 5.433414459228516 acc= 0.6600000262260437 auc= 0.8380000000000001\n",
      "\n",
      "Epoch 186/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9488e+02\n",
      "\n",
      "Test on train set: loss= 1.3316370248794556 acc= 0.9145354628562927 auc= 0.9222789515395041\n",
      "Test on valid set: loss= 5.8025970458984375 acc= 0.6399178504943848 auc= 0.7982222222222222\n",
      "\n",
      "Epoch 187/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6191e+02\n",
      "\n",
      "Test on train set: loss= 1.2207483053207397 acc= 0.9210909605026245 auc= 0.9081977312690173\n",
      "Test on valid set: loss= 7.091961860656738 acc= 0.5600000023841858 auc= 0.7664444444444444\n",
      "\n",
      "Epoch 188/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6229e+02\n",
      "\n",
      "Test on train set: loss= 0.8799849152565002 acc= 0.9431045651435852 auc= 0.9401463478787665\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8237777777777777\n",
      "\n",
      "Epoch 189/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.4855e+02\n",
      "\n",
      "Test on train set: loss= 0.9582012891769409 acc= 0.9393816590309143 auc= 0.9398132593945382\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.6000000238418579 auc= 0.7877777777777778\n",
      "\n",
      "Epoch 190/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.1888e+02\n",
      "\n",
      "Test on train set: loss= 1.2394530773162842 acc= 0.9205244183540344 auc= 0.9348453370844367\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8115555555555556\n",
      "\n",
      "Epoch 191/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6978e+02\n",
      "\n",
      "Test on train set: loss= 1.0006186962127686 acc= 0.9368727803230286 auc= 0.9287745842656288\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.807111111111111\n",
      "\n",
      "Epoch 192/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.7889e+02\n",
      "\n",
      "Test on train set: loss= 0.9795336127281189 acc= 0.9377630352973938 auc= 0.9224818988530199\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.699999988079071 auc= 0.8431111111111111\n",
      "\n",
      "Epoch 193/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9464e+02\n",
      "\n",
      "Test on train set: loss= 1.4377690553665161 acc= 0.9090320467948914 auc= 0.9016220823071567\n",
      "Test on valid set: loss= 5.702517032623291 acc= 0.6201573014259338 auc= 0.8391111111111111\n",
      "\n",
      "Epoch 194/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9852e+02\n",
      "\n",
      "Test on train set: loss= 1.042754888534546 acc= 0.9337164163589478 auc= 0.9424233450378738\n",
      "Test on valid set: loss= 4.957780838012695 acc= 0.6800440549850464 auc= 0.850888888888889\n",
      "\n",
      "Epoch 195/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.0398e+02\n",
      "\n",
      "Test on train set: loss= 0.788454532623291 acc= 0.9506312608718872 auc= 0.9444292026821686\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.699999988079071 auc= 0.8426666666666668\n",
      "\n",
      "Epoch 196/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.3356e+02\n",
      "\n",
      "Test on train set: loss= 0.8878152966499329 acc= 0.9441567063331604 auc= 0.9421580331327265\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 197/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.9755e+02\n",
      "\n",
      "Test on train set: loss= 1.035501480102539 acc= 0.9348494410514832 auc= 0.9426064212022242\n",
      "Test on valid set: loss= 4.482110977172852 acc= 0.7199999690055847 auc= 0.8546666666666667\n",
      "\n",
      "Epoch 198/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.8360e+02\n",
      "\n",
      "Test on train set: loss= 0.7158070206642151 acc= 0.9550015926361084 auc= 0.9379712812574132\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8304444444444444\n",
      "\n",
      "Epoch 199/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.6761e+02\n",
      "\n",
      "Test on train set: loss= 0.925135612487793 acc= 0.9416477680206299 auc= 0.9350592640140833\n",
      "Test on valid set: loss= 6.447238922119141 acc= 0.6000000238418579 auc= 0.7866666666666666\n",
      "\n",
      "Epoch 200/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.8562e+02\n",
      "\n",
      "Test on train set: loss= 0.8280603289604187 acc= 0.9480414390563965 auc= 0.9542820803519568\n",
      "Test on valid set: loss= 4.908198356628418 acc= 0.6803668737411499 auc= 0.842888888888889\n",
      "\n",
      "Epoch 201/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: -7.0494e+02\n",
      "\n",
      "Test on train set: loss= 0.5216416716575623 acc= 0.9668177366256714 auc= 0.9651665096452146\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.82\n",
      "\n",
      "Epoch 202/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.9403e+02\n",
      "\n",
      "Test on train set: loss= 0.4658889174461365 acc= 0.9703787565231323 auc= 0.9696411436559952\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8220000000000001\n",
      "\n",
      "Epoch 203/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.7188e+02\n",
      "\n",
      "Test on train set: loss= 0.43818962574005127 acc= 0.9725639224052429 auc= 0.972428368871571\n",
      "Test on valid set: loss= 5.504678249359131 acc= 0.6458675861358643 auc= 0.810888888888889\n",
      "\n",
      "Epoch 204/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.5444e+02\n",
      "\n",
      "Test on train set: loss= 0.431806355714798 acc= 0.9725639224052429 auc= 0.9706336666489456\n",
      "Test on valid set: loss= 4.895461559295654 acc= 0.6809940934181213 auc= 0.8406666666666667\n",
      "\n",
      "Epoch 205/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.9480e+02\n",
      "\n",
      "Test on train set: loss= 0.4066079258918762 acc= 0.9736970067024231 auc= 0.9716616616010333\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.6999999284744263 auc= 0.8333333333333334\n",
      "\n",
      "Epoch 206/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.8676e+02\n",
      "\n",
      "Test on train set: loss= 0.3893287479877472 acc= 0.9750728607177734 auc= 0.975259174015877\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8106666666666668\n",
      "\n",
      "Epoch 207/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.3163e+02\n",
      "\n",
      "Test on train set: loss= 0.38957586884498596 acc= 0.9752346873283386 auc= 0.9761410463731691\n",
      "Test on valid set: loss= 5.637368202209473 acc= 0.6400076746940613 auc= 0.8111111111111112\n",
      "\n",
      "Epoch 208/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -5.8278e+02\n",
      "\n",
      "Test on train set: loss= 0.3565312325954437 acc= 0.9775007963180542 auc= 0.9781126755039825\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8197777777777778\n",
      "\n",
      "Epoch 209/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1332e+02\n",
      "\n",
      "Test on train set: loss= 0.36437320709228516 acc= 0.976610541343689 auc= 0.976687628108192\n",
      "Test on valid set: loss= 5.1577935218811035 acc= 0.6799970269203186 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 210/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.3001e+02\n",
      "\n",
      "Test on train set: loss= 0.3377423882484436 acc= 0.9784719944000244 auc= 0.9783352156907593\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8222222222222223\n",
      "\n",
      "Epoch 211/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1725e+02\n",
      "\n",
      "Test on train set: loss= 0.31347352266311646 acc= 0.9799287915229797 auc= 0.9772362698370245\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8102222222222222\n",
      "\n",
      "Epoch 212/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2360e+02\n",
      "\n",
      "Test on train set: loss= 0.3098929524421692 acc= 0.9796859622001648 auc= 0.9797188520707405\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8122222222222222\n",
      "\n",
      "Epoch 213/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.3381e+02\n",
      "\n",
      "Test on train set: loss= 0.3132602572441101 acc= 0.9797669053077698 auc= 0.9789592283893859\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8184444444444445\n",
      "\n",
      "Epoch 214/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2233e+02\n",
      "\n",
      "Test on train set: loss= 0.30432575941085815 acc= 0.9804143905639648 auc= 0.9815121088918024\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8117777777777778\n",
      "\n",
      "Epoch 215/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2995e+02\n",
      "\n",
      "Test on train set: loss= 0.3031211793422699 acc= 0.98073810338974 auc= 0.98074676268561\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8231111111111111\n",
      "\n",
      "Epoch 216/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.3998e+02\n",
      "\n",
      "Test on train set: loss= 0.29517871141433716 acc= 0.98089998960495 auc= 0.9813713616260473\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8222222222222222\n",
      "\n",
      "Epoch 217/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2195e+02\n",
      "\n",
      "Test on train set: loss= 0.26728010177612305 acc= 0.9825186133384705 auc= 0.982801265341388\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 218/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2917e+02\n",
      "\n",
      "Test on train set: loss= 0.253681480884552 acc= 0.9838944673538208 auc= 0.9833206988788383\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8224444444444445\n",
      "\n",
      "Epoch 219/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1073e+02\n",
      "\n",
      "Test on train set: loss= 0.23741529881954193 acc= 0.9846228361129761 auc= 0.9821166137576158\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8213333333333332\n",
      "\n",
      "Epoch 220/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 5s - loss: -6.2110e+02\n",
      "\n",
      "Test on train set: loss= 0.2533850371837616 acc= 0.9834898114204407 auc= 0.9816392815552495\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 221/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1405e+02\n",
      "\n",
      "Test on train set: loss= 0.25366076827049255 acc= 0.9838135242462158 auc= 0.9838842111781926\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 222/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.4544e+02\n",
      "\n",
      "Test on train set: loss= 0.24230900406837463 acc= 0.984137237071991 auc= 0.9828018786298875\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8217777777777778\n",
      "\n",
      "Epoch 223/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1693e+02\n",
      "\n",
      "Test on train set: loss= 0.24830301105976105 acc= 0.9838944673538208 auc= 0.9855146458819879\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8195555555555556\n",
      "\n",
      "Epoch 224/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.0620e+02\n",
      "\n",
      "Test on train set: loss= 0.2488054633140564 acc= 0.9835707545280457 auc= 0.9853873646707527\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 225/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1223e+02\n",
      "\n",
      "Test on train set: loss= 0.259110689163208 acc= 0.9829232692718506 auc= 0.9837245251437252\n",
      "Test on valid set: loss= 5.158583164215088 acc= 0.6792227625846863 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 226/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2959e+02\n",
      "\n",
      "Test on train set: loss= 0.22138994932174683 acc= 0.9855130910873413 auc= 0.9832769402258889\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 227/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.2801e+02\n",
      "\n",
      "Test on train set: loss= 0.24003538489341736 acc= 0.984703779220581 auc= 0.981942741064144\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8188888888888888\n",
      "\n",
      "Epoch 228/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.5737e+02\n",
      "\n",
      "Test on train set: loss= 0.21279819309711456 acc= 0.9863224625587463 auc= 0.9827875596737788\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8293333333333333\n",
      "\n",
      "Epoch 229/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.7837e+02\n",
      "\n",
      "Test on train set: loss= 0.19830581545829773 acc= 0.9868080019950867 auc= 0.9853105322856475\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8211111111111112\n",
      "\n",
      "Epoch 230/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.6459e+02\n",
      "\n",
      "Test on train set: loss= 0.2080337405204773 acc= 0.9867271184921265 auc= 0.9828840580650546\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.82\n",
      "\n",
      "Epoch 231/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.5437e+02\n",
      "\n",
      "Test on train set: loss= 0.24921570718288422 acc= 0.984218180179596 auc= 0.9821397526715536\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8202222222222222\n",
      "\n",
      "Epoch 232/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.4376e+02\n",
      "\n",
      "Test on train set: loss= 0.24971725046634674 acc= 0.9836516380310059 auc= 0.9843093995599228\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8233333333333335\n",
      "\n",
      "Epoch 233/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -7.1171e+02\n",
      "\n",
      "Test on train set: loss= 0.2648332417011261 acc= 0.9818711280822754 auc= 0.9835352640339389\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8111111111111111\n",
      "\n",
      "Epoch 234/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.8683e+02\n",
      "\n",
      "Test on train set: loss= 0.23395198583602905 acc= 0.984784722328186 auc= 0.986806172816571\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8202222222222224\n",
      "\n",
      "Epoch 235/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.8453e+02\n",
      "\n",
      "Test on train set: loss= 0.19844870269298553 acc= 0.9874554872512817 auc= 0.9827672476567404\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 236/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 6s - loss: -6.9865e+02\n",
      "\n",
      "Test on train set: loss= 0.20362837612628937 acc= 0.9869698882102966 auc= 0.9832315574441457\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8231111111111111\n",
      "\n",
      "Epoch 237/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 6s - loss: -6.8914e+02\n",
      "\n",
      "Test on train set: loss= 0.19360561668872833 acc= 0.9876982569694519 auc= 0.9849233221572448\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8220000000000001\n",
      "\n",
      "Epoch 238/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: -6.7316e+02\n",
      "\n",
      "Test on train set: loss= 0.18285834789276123 acc= 0.988345742225647 auc= 0.983461380504626\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8222222222222223\n",
      "\n",
      "Epoch 239/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.6642e+02\n",
      "\n",
      "Test on train set: loss= 0.18532328307628632 acc= 0.988183856010437 auc= 0.9854680274228766\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8222222222222223\n",
      "\n",
      "Epoch 240/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 6s - loss: -6.7744e+02\n",
      "\n",
      "Test on train set: loss= 0.18661901354789734 acc= 0.9877792000770569 auc= 0.9847568867780664\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8240000000000001\n",
      "\n",
      "Epoch 241/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.8269e+02\n",
      "\n",
      "Test on train set: loss= 0.20306840538978577 acc= 0.9866461753845215 auc= 0.9856421337799661\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8240000000000001\n",
      "\n",
      "Epoch 242/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 4s - loss: -6.8063e+02\n",
      "\n",
      "Test on train set: loss= 0.18839509785175323 acc= 0.9876982569694519 auc= 0.9856079104234416\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444445\n",
      "\n",
      "Epoch 243/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.7008e+02\n",
      "\n",
      "Test on train set: loss= 0.1919465959072113 acc= 0.9874554872512817 auc= 0.9867552065263876\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8233333333333335\n",
      "\n",
      "Epoch 244/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.7589e+02\n",
      "\n",
      "Test on train set: loss= 0.1915104240179062 acc= 0.9872936010360718 auc= 0.9864806512906845\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8208888888888888\n",
      "\n",
      "Epoch 245/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.6151e+02\n",
      "\n",
      "Test on train set: loss= 0.16765892505645752 acc= 0.9889122843742371 auc= 0.9875076553608381\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 246/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.5961e+02\n",
      "\n",
      "Test on train set: loss= 0.17226217687129974 acc= 0.9886694550514221 auc= 0.984479978766655\n",
      "Test on valid set: loss= 4.952783107757568 acc= 0.6800565719604492 auc= 0.8333333333333334\n",
      "\n",
      "Epoch 247/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.6125e+02\n",
      "\n",
      "Test on train set: loss= 0.18050876259803772 acc= 0.9881029725074768 auc= 0.9858878364808052\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8217777777777778\n",
      "\n",
      "Epoch 248/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.1190e+02\n",
      "\n",
      "Test on train set: loss= 0.1893850713968277 acc= 0.9879410862922668 auc= 0.9869116120958614\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8206666666666667\n",
      "\n",
      "Epoch 249/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.3829e+02\n",
      "\n",
      "Test on train set: loss= 0.18457865715026855 acc= 0.9877792000770569 auc= 0.9865294615103147\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 250/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -6.5207e+02\n",
      "\n",
      "Test on train set: loss= 0.17890070378780365 acc= 0.988345742225647 auc= 0.9871142929001768\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 251/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5705e+02\n",
      "\n",
      "Test on train set: loss= 0.19445644319057465 acc= 0.9875364303588867 auc= 0.9855621612263636\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.820888888888889\n",
      "\n",
      "Epoch 252/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6523e+02\n",
      "\n",
      "Test on train set: loss= 0.17788560688495636 acc= 0.9886694550514221 auc= 0.9846823029504526\n",
      "Test on valid set: loss= 5.1917877197265625 acc= 0.6636541485786438 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 253/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6835e+02\n",
      "\n",
      "Test on train set: loss= 0.17839013040065765 acc= 0.988426685333252 auc= 0.9842101139878974\n",
      "Test on valid set: loss= 5.168834686279297 acc= 0.6715134382247925 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 254/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5527e+02\n",
      "\n",
      "Test on train set: loss= 0.17479261755943298 acc= 0.9887503981590271 auc= 0.9853510151497767\n",
      "Test on valid set: loss= 5.1767401695251465 acc= 0.6677543520927429 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 255/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5176e+02\n",
      "\n",
      "Test on train set: loss= 0.17321057617664337 acc= 0.9888313412666321 auc= 0.9850091510964163\n",
      "Test on valid set: loss= 5.397075176239014 acc= 0.6600000858306885 auc= 0.821111111111111\n",
      "\n",
      "Epoch 256/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6024e+02\n",
      "\n",
      "Test on train set: loss= 0.1709894835948944 acc= 0.9891550540924072 auc= 0.9868922121945356\n",
      "Test on valid set: loss= 5.157924175262451 acc= 0.6798667907714844 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 257/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 2s - loss: -6.5379e+02\n",
      "\n",
      "Test on train set: loss= 0.16726413369178772 acc= 0.9891550540924072 auc= 0.9857949174655871\n",
      "Test on valid set: loss= 5.196846961975098 acc= 0.6628373861312866 auc= 0.821111111111111\n",
      "\n",
      "Epoch 258/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5617e+02\n",
      "\n",
      "Test on train set: loss= 0.18271048367023468 acc= 0.9877792000770569 auc= 0.9856795428438077\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8213333333333332\n",
      "\n",
      "Epoch 259/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6660e+02\n",
      "\n",
      "Test on train set: loss= 0.18081584572792053 acc= 0.988345742225647 auc= 0.9851424002498801\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 260/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6315e+02\n",
      "\n",
      "Test on train set: loss= 0.17021147906780243 acc= 0.9890741109848022 auc= 0.9858463744529468\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 261/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6915e+02\n",
      "\n",
      "Test on train set: loss= 0.16844859719276428 acc= 0.9892359972000122 auc= 0.9848283773449404\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 262/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6660e+02\n",
      "\n",
      "Test on train set: loss= 0.1975918859243393 acc= 0.9870508313179016 auc= 0.9868976102034834\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.821111111111111\n",
      "\n",
      "Epoch 263/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7728e+02\n",
      "\n",
      "Test on train set: loss= 0.1687387377023697 acc= 0.9894787669181824 auc= 0.9856393030995936\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8226666666666667\n",
      "\n",
      "Epoch 264/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6768e+02\n",
      "\n",
      "Test on train set: loss= 0.18440277874469757 acc= 0.9880220293998718 auc= 0.9872554365695085\n",
      "Test on valid set: loss= 5.157915115356445 acc= 0.6798759698867798 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 265/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6766e+02\n",
      "\n",
      "Test on train set: loss= 0.19057123363018036 acc= 0.9876173734664917 auc= 0.9868263960111466\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.821111111111111\n",
      "\n",
      "Epoch 266/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5686e+02\n",
      "\n",
      "Test on train set: loss= 0.16965122520923615 acc= 0.9891550540924072 auc= 0.9867650455454046\n",
      "Test on valid set: loss= 5.242610931396484 acc= 0.6602878570556641 auc= 0.8226666666666667\n",
      "\n",
      "Epoch 267/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6066e+02\n",
      "\n",
      "Test on train set: loss= 0.17867523431777954 acc= 0.9885076284408569 auc= 0.9884597243311781\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8222222222222222\n",
      "\n",
      "Epoch 268/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6497e+02\n",
      "\n",
      "Test on train set: loss= 0.17038555443286896 acc= 0.9892359972000122 auc= 0.9859206007935365\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 269/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5464e+02\n",
      "\n",
      "Test on train set: loss= 0.17405906319618225 acc= 0.9886694550514221 auc= 0.9854389358912142\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 270/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5197e+02\n",
      "\n",
      "Test on train set: loss= 0.1575208604335785 acc= 0.9897215962409973 auc= 0.9869583334553749\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 271/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5906e+02\n",
      "\n",
      "Test on train set: loss= 0.15304729342460632 acc= 0.9899643659591675 auc= 0.9876085939073898\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 272/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.5939e+02\n",
      "\n",
      "Test on train set: loss= 0.19348368048667908 acc= 0.9872936010360718 auc= 0.9862163592708418\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8213333333333332\n",
      "\n",
      "Epoch 273/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6085e+02\n",
      "\n",
      "Test on train set: loss= 0.2046975940465927 acc= 0.9867271184921265 auc= 0.9870227244382841\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8206666666666665\n",
      "\n",
      "Epoch 274/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6509e+02\n",
      "\n",
      "Test on train set: loss= 0.16738207638263702 acc= 0.9891550540924072 auc= 0.9872944894499422\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8226666666666667\n",
      "\n",
      "Epoch 275/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6748e+02\n",
      "\n",
      "Test on train set: loss= 0.1586529016494751 acc= 0.9895597100257874 auc= 0.9876025650976015\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8124444444444444\n",
      "\n",
      "Epoch 276/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6734e+02\n",
      "\n",
      "Test on train set: loss= 0.1708095818758011 acc= 0.9888313412666321 auc= 0.988326120696778\n",
      "Test on valid set: loss= 5.163968086242676 acc= 0.6746854782104492 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 277/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7181e+02\n",
      "\n",
      "Test on train set: loss= 0.18760372698307037 acc= 0.9875364303588867 auc= 0.9885667814397585\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8222222222222222\n",
      "\n",
      "Epoch 278/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6940e+02\n",
      "\n",
      "Test on train set: loss= 0.17326676845550537 acc= 0.9887503981590271 auc= 0.9876308535141771\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.821111111111111\n",
      "\n",
      "Epoch 279/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6989e+02\n",
      "\n",
      "Test on train set: loss= 0.18315982818603516 acc= 0.9880220293998718 auc= 0.9872263581943959\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.82\n",
      "\n",
      "Epoch 280/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6790e+02\n",
      "\n",
      "Test on train set: loss= 0.17192035913467407 acc= 0.9888313412666321 auc= 0.9873214469081697\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8097777777777777\n",
      "\n",
      "Epoch 281/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6967e+02\n",
      "\n",
      "Test on train set: loss= 0.16645395755767822 acc= 0.9891550540924072 auc= 0.9874516984104786\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.821111111111111\n",
      "\n",
      "Epoch 282/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6864e+02\n",
      "\n",
      "Test on train set: loss= 0.16715320944786072 acc= 0.9890741109848022 auc= 0.987587281040313\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 283/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6991e+02\n",
      "\n",
      "Test on train set: loss= 0.1717921942472458 acc= 0.9890741109848022 auc= 0.9867243678673244\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8202222222222222\n",
      "\n",
      "Epoch 284/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6489e+02\n",
      "\n",
      "Test on train set: loss= 0.16361360251903534 acc= 0.9893169403076172 auc= 0.988402934188513\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 285/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6864e+02\n",
      "\n",
      "Test on train set: loss= 0.161839097738266 acc= 0.9894787669181824 auc= 0.9858908407152264\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8226666666666667\n",
      "\n",
      "Epoch 286/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6173e+02\n",
      "\n",
      "Test on train set: loss= 0.15913106501102448 acc= 0.9897215962409973 auc= 0.9869816721478332\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 287/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6820e+02\n",
      "\n",
      "Test on train set: loss= 0.17754478752613068 acc= 0.988426685333252 auc= 0.9880953013784974\n",
      "Test on valid set: loss= 5.295714855194092 acc= 0.6600202322006226 auc= 0.8224444444444444\n",
      "\n",
      "Epoch 288/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7373e+02\n",
      "\n",
      "Test on train set: loss= 0.1786097288131714 acc= 0.988426685333252 auc= 0.9855751875688362\n",
      "Test on valid set: loss= 5.158175468444824 acc= 0.6796185970306396 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 289/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7338e+02\n",
      "\n",
      "Test on train set: loss= 0.16181886196136475 acc= 0.9895597100257874 auc= 0.9868912443594917\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 290/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6029e+02\n",
      "\n",
      "Test on train set: loss= 0.1606040894985199 acc= 0.9897215962409973 auc= 0.9877890893751946\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 291/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.6828e+02\n",
      "\n",
      "Test on train set: loss= 0.1664353460073471 acc= 0.9893169403076172 auc= 0.9866606170023211\n",
      "Test on valid set: loss= 5.264650344848633 acc= 0.6600955724716187 auc= 0.8222222222222223\n",
      "\n",
      "Epoch 292/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7428e+02\n",
      "\n",
      "Test on train set: loss= 0.17723222076892853 acc= 0.9885076284408569 auc= 0.9863472558362274\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8099999999999999\n",
      "\n",
      "Epoch 293/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7324e+02\n",
      "\n",
      "Test on train set: loss= 0.18188340961933136 acc= 0.988264799118042 auc= 0.9869280903969576\n",
      "Test on valid set: loss= 5.482996940612793 acc= 0.6573482751846313 auc= 0.821111111111111\n",
      "\n",
      "Epoch 294/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.7533e+02\n",
      "\n",
      "Test on train set: loss= 0.16281354427337646 acc= 0.9893978834152222 auc= 0.9838910681323776\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 295/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: -6.7779e+02\n",
      "\n",
      "Test on train set: loss= 0.1692800521850586 acc= 0.9888313412666321 auc= 0.9881846932071123\n",
      "Test on valid set: loss= 5.788511753082275 acc= 0.6399999856948853 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 296/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 5s - loss: -6.8016e+02\n",
      "\n",
      "Test on train set: loss= 0.1671541929244995 acc= 0.9891550540924072 auc= 0.9879993134601508\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8095555555555555\n",
      "\n",
      "Epoch 297/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.9746e+02\n",
      "\n",
      "Test on train set: loss= 0.16893035173416138 acc= 0.9890741109848022 auc= 0.9880812945426225\n",
      "Test on valid set: loss= 5.4241557121276855 acc= 0.6600000262260437 auc= 0.8231111111111111\n",
      "\n",
      "Epoch 298/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -6.8359e+02\n",
      "\n",
      "Test on train set: loss= 0.16731251776218414 acc= 0.9891550540924072 auc= 0.9869426259487873\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.82\n",
      "\n",
      "Epoch 299/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 6s - loss: -6.6547e+02\n",
      "\n",
      "Test on train set: loss= 0.15741263329982758 acc= 0.9898834824562073 auc= 0.9854289038015714\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 300/300\n",
      "\n",
      "Enhancement\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 6s - loss: -6.7082e+02\n",
      "\n",
      "Test on train set: loss= 0.15151919424533844 acc= 0.9902071952819824 auc= 0.9864158418601573\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8202222222222222\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "encoding_matrix = tf.Variable(tf.eye(10), trainable=False)\n",
    "trainGen = train_generator(epochs, batch_size, encoding_matrix)\n",
    "model.set_weights(pretrainedWeights)\n",
    "model.compile(optimizer=copy.deepcopy(optimizer), loss = loss_fn)\n",
    "\n",
    "metric_idx = 1\n",
    "trainMetrics = (softConfusionMatrix_train[metric_idx], \n",
    "                confusionMatrix_train[metric_idx],loss_train[metric_idx], \n",
    "                acc_train[metric_idx], auc_train[metric_idx])\n",
    "\n",
    "validMetrics = (softConfusionMatrix_valid[metric_idx], \n",
    "                loss_valid[metric_idx], acc_valid[metric_idx], auc_valid[metric_idx])\n",
    "\n",
    "adjust_lr = AdjustLR(\n",
    "      schedule = lr_schedule,\n",
    "      base_learning_rate = lr,\n",
    "  )\n",
    "\n",
    "uemgm = UpdateEncodingMatrixAndGetMetrics_EEC(beginEncodingEpoch, endEncodingEpoch,  \n",
    "                                               codingEnhancementRate, mu,\n",
    "                                               train_x_no_valid, train_y_no_valid,\n",
    "                                               valid_x, valid_y, trainMetrics, \n",
    "                                               validMetrics, 'Enhancement')\n",
    "                        \n",
    "_ = model.fit(trainGen, \n",
    "              initial_epoch = beginEncodingEpoch, \n",
    "              epochs = epochs, verbose = 2,\n",
    "              steps_per_epoch = steps, callbacks=[uemgm,\n",
    "                                             adjust_lr,\n",
    "                                            ])\n",
    "enhancementWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.016666668>\n",
      "97/97 - 5s - loss: 1.5439\n",
      "\n",
      "Test on train set: loss= 1.2770020961761475 acc= 0.5482356548309326 auc= 0.784895230581214\n",
      "Test on valid set: loss= 2.470176935195923 acc= 0.17418470978736877 auc= 0.6804444444444444\n",
      "\n",
      "Epoch 2/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.033333335>\n",
      "97/97 - 4s - loss: 1.7073\n",
      "\n",
      "Test on train set: loss= 1.7529674768447876 acc= 0.61573326587677 auc= 0.7685027942506644\n",
      "Test on valid set: loss= 4.806485176086426 acc= 0.2624422013759613 auc= 0.6595555555555557\n",
      "\n",
      "Epoch 3/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.05>\n",
      "97/97 - 3s - loss: 2.4084\n",
      "\n",
      "Test on train set: loss= 1.9185322523117065 acc= 0.6465684771537781 auc= 0.7772352952157584\n",
      "Test on valid set: loss= 5.681309223175049 acc= 0.28321126103401184 auc= 0.7302222222222222\n",
      "\n",
      "Epoch 4/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.06666667>\n",
      "97/97 - 3s - loss: 2.9219\n",
      "\n",
      "Test on train set: loss= 2.979576587677002 acc= 0.5838459134101868 auc= 0.7937957284687992\n",
      "Test on valid set: loss= 6.6840996742248535 acc= 0.3507503867149353 auc= 0.7557777777777778\n",
      "\n",
      "Epoch 5/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.083333336>\n",
      "97/97 - 5s - loss: 3.0812\n",
      "\n",
      "Test on train set: loss= 2.4111669063568115 acc= 0.6671252846717834 auc= 0.8501238895657262\n",
      "Test on valid set: loss= 7.762313365936279 acc= 0.28510889410972595 auc= 0.7604444444444445\n",
      "\n",
      "Epoch 6/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 3.2105\n",
      "\n",
      "Test on train set: loss= 3.281446933746338 acc= 0.6402557492256165 auc= 0.8220662141955927\n",
      "Test on valid set: loss= 8.128632545471191 acc= 0.2641770839691162 auc= 0.7313333333333334\n",
      "\n",
      "Epoch 7/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 3.5918\n",
      "\n",
      "Test on train set: loss= 2.2102773189544678 acc= 0.7075105309486389 auc= 0.8376942642394175\n",
      "Test on valid set: loss= 6.801425933837891 acc= 0.3717063367366791 auc= 0.8395555555555557\n",
      "\n",
      "Epoch 8/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 5.1035\n",
      "\n",
      "Test on train set: loss= 4.108178615570068 acc= 0.6640498638153076 auc= 0.8500743267590769\n",
      "Test on valid set: loss= 11.3494873046875 acc= 0.2364269495010376 auc= 0.7373333333333333\n",
      "\n",
      "Epoch 9/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 4.9323\n",
      "\n",
      "Test on train set: loss= 4.899280548095703 acc= 0.5582712888717651 auc= 0.8106552437160506\n",
      "Test on valid set: loss= 8.480693817138672 acc= 0.30060461163520813 auc= 0.7451111111111113\n",
      "\n",
      "Epoch 10/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 6.2797\n",
      "\n",
      "Test on train set: loss= 2.796529769897461 acc= 0.7312237024307251 auc= 0.8520538480779576\n",
      "Test on valid set: loss= 7.92896842956543 acc= 0.3404432237148285 auc= 0.8022222222222222\n",
      "\n",
      "Epoch 11/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 9.4591\n",
      "\n",
      "Test on train set: loss= 4.267308712005615 acc= 0.6705244183540344 auc= 0.8633849058854632\n",
      "Test on valid set: loss= 7.621420860290527 acc= 0.4387969970703125 auc= 0.8228888888888889\n",
      "\n",
      "Epoch 12/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 10.0779\n",
      "\n",
      "Test on train set: loss= 3.3294169902801514 acc= 0.7310618162155151 auc= 0.8923896364397377\n",
      "Test on valid set: loss= 7.337181568145752 acc= 0.47009992599487305 auc= 0.8286666666666667\n",
      "\n",
      "Epoch 13/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 10.4363\n",
      "\n",
      "Test on train set: loss= 5.062185764312744 acc= 0.6392845511436462 auc= 0.845203977416579\n",
      "Test on valid set: loss= 8.555255889892578 acc= 0.41193586587905884 auc= 0.8099999999999999\n",
      "\n",
      "Epoch 14/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 9.8984\n",
      "\n",
      "Test on train set: loss= 4.1764397621154785 acc= 0.695613443851471 auc= 0.8826395937419307\n",
      "Test on valid set: loss= 9.408416748046875 acc= 0.37002629041671753 auc= 0.8455555555555554\n",
      "\n",
      "Epoch 15/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 10.9765\n",
      "\n",
      "Test on train set: loss= 3.885841131210327 acc= 0.6991744637489319 auc= 0.871678158048719\n",
      "Test on valid set: loss= 8.615504264831543 acc= 0.42668333649635315 auc= 0.8166666666666668\n",
      "\n",
      "Epoch 16/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 14.2017\n",
      "\n",
      "Test on train set: loss= 4.277976036071777 acc= 0.6999838352203369 auc= 0.8599795192718778\n",
      "Test on valid set: loss= 10.305952072143555 acc= 0.3584265112876892 auc= 0.7893333333333332\n",
      "\n",
      "Epoch 17/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 15.0776\n",
      "\n",
      "Test on train set: loss= 4.4195661544799805 acc= 0.688653290271759 auc= 0.8317357728914467\n",
      "Test on valid set: loss= 8.5132417678833 acc= 0.4472218155860901 auc= 0.8039999999999999\n",
      "\n",
      "Epoch 18/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 15.4330\n",
      "\n",
      "Test on train set: loss= 4.105174541473389 acc= 0.7046778798103333 auc= 0.8141792888458885\n",
      "Test on valid set: loss= 8.620882987976074 acc= 0.4164341390132904 auc= 0.7904444444444444\n",
      "\n",
      "Epoch 19/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 14.7925\n",
      "\n",
      "Test on train set: loss= 5.1638078689575195 acc= 0.6591939330101013 auc= 0.6939815594960537\n",
      "Test on valid set: loss= 12.24975299835205 acc= 0.239999920129776 auc= 0.6293333333333334\n",
      "\n",
      "Epoch 20/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 15.2795\n",
      "\n",
      "Test on train set: loss= 2.5468788146972656 acc= 0.811994194984436 auc= 0.9086073247808963\n",
      "Test on valid set: loss= 8.843462944030762 acc= 0.41904765367507935 auc= 0.8542222222222222\n",
      "\n",
      "Epoch 21/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 17.8629\n",
      "\n",
      "Test on train set: loss= 3.637333393096924 acc= 0.745953381061554 auc= 0.8639201538335453\n",
      "Test on valid set: loss= 10.722419738769531 acc= 0.31944409012794495 auc= 0.7988888888888889\n",
      "\n",
      "Epoch 22/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 18.2668\n",
      "\n",
      "Test on train set: loss= 2.992359161376953 acc= 0.7937843799591064 auc= 0.8845852345389646\n",
      "Test on valid set: loss= 8.344573974609375 acc= 0.4403626024723053 auc= 0.8779999999999999\n",
      "\n",
      "Epoch 23/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 17.8550\n",
      "\n",
      "Test on train set: loss= 2.911158323287964 acc= 0.795969545841217 auc= 0.8850789580022598\n",
      "Test on valid set: loss= 7.297360897064209 acc= 0.5399160385131836 auc= 0.8555555555555557\n",
      "\n",
      "Epoch 24/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 16.0300\n",
      "\n",
      "Test on train set: loss= 4.359321117401123 acc= 0.7005503177642822 auc= 0.8317834458458364\n",
      "Test on valid set: loss= 6.941059589385986 acc= 0.5346086025238037 auc= 0.8242222222222223\n",
      "\n",
      "Epoch 25/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 16.1043\n",
      "\n",
      "Test on train set: loss= 2.877903699874878 acc= 0.7772741913795471 auc= 0.9026065695727308\n",
      "Test on valid set: loss= 6.93870735168457 acc= 0.4975835680961609 auc= 0.8926666666666667\n",
      "\n",
      "Epoch 26/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 18.5868\n",
      "\n",
      "Test on train set: loss= 2.9598865509033203 acc= 0.7971835732460022 auc= 0.8606712092176518\n",
      "Test on valid set: loss= 8.059222221374512 acc= 0.4998258650302887 auc= 0.7884444444444444\n",
      "\n",
      "Epoch 27/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 18.7475\n",
      "\n",
      "Test on train set: loss= 2.9000422954559326 acc= 0.8043056130409241 auc= 0.864422028816176\n",
      "Test on valid set: loss= 9.356500625610352 acc= 0.4006071090698242 auc= 0.8019999999999999\n",
      "\n",
      "Epoch 28/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 19.5878\n",
      "\n",
      "Test on train set: loss= 3.4422695636749268 acc= 0.7635966539382935 auc= 0.8652491431452921\n",
      "Test on valid set: loss= 7.045576095581055 acc= 0.5391554236412048 auc= 0.861111111111111\n",
      "\n",
      "Epoch 29/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 21.2839\n",
      "\n",
      "Test on train set: loss= 3.8373639583587646 acc= 0.7299287915229797 auc= 0.8688729467584038\n",
      "Test on valid set: loss= 7.067049503326416 acc= 0.5405580401420593 auc= 0.844888888888889\n",
      "\n",
      "Epoch 30/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 22.0029\n",
      "\n",
      "Test on train set: loss= 2.823155641555786 acc= 0.8022013306617737 auc= 0.8925959183962495\n",
      "Test on valid set: loss= 7.727443695068359 acc= 0.5195250511169434 auc= 0.8188888888888888\n",
      "\n",
      "Epoch 31/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 21.3512\n",
      "\n",
      "Test on train set: loss= 3.3823654651641846 acc= 0.7722563743591309 auc= 0.8407055307741862\n",
      "Test on valid set: loss= 7.623133659362793 acc= 0.48924511671066284 auc= 0.778888888888889\n",
      "\n",
      "Epoch 32/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 22.4062\n",
      "\n",
      "Test on train set: loss= 3.1723523139953613 acc= 0.7856102585792542 auc= 0.8471183622482391\n",
      "Test on valid set: loss= 7.922990798950195 acc= 0.5000017881393433 auc= 0.784888888888889\n",
      "\n",
      "Epoch 33/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 21.6164\n",
      "\n",
      "Test on train set: loss= 2.924720287322998 acc= 0.8075429201126099 auc= 0.8399805319701862\n",
      "Test on valid set: loss= 6.447247505187988 acc= 0.5999914407730103 auc= 0.8188888888888888\n",
      "\n",
      "Epoch 34/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 23.6415\n",
      "\n",
      "Test on train set: loss= 2.487413167953491 acc= 0.8314179182052612 auc= 0.9035109786480897\n",
      "Test on valid set: loss= 6.42097282409668 acc= 0.5728750824928284 auc= 0.9008888888888889\n",
      "\n",
      "Epoch 35/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 19.2405\n",
      "\n",
      "Test on train set: loss= 2.323798656463623 acc= 0.8384590744972229 auc= 0.8999000958034872\n",
      "Test on valid set: loss= 6.134156703948975 acc= 0.6125509142875671 auc= 0.8588888888888888\n",
      "\n",
      "Epoch 36/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 18.8183\n",
      "\n",
      "Test on train set: loss= 2.3793115615844727 acc= 0.834736168384552 auc= 0.9228012317040676\n",
      "Test on valid set: loss= 5.183637619018555 acc= 0.6594318151473999 auc= 0.8962222222222224\n",
      "\n",
      "Epoch 37/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 18.4895\n",
      "\n",
      "Test on train set: loss= 2.7436113357543945 acc= 0.8116704225540161 auc= 0.9200999576856074\n",
      "Test on valid set: loss= 5.466042995452881 acc= 0.6163724660873413 auc= 0.9053333333333334\n",
      "\n",
      "Epoch 38/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 16.8558\n",
      "\n",
      "Test on train set: loss= 2.786423444747925 acc= 0.8110229969024658 auc= 0.9099641862360943\n",
      "Test on valid set: loss= 6.005548000335693 acc= 0.6186620593070984 auc= 0.8886666666666667\n",
      "\n",
      "Epoch 39/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 17.2958\n",
      "\n",
      "Test on train set: loss= 2.162912368774414 acc= 0.8495467901229858 auc= 0.8935252277467262\n",
      "Test on valid set: loss= 6.972142219543457 acc= 0.5394152402877808 auc= 0.8615555555555556\n",
      "\n",
      "Epoch 40/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 16.8464\n",
      "\n",
      "Test on train set: loss= 3.7256393432617188 acc= 0.7487050890922546 auc= 0.8642792374475619\n",
      "Test on valid set: loss= 6.0381317138671875 acc= 0.6000624895095825 auc= 0.8377777777777778\n",
      "\n",
      "Epoch 41/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 18.2221\n",
      "\n",
      "Test on train set: loss= 2.5904276371002197 acc= 0.8262382745742798 auc= 0.8724649822747397\n",
      "Test on valid set: loss= 6.3535919189453125 acc= 0.5800685882568359 auc= 0.8355555555555556\n",
      "\n",
      "Epoch 42/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 19.8047\n",
      "\n",
      "Test on train set: loss= 2.986802339553833 acc= 0.7936225533485413 auc= 0.8973131062645688\n",
      "Test on valid set: loss= 8.059048652648926 acc= 0.49999889731407166 auc= 0.7842222222222223\n",
      "\n",
      "Epoch 43/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 17.9996\n",
      "\n",
      "Test on train set: loss= 3.0263922214508057 acc= 0.7869051694869995 auc= 0.8503398298038307\n",
      "Test on valid set: loss= 8.067571640014648 acc= 0.48113107681274414 auc= 0.8099999999999999\n",
      "\n",
      "Epoch 44/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 20.6253\n",
      "\n",
      "Test on train set: loss= 2.8205692768096924 acc= 0.804386556148529 auc= 0.921269656626136\n",
      "Test on valid set: loss= 6.709075927734375 acc= 0.5693231821060181 auc= 0.836888888888889\n",
      "\n",
      "Epoch 45/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.1655\n",
      "\n",
      "Test on train set: loss= 2.3666539192199707 acc= 0.8339268565177917 auc= 0.8972281278257981\n",
      "Test on valid set: loss= 6.357390880584717 acc= 0.5999587178230286 auc= 0.8397777777777777\n",
      "\n",
      "Epoch 46/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.5562\n",
      "\n",
      "Test on train set: loss= 3.087453603744507 acc= 0.7935416102409363 auc= 0.8880191065370806\n",
      "Test on valid set: loss= 7.4143242835998535 acc= 0.5399993658065796 auc= 0.7922222222222223\n",
      "\n",
      "Epoch 47/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.0195\n",
      "\n",
      "Test on train set: loss= 2.5398688316345215 acc= 0.831256091594696 auc= 0.8939198231552681\n",
      "Test on valid set: loss= 5.497275352478027 acc= 0.6460505723953247 auc= 0.8815555555555555\n",
      "\n",
      "Epoch 48/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.1855\n",
      "\n",
      "Test on train set: loss= 2.368730306625366 acc= 0.842100977897644 auc= 0.8679038867391624\n",
      "Test on valid set: loss= 8.05904769897461 acc= 0.5 auc= 0.7575555555555555\n",
      "\n",
      "Epoch 49/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.3100\n",
      "\n",
      "Test on train set: loss= 3.3416359424591064 acc= 0.7719326615333557 auc= 0.858413852135431\n",
      "Test on valid set: loss= 7.737435817718506 acc= 0.5192636251449585 auc= 0.808888888888889\n",
      "\n",
      "Epoch 50/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.2045\n",
      "\n",
      "Test on train set: loss= 2.368959903717041 acc= 0.8446908593177795 auc= 0.8394682334124758\n",
      "Test on valid set: loss= 7.866275787353516 acc= 0.5000306963920593 auc= 0.7666666666666666\n",
      "\n",
      "Epoch 51/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.8041\n",
      "\n",
      "Test on train set: loss= 3.014533281326294 acc= 0.8023632168769836 auc= 0.8683335539379993\n",
      "Test on valid set: loss= 7.358281135559082 acc= 0.5200772881507874 auc= 0.8217777777777778\n",
      "\n",
      "Epoch 52/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.8703\n",
      "\n",
      "Test on train set: loss= 2.2974774837493896 acc= 0.8492230772972107 auc= 0.8661876782326067\n",
      "Test on valid set: loss= 7.093074798583984 acc= 0.5589178204536438 auc= 0.812888888888889\n",
      "\n",
      "Epoch 53/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.1296\n",
      "\n",
      "Test on train set: loss= 2.5012478828430176 acc= 0.8365976214408875 auc= 0.8742710814544253\n",
      "Test on valid set: loss= 8.069777488708496 acc= 0.4916955828666687 auc= 0.8188888888888888\n",
      "\n",
      "Epoch 54/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.4387\n",
      "\n",
      "Test on train set: loss= 2.317081928253174 acc= 0.8429103493690491 auc= 0.9030351052977743\n",
      "Test on valid set: loss= 5.600228309631348 acc= 0.6201399564743042 auc= 0.8917777777777779\n",
      "\n",
      "Epoch 55/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.7178\n",
      "\n",
      "Test on train set: loss= 2.608306646347046 acc= 0.8268857002258301 auc= 0.8900776462127492\n",
      "Test on valid set: loss= 6.770695686340332 acc= 0.578929603099823 auc= 0.8102222222222224\n",
      "\n",
      "Epoch 56/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.6538\n",
      "\n",
      "Test on train set: loss= 3.0374321937561035 acc= 0.8030107021331787 auc= 0.8513654274540821\n",
      "Test on valid set: loss= 5.820863246917725 acc= 0.6200165748596191 auc= 0.8257777777777777\n",
      "\n",
      "Epoch 57/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.0038\n",
      "\n",
      "Test on train set: loss= 2.8669421672821045 acc= 0.8137747049331665 auc= 0.857490251276831\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.6000000238418579 auc= 0.8193333333333334\n",
      "\n",
      "Epoch 58/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.2405\n",
      "\n",
      "Test on train set: loss= 2.5220980644226074 acc= 0.8363547921180725 auc= 0.8356385476516076\n",
      "Test on valid set: loss= 7.414323806762695 acc= 0.5400000214576721 auc= 0.7811111111111111\n",
      "\n",
      "Epoch 59/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.1997\n",
      "\n",
      "Test on train set: loss= 2.060424566268921 acc= 0.8654904365539551 auc= 0.9248738026564023\n",
      "Test on valid set: loss= 4.8361430168151855 acc= 0.6992982625961304 auc= 0.8560000000000001\n",
      "\n",
      "Epoch 60/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.7686\n",
      "\n",
      "Test on train set: loss= 2.2498795986175537 acc= 0.8527840971946716 auc= 0.9097833494236843\n",
      "Test on valid set: loss= 5.4802045822143555 acc= 0.6599479913711548 auc= 0.8295555555555556\n",
      "\n",
      "Epoch 61/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.0143\n",
      "\n",
      "Test on train set: loss= 1.735538363456726 acc= 0.8857235312461853 auc= 0.9022746803236064\n",
      "Test on valid set: loss= 6.447238922119141 acc= 0.6000000238418579 auc= 0.8297777777777778\n",
      "\n",
      "Epoch 62/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.1499\n",
      "\n",
      "Test on train set: loss= 1.7701382637023926 acc= 0.8825671672821045 auc= 0.9091813477532726\n",
      "Test on valid set: loss= 5.491700649261475 acc= 0.6512181162834167 auc= 0.8537777777777779\n",
      "\n",
      "Epoch 63/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 24.2442\n",
      "\n",
      "Test on train set: loss= 2.688422441482544 acc= 0.8223535418510437 auc= 0.8568250977984476\n",
      "Test on valid set: loss= 7.269933700561523 acc= 0.540002703666687 auc= 0.7862222222222222\n",
      "\n",
      "Epoch 64/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.7076\n",
      "\n",
      "Test on train set: loss= 2.5028722286224365 acc= 0.8359501361846924 auc= 0.8418194991852582\n",
      "Test on valid set: loss= 6.127800464630127 acc= 0.6172691583633423 auc= 0.8024444444444445\n",
      "\n",
      "Epoch 65/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.2027\n",
      "\n",
      "Test on train set: loss= 2.4695985317230225 acc= 0.8379734754562378 auc= 0.9010697765410549\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8353333333333334\n",
      "\n",
      "Epoch 66/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.2363\n",
      "\n",
      "Test on train set: loss= 1.9615557193756104 acc= 0.8724506497383118 auc= 0.8937866366590026\n",
      "Test on valid set: loss= 7.091961860656738 acc= 0.5600000023841858 auc= 0.8177777777777777\n",
      "\n",
      "Epoch 67/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.6616\n",
      "\n",
      "Test on train set: loss= 1.684817910194397 acc= 0.8887989521026611 auc= 0.9412581439330461\n",
      "Test on valid set: loss= 4.336003303527832 acc= 0.7004984021186829 auc= 0.8722222222222223\n",
      "\n",
      "Epoch 68/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.2443\n",
      "\n",
      "Test on train set: loss= 2.0990588665008545 acc= 0.865652322769165 auc= 0.8618584123509668\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.8173333333333334\n",
      "\n",
      "Epoch 69/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.3831\n",
      "\n",
      "Test on train set: loss= 1.9588803052902222 acc= 0.8722887635231018 auc= 0.8936206960490409\n",
      "Test on valid set: loss= 4.513306140899658 acc= 0.7197620868682861 auc= 0.8688888888888888\n",
      "\n",
      "Epoch 70/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.1499\n",
      "\n",
      "Test on train set: loss= 2.5017449855804443 acc= 0.8396730422973633 auc= 0.8376424581015238\n",
      "Test on valid set: loss= 7.091961860656738 acc= 0.559999942779541 auc= 0.7997777777777778\n",
      "\n",
      "Epoch 71/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.8703\n",
      "\n",
      "Test on train set: loss= 2.0766448974609375 acc= 0.8653286099433899 auc= 0.8614195232001804\n",
      "Test on valid set: loss= 5.80251407623291 acc= 0.6399999856948853 auc= 0.8057777777777778\n",
      "\n",
      "Epoch 72/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.8995\n",
      "\n",
      "Test on train set: loss= 1.8645199537277222 acc= 0.8784396052360535 auc= 0.9242963943970098\n",
      "Test on valid set: loss= 3.236544132232666 acc= 0.7904560565948486 auc= 0.9053333333333333\n",
      "\n",
      "Epoch 73/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.0698\n",
      "\n",
      "Test on train set: loss= 1.7374695539474487 acc= 0.888394296169281 auc= 0.8776270746938802\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8275555555555556\n",
      "\n",
      "Epoch 74/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.9238\n",
      "\n",
      "Test on train set: loss= 1.6677167415618896 acc= 0.8919553160667419 auc= 0.8825372187444577\n",
      "Test on valid set: loss= 5.802516460418701 acc= 0.6399979591369629 auc= 0.8331111111111111\n",
      "\n",
      "Epoch 75/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.3226\n",
      "\n",
      "Test on train set: loss= 2.0114247798919678 acc= 0.8675947189331055 auc= 0.9142449038368381\n",
      "Test on valid set: loss= 4.995500087738037 acc= 0.6726422309875488 auc= 0.8755555555555554\n",
      "\n",
      "Epoch 76/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 24.7153\n",
      "\n",
      "Test on train set: loss= 1.683362603187561 acc= 0.8894464373588562 auc= 0.9134816973326394\n",
      "Test on valid set: loss= 5.547823905944824 acc= 0.6325167417526245 auc= 0.8468888888888889\n",
      "\n",
      "Epoch 77/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.0418\n",
      "\n",
      "Test on train set: loss= 1.876759648323059 acc= 0.8754451274871826 auc= 0.9126621247098449\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8164444444444443\n",
      "\n",
      "Epoch 78/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.6177\n",
      "\n",
      "Test on train set: loss= 1.8487671613693237 acc= 0.880786657333374 auc= 0.902910097588536\n",
      "Test on valid set: loss= 6.5748395919799805 acc= 0.5800338983535767 auc= 0.7922222222222222\n",
      "\n",
      "Epoch 79/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.2137\n",
      "\n",
      "Test on train set: loss= 1.3384162187576294 acc= 0.9109744429588318 auc= 0.9261935253138447\n",
      "Test on valid set: loss= 6.142412185668945 acc= 0.608322262763977 auc= 0.8091111111111111\n",
      "\n",
      "Epoch 80/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.3834\n",
      "\n",
      "Test on train set: loss= 2.019618511199951 acc= 0.8698607683181763 auc= 0.8891034569984372\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8506666666666666\n",
      "\n",
      "Epoch 81/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.4725\n",
      "\n",
      "Test on train set: loss= 1.8059866428375244 acc= 0.8824862241744995 auc= 0.916425816181308\n",
      "Test on valid set: loss= 6.4205851554870605 acc= 0.6000000238418579 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 82/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.3375\n",
      "\n",
      "Test on train set: loss= 1.7232067584991455 acc= 0.8879896402359009 auc= 0.8999179330429005\n",
      "Test on valid set: loss= 4.777317047119141 acc= 0.6966499090194702 auc= 0.8535555555555556\n",
      "\n",
      "Epoch 83/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.6196\n",
      "\n",
      "Test on train set: loss= 1.4767967462539673 acc= 0.9044998288154602 auc= 0.9055519449376919\n",
      "Test on valid set: loss= 5.157825946807861 acc= 0.6799647808074951 auc= 0.82\n",
      "\n",
      "Epoch 84/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.2572\n",
      "\n",
      "Test on train set: loss= 2.0399177074432373 acc= 0.8684849739074707 auc= 0.9008897829561084\n",
      "Test on valid set: loss= 4.8562846183776855 acc= 0.6867176294326782 auc= 0.8404444444444445\n",
      "\n",
      "Epoch 85/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 24.9729\n",
      "\n",
      "Test on train set: loss= 1.6769434213638306 acc= 0.8921981453895569 auc= 0.9368826410196389\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000691413879 auc= 0.8744444444444444\n",
      "\n",
      "Epoch 86/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.0768\n",
      "\n",
      "Test on train set: loss= 1.9955873489379883 acc= 0.8718031644821167 auc= 0.9043114917967914\n",
      "Test on valid set: loss= 5.480553150177002 acc= 0.6596032381057739 auc= 0.8213333333333335\n",
      "\n",
      "Epoch 87/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 24.0916\n",
      "\n",
      "Test on train set: loss= 1.5005203485488892 acc= 0.903609573841095 auc= 0.8916499163504925\n",
      "Test on valid set: loss= 7.591216564178467 acc= 0.5200029015541077 auc= 0.7793333333333333\n",
      "\n",
      "Epoch 88/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 23.7308\n",
      "\n",
      "Test on train set: loss= 1.4757070541381836 acc= 0.90425705909729 auc= 0.9189383508893295\n",
      "Test on valid set: loss= 4.835430145263672 acc= 0.6999983787536621 auc= 0.8322222222222223\n",
      "\n",
      "Epoch 89/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.9794\n",
      "\n",
      "Test on train set: loss= 1.6131969690322876 acc= 0.8954353928565979 auc= 0.9361514696794142\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7200000286102295 auc= 0.8433333333333334\n",
      "\n",
      "Epoch 90/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.0069\n",
      "\n",
      "Test on train set: loss= 1.544288992881775 acc= 0.8998866677284241 auc= 0.9110087849954546\n",
      "Test on valid set: loss= 5.182475566864014 acc= 0.6658211350440979 auc= 0.842\n",
      "\n",
      "Epoch 91/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.5021\n",
      "\n",
      "Test on train set: loss= 2.7676267623901367 acc= 0.8238102793693542 auc= 0.8487856229748143\n",
      "Test on valid set: loss= 8.309656143188477 acc= 0.48000001907348633 auc= 0.7286666666666666\n",
      "\n",
      "Epoch 92/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.9463\n",
      "\n",
      "Test on train set: loss= 1.5474807024002075 acc= 0.900048553943634 auc= 0.9068609449143809\n",
      "Test on valid set: loss= 5.261023044586182 acc= 0.6420220136642456 auc= 0.8682222222222222\n",
      "\n",
      "Epoch 93/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.0328\n",
      "\n",
      "Test on train set: loss= 1.415789246559143 acc= 0.9091939330101013 auc= 0.9166224122192791\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8542222222222223\n",
      "\n",
      "Epoch 94/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.1691\n",
      "\n",
      "Test on train set: loss= 1.6774579286575317 acc= 0.892683744430542 auc= 0.9123736041093222\n",
      "Test on valid set: loss= 5.7186994552612305 acc= 0.6397806406021118 auc= 0.8284444444444444\n",
      "\n",
      "Epoch 95/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.2886\n",
      "\n",
      "Test on train set: loss= 1.3128098249435425 acc= 0.915263831615448 auc= 0.9150646818405747\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8173333333333334\n",
      "\n",
      "Epoch 96/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.0180\n",
      "\n",
      "Test on train set: loss= 2.0292203426361084 acc= 0.8709938526153564 auc= 0.9137201260353578\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.8233333333333333\n",
      "\n",
      "Epoch 97/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.6251\n",
      "\n",
      "Test on train set: loss= 1.8148261308670044 acc= 0.8835383653640747 auc= 0.8957251240914277\n",
      "Test on valid set: loss= 5.27029275894165 acc= 0.6600721478462219 auc= 0.8217777777777778\n",
      "\n",
      "Epoch 98/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.6215\n",
      "\n",
      "Test on train set: loss= 1.6288344860076904 acc= 0.8956782221794128 auc= 0.8869613485351422\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.699999988079071 auc= 0.8619999999999999\n",
      "\n",
      "Epoch 99/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.7165\n",
      "\n",
      "Test on train set: loss= 1.4119542837142944 acc= 0.9093557596206665 auc= 0.9175576472611408\n",
      "Test on valid set: loss= 5.255572319030762 acc= 0.6601505875587463 auc= 0.868888888888889\n",
      "\n",
      "Epoch 100/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.4968\n",
      "\n",
      "Test on train set: loss= 1.6355743408203125 acc= 0.8957591652870178 auc= 0.8991631744414497\n",
      "Test on valid set: loss= 5.480550765991211 acc= 0.6596049070358276 auc= 0.82\n",
      "\n",
      "Epoch 101/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.3044\n",
      "\n",
      "Test on train set: loss= 1.4408742189407349 acc= 0.907656192779541 auc= 0.9039483097019995\n",
      "Test on valid set: loss= 5.480154037475586 acc= 0.6599985361099243 auc= 0.8300000000000001\n",
      "\n",
      "Epoch 102/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.7578\n",
      "\n",
      "Test on train set: loss= 1.430522084236145 acc= 0.9067659378051758 auc= 0.9265003459625187\n",
      "Test on valid set: loss= 6.7696003913879395 acc= 0.5799999833106995 auc= 0.7828888888888889\n",
      "\n",
      "Epoch 103/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.4986\n",
      "\n",
      "Test on train set: loss= 1.978391170501709 acc= 0.872612476348877 auc= 0.9277837636645228\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8302222222222223\n",
      "\n",
      "Epoch 104/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 36.1000\n",
      "\n",
      "Test on train set: loss= 1.6116083860397339 acc= 0.8957591652870178 auc= 0.9347252284516507\n",
      "Test on valid set: loss= 4.1907477378845215 acc= 0.7399570941925049 auc= 0.8844444444444445\n",
      "\n",
      "Epoch 105/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 33.7094\n",
      "\n",
      "Test on train set: loss= 1.4020204544067383 acc= 0.9094367027282715 auc= 0.9344229031398555\n",
      "Test on valid set: loss= 4.521262168884277 acc= 0.7125903367996216 auc= 0.8533333333333333\n",
      "\n",
      "Epoch 106/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.9162\n",
      "\n",
      "Test on train set: loss= 1.3327124118804932 acc= 0.9116218686103821 auc= 0.9410249894273018\n",
      "Test on valid set: loss= 3.55332612991333 acc= 0.773707389831543 auc= 0.8842222222222222\n",
      "\n",
      "Epoch 107/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.7399\n",
      "\n",
      "Test on train set: loss= 1.366579294204712 acc= 0.9092748165130615 auc= 0.9297233810588862\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799998879432678 auc= 0.8515555555555556\n",
      "\n",
      "Epoch 108/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.9348\n",
      "\n",
      "Test on train set: loss= 1.9262009859085083 acc= 0.8759307265281677 auc= 0.9040481866760712\n",
      "Test on valid set: loss= 5.357489109039307 acc= 0.6600009202957153 auc= 0.8602222222222222\n",
      "\n",
      "Epoch 109/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.5455\n",
      "\n",
      "Test on train set: loss= 1.5995374917984009 acc= 0.8946260809898376 auc= 0.9355579105283583\n",
      "Test on valid set: loss= 3.919501304626465 acc= 0.7415493130683899 auc= 0.8940000000000001\n",
      "\n",
      "Epoch 110/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 25.7973\n",
      "\n",
      "Test on train set: loss= 1.5155965089797974 acc= 0.899482011795044 auc= 0.9389186949052547\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8304444444444444\n",
      "\n",
      "Epoch 111/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 23.4234\n",
      "\n",
      "Test on train set: loss= 1.3088990449905396 acc= 0.9130786657333374 auc= 0.9441014672696266\n",
      "Test on valid set: loss= 3.9482226371765137 acc= 0.7401026487350464 auc= 0.8640000000000001\n",
      "\n",
      "Epoch 112/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 28.7601\n",
      "\n",
      "Test on train set: loss= 2.230052947998047 acc= 0.8560213446617126 auc= 0.9126829700518391\n",
      "Test on valid set: loss= 4.513067245483398 acc= 0.7200000286102295 auc= 0.8517777777777777\n",
      "\n",
      "Epoch 113/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 25.4414\n",
      "\n",
      "Test on train set: loss= 1.2871228456497192 acc= 0.9163159728050232 auc= 0.9300515453566371\n",
      "Test on valid set: loss= 4.798821449279785 acc= 0.699999988079071 auc= 0.8515555555555556\n",
      "\n",
      "Epoch 114/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 28.6578\n",
      "\n",
      "Test on train set: loss= 1.3259638547897339 acc= 0.9123502969741821 auc= 0.929396695129529\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999070167542 auc= 0.8344444444444445\n",
      "\n",
      "Epoch 115/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 23.6783\n",
      "\n",
      "Test on train set: loss= 1.3909212350845337 acc= 0.9083036780357361 auc= 0.9247894161861527\n",
      "Test on valid set: loss= 6.126037120819092 acc= 0.6188725233078003 auc= 0.8059999999999998\n",
      "\n",
      "Epoch 116/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.8594\n",
      "\n",
      "Test on train set: loss= 1.1680556535720825 acc= 0.9243282675743103 auc= 0.9067220173419057\n",
      "Test on valid set: loss= 5.317277908325195 acc= 0.6547754406929016 auc= 0.8259999999999998\n",
      "\n",
      "Epoch 117/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.0973\n",
      "\n",
      "Test on train set: loss= 1.1572543382644653 acc= 0.9257850646972656 auc= 0.9324871121436994\n",
      "Test on valid set: loss= 4.1910271644592285 acc= 0.7396801114082336 auc= 0.8742222222222222\n",
      "\n",
      "Epoch 118/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.7778\n",
      "\n",
      "Test on train set: loss= 1.31641685962677 acc= 0.9155875444412231 auc= 0.927378867443298\n",
      "Test on valid set: loss= 5.0770721435546875 acc= 0.6796830296516418 auc= 0.8437777777777778\n",
      "\n",
      "Epoch 119/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.0727\n",
      "\n",
      "Test on train set: loss= 1.2225722074508667 acc= 0.9219002723693848 auc= 0.917555567620736\n",
      "Test on valid set: loss= 6.779089450836182 acc= 0.561031699180603 auc= 0.7826666666666667\n",
      "\n",
      "Epoch 120/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.9330\n",
      "\n",
      "Test on train set: loss= 1.0939632654190063 acc= 0.9286985993385315 auc= 0.9380408050660822\n",
      "Test on valid set: loss= 4.513067245483398 acc= 0.7200000286102295 auc= 0.8542222222222222\n",
      "\n",
      "Epoch 121/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.3882\n",
      "\n",
      "Test on train set: loss= 1.3625679016113281 acc= 0.9121884107589722 auc= 0.9310635166174686\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8615555555555556\n",
      "\n",
      "Epoch 122/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.2907\n",
      "\n",
      "Test on train set: loss= 2.5197579860687256 acc= 0.8392683863639832 auc= 0.9229999378920886\n",
      "Test on valid set: loss= 5.480412483215332 acc= 0.6597411036491394 auc= 0.8208888888888888\n",
      "\n",
      "Epoch 123/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.9586\n",
      "\n",
      "Test on train set: loss= 1.2390776872634888 acc= 0.9206053614616394 auc= 0.9351181465429372\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8433333333333334\n",
      "\n",
      "Epoch 124/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 37.0717\n",
      "\n",
      "Test on train set: loss= 1.3394229412078857 acc= 0.9145354628562927 auc= 0.8936826301272722\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8215555555555556\n",
      "\n",
      "Epoch 125/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.4056\n",
      "\n",
      "Test on train set: loss= 1.1764990091323853 acc= 0.923599898815155 auc= 0.9400113022745469\n",
      "Test on valid set: loss= 4.8354291915893555 acc= 0.6999992728233337 auc= 0.8620000000000001\n",
      "\n",
      "Epoch 126/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.4982\n",
      "\n",
      "Test on train set: loss= 1.0684434175491333 acc= 0.9314503073692322 auc= 0.9471433051732451\n",
      "Test on valid set: loss= 4.029707431793213 acc= 0.7400063276290894 auc= 0.8851111111111111\n",
      "\n",
      "Epoch 127/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.6052\n",
      "\n",
      "Test on train set: loss= 0.9962130784988403 acc= 0.9359825253486633 auc= 0.948844288752087\n",
      "Test on valid set: loss= 5.633244037628174 acc= 0.6320568323135376 auc= 0.8284444444444444\n",
      "\n",
      "Epoch 128/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.8788\n",
      "\n",
      "Test on train set: loss= 0.9604982137680054 acc= 0.9376011490821838 auc= 0.9443218679586686\n",
      "Test on valid set: loss= 4.360555171966553 acc= 0.720004141330719 auc= 0.8648888888888889\n",
      "\n",
      "Epoch 129/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.8245\n",
      "\n",
      "Test on train set: loss= 1.2755540609359741 acc= 0.9184201955795288 auc= 0.9303429282695657\n",
      "Test on valid set: loss= 4.514367580413818 acc= 0.7187405228614807 auc= 0.8522222222222222\n",
      "\n",
      "Epoch 130/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.0238\n",
      "\n",
      "Test on train set: loss= 1.0753211975097656 acc= 0.931045651435852 auc= 0.9417076673415483\n",
      "Test on valid set: loss= 4.966760158538818 acc= 0.6800281405448914 auc= 0.8408888888888889\n",
      "\n",
      "Epoch 131/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.0780\n",
      "\n",
      "Test on train set: loss= 1.2068917751312256 acc= 0.9224668145179749 auc= 0.9122294509971992\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.6999999284744263 auc= 0.8417777777777777\n",
      "\n",
      "Epoch 132/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.4465\n",
      "\n",
      "Test on train set: loss= 2.0025274753570557 acc= 0.8718031644821167 auc= 0.8933920102412009\n",
      "Test on valid set: loss= 7.736685752868652 acc= 0.5199999213218689 auc= 0.7422222222222221\n",
      "\n",
      "Epoch 133/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.0438\n",
      "\n",
      "Test on train set: loss= 1.1225556135177612 acc= 0.9262706637382507 auc= 0.958104507578134\n",
      "Test on valid set: loss= 4.868992328643799 acc= 0.6804008483886719 auc= 0.8706666666666667\n",
      "\n",
      "Epoch 134/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.1132\n",
      "\n",
      "Test on train set: loss= 1.425934910774231 acc= 0.9085464477539062 auc= 0.9511988130604667\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8740000000000002\n",
      "\n",
      "Epoch 135/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 37.4147\n",
      "\n",
      "Test on train set: loss= 1.6437525749206543 acc= 0.8950307369232178 auc= 0.9307273495027133\n",
      "Test on valid set: loss= 5.905594348907471 acc= 0.6201155781745911 auc= 0.8277777777777778\n",
      "\n",
      "Epoch 136/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 38.1968\n",
      "\n",
      "Test on train set: loss= 1.569084644317627 acc= 0.900291383266449 auc= 0.9148812158406908\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.7000000476837158 auc= 0.8322222222222223\n",
      "\n",
      "Epoch 137/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.9044\n",
      "\n",
      "Test on train set: loss= 1.2899878025054932 acc= 0.9171252846717834 auc= 0.9096496208175969\n",
      "Test on valid set: loss= 5.597888946533203 acc= 0.6400555372238159 auc= 0.8086666666666666\n",
      "\n",
      "Epoch 138/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.8403\n",
      "\n",
      "Test on train set: loss= 1.135918140411377 acc= 0.9276464581489563 auc= 0.9252303535376625\n",
      "Test on valid set: loss= 5.161367416381836 acc= 0.676716148853302 auc= 0.8477777777777777\n",
      "\n",
      "Epoch 139/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.1520\n",
      "\n",
      "Test on train set: loss= 1.4358454942703247 acc= 0.907818078994751 auc= 0.897456303831438\n",
      "Test on valid set: loss= 5.482558727264404 acc= 0.6577332019805908 auc= 0.8088888888888889\n",
      "\n",
      "Epoch 140/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.5733\n",
      "\n",
      "Test on train set: loss= 1.5713917016983032 acc= 0.8997248411178589 auc= 0.8951371085250713\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8100000000000002\n",
      "\n",
      "Epoch 141/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.6573\n",
      "\n",
      "Test on train set: loss= 1.1314992904663086 acc= 0.9276464581489563 auc= 0.9304862386790059\n",
      "Test on valid set: loss= 3.952885627746582 acc= 0.7400252819061279 auc= 0.8762222222222222\n",
      "\n",
      "Epoch 142/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.3321\n",
      "\n",
      "Test on train set: loss= 0.9555578827857971 acc= 0.9384914040565491 auc= 0.9435349830089159\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555557\n",
      "\n",
      "Epoch 143/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.1623\n",
      "\n",
      "Test on train set: loss= 1.015398383140564 acc= 0.9350922703742981 auc= 0.9594646099526036\n",
      "Test on valid set: loss= 3.545980930328369 acc= 0.7800000309944153 auc= 0.8875555555555555\n",
      "\n",
      "Epoch 144/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.0851\n",
      "\n",
      "Test on train set: loss= 1.337033748626709 acc= 0.9145354628562927 auc= 0.8928253463015601\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.6000000238418579 auc= 0.7875555555555556\n",
      "\n",
      "Epoch 145/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 24.6995\n",
      "\n",
      "Test on train set: loss= 1.1680647134780884 acc= 0.9231951832771301 auc= 0.9617950469771104\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.7000000476837158 auc= 0.8324444444444445\n",
      "\n",
      "Epoch 146/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 26.7201\n",
      "\n",
      "Test on train set: loss= 0.8614871501922607 acc= 0.9435901641845703 auc= 0.9473064227897643\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8104444444444443\n",
      "\n",
      "Epoch 147/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.1348\n",
      "\n",
      "Test on train set: loss= 1.0281414985656738 acc= 0.934606671333313 auc= 0.9451203676571197\n",
      "Test on valid set: loss= 6.021693229675293 acc= 0.6200003623962402 auc= 0.7984444444444445\n",
      "\n",
      "Epoch 148/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.8462\n",
      "\n",
      "Test on train set: loss= 1.0755038261413574 acc= 0.9299125671386719 auc= 0.9548817452886483\n",
      "Test on valid set: loss= 4.9881415367126465 acc= 0.6796956062316895 auc= 0.8597777777777779\n",
      "\n",
      "Epoch 149/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.1547\n",
      "\n",
      "Test on train set: loss= 1.4122670888900757 acc= 0.9089511036872864 auc= 0.9283882618951538\n",
      "Test on valid set: loss= 4.659425735473633 acc= 0.700013279914856 auc= 0.8437777777777777\n",
      "\n",
      "Epoch 150/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.0082\n",
      "\n",
      "Test on train set: loss= 0.9608865976333618 acc= 0.9381676912307739 auc= 0.9478265109224063\n",
      "Test on valid set: loss= 5.361120223999023 acc= 0.6600008010864258 auc= 0.8313333333333335\n",
      "\n",
      "Epoch 151/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.3604\n",
      "\n",
      "Test on train set: loss= 1.1052535772323608 acc= 0.9291032552719116 auc= 0.9489982587863667\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.64000004529953 auc= 0.8175555555555555\n",
      "\n",
      "Epoch 152/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.2558\n",
      "\n",
      "Test on train set: loss= 1.1734992265701294 acc= 0.9249756932258606 auc= 0.9237824850297486\n",
      "Test on valid set: loss= 4.70491361618042 acc= 0.7000013589859009 auc= 0.8435555555555556\n",
      "\n",
      "Epoch 153/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.3191\n",
      "\n",
      "Test on train set: loss= 1.471950888633728 acc= 0.9056329131126404 auc= 0.9184239154420311\n",
      "Test on valid set: loss= 6.126235485076904 acc= 0.6186860203742981 auc= 0.7973333333333332\n",
      "\n",
      "Epoch 154/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 6s - loss: 27.3336\n",
      "\n",
      "Test on train set: loss= 1.1866897344589233 acc= 0.9227096438407898 auc= 0.9497906539878036\n",
      "Test on valid set: loss= 4.723740100860596 acc= 0.700000524520874 auc= 0.8635555555555555\n",
      "\n",
      "Epoch 155/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 30.5563\n",
      "\n",
      "Test on train set: loss= 1.1989362239837646 acc= 0.92279052734375 auc= 0.9407051805705148\n",
      "Test on valid set: loss= 4.540752410888672 acc= 0.7050101161003113 auc= 0.8460000000000001\n",
      "\n",
      "Epoch 156/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.5980\n",
      "\n",
      "Test on train set: loss= 1.0994428396224976 acc= 0.9296697974205017 auc= 0.9326438171247396\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.7997777777777777\n",
      "\n",
      "Epoch 157/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.0261\n",
      "\n",
      "Test on train set: loss= 1.2554705142974854 acc= 0.919472336769104 auc= 0.9321429744910079\n",
      "Test on valid set: loss= 5.7326178550720215 acc= 0.6400001049041748 auc= 0.8286666666666667\n",
      "\n",
      "Epoch 158/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.7462\n",
      "\n",
      "Test on train set: loss= 1.150628924369812 acc= 0.9264324903488159 auc= 0.925742554937442\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8484444444444443\n",
      "\n",
      "Epoch 159/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 33.3786\n",
      "\n",
      "Test on train set: loss= 0.9790126085281372 acc= 0.9376011490821838 auc= 0.9336250039517031\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6600000262260437 auc= 0.8295555555555556\n",
      "\n",
      "Epoch 160/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.6192\n",
      "\n",
      "Test on train set: loss= 1.7048423290252686 acc= 0.8923599720001221 auc= 0.9271547603651795\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8422222222222222\n",
      "\n",
      "Epoch 161/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 36.7720\n",
      "\n",
      "Test on train set: loss= 0.827490508556366 acc= 0.9472321271896362 auc= 0.9451334550441798\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8337777777777777\n",
      "\n",
      "Epoch 162/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.0774\n",
      "\n",
      "Test on train set: loss= 1.009553074836731 acc= 0.9356588125228882 auc= 0.9396933910652345\n",
      "Test on valid set: loss= 6.274498462677002 acc= 0.6000112891197205 auc= 0.7984444444444445\n",
      "\n",
      "Epoch 163/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.0840\n",
      "\n",
      "Test on train set: loss= 0.9763018488883972 acc= 0.9363871812820435 auc= 0.9484319190965751\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8300000000000001\n",
      "\n",
      "Epoch 164/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.8619\n",
      "\n",
      "Test on train set: loss= 0.8318130373954773 acc= 0.9473939538002014 auc= 0.9482472538841163\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 165/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.1008\n",
      "\n",
      "Test on train set: loss= 1.011849284172058 acc= 0.9357396960258484 auc= 0.9463996809694608\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8537777777777776\n",
      "\n",
      "Epoch 166/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.3990\n",
      "\n",
      "Test on train set: loss= 1.3000999689102173 acc= 0.9169633984565735 auc= 0.9197925649058517\n",
      "Test on valid set: loss= 6.447238922119141 acc= 0.6000000238418579 auc= 0.7977777777777778\n",
      "\n",
      "Epoch 167/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.2132\n",
      "\n",
      "Test on train set: loss= 0.91668301820755 acc= 0.9418096542358398 auc= 0.9399099985844174\n",
      "Test on valid set: loss= 4.835428714752197 acc= 0.699999988079071 auc= 0.8437777777777777\n",
      "\n",
      "Epoch 168/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.3366\n",
      "\n",
      "Test on train set: loss= 0.9168574213981628 acc= 0.9414859414100647 auc= 0.9419330893818447\n",
      "Test on valid set: loss= 5.991361141204834 acc= 0.6200015544891357 auc= 0.8297777777777778\n",
      "\n",
      "Epoch 169/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 4s - loss: 33.0782\n",
      "\n",
      "Test on train set: loss= 0.855438232421875 acc= 0.9455325603485107 auc= 0.9587631864039677\n",
      "Test on valid set: loss= 4.513067245483398 acc= 0.7200000286102295 auc= 0.8644444444444443\n",
      "\n",
      "Epoch 170/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 36.8188\n",
      "\n",
      "Test on train set: loss= 0.9059826731681824 acc= 0.9416477680206299 auc= 0.9379365048246624\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8200000000000001\n",
      "\n",
      "Epoch 171/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 5s - loss: 29.6336\n",
      "\n",
      "Test on train set: loss= 0.9081761240959167 acc= 0.9414049983024597 auc= 0.9460202685089476\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8317777777777777\n",
      "\n",
      "Epoch 172/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.9979\n",
      "\n",
      "Test on train set: loss= 0.8851486444473267 acc= 0.942133367061615 auc= 0.939614953137452\n",
      "Test on valid set: loss= 4.513067722320557 acc= 0.7199994325637817 auc= 0.8615555555555556\n",
      "\n",
      "Epoch 173/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.3609\n",
      "\n",
      "Test on train set: loss= 0.9203145503997803 acc= 0.9405956864356995 auc= 0.9363843360799817\n",
      "Test on valid set: loss= 4.836010456085205 acc= 0.6994225978851318 auc= 0.8426666666666668\n",
      "\n",
      "Epoch 174/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.7889\n",
      "\n",
      "Test on train set: loss= 0.7504240274429321 acc= 0.9519261717796326 auc= 0.9368031813545447\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8213333333333335\n",
      "\n",
      "Epoch 175/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.5290\n",
      "\n",
      "Test on train set: loss= 1.1662938594818115 acc= 0.9253804087638855 auc= 0.9329793503666283\n",
      "Test on valid set: loss= 6.931652069091797 acc= 0.5600060224533081 auc= 0.7828888888888887\n",
      "\n",
      "Epoch 176/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 23.7088\n",
      "\n",
      "Test on train set: loss= 0.8146334290504456 acc= 0.9471511840820312 auc= 0.9416621574361747\n",
      "Test on valid set: loss= 6.124876022338867 acc= 0.6200000047683716 auc= 0.7986666666666666\n",
      "\n",
      "Epoch 177/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.2702\n",
      "\n",
      "Test on train set: loss= 1.2219210863113403 acc= 0.92279052734375 auc= 0.9113355295006139\n",
      "Test on valid set: loss= 5.551779270172119 acc= 0.6405567526817322 auc= 0.8206666666666665\n",
      "\n",
      "Epoch 178/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.3830\n",
      "\n",
      "Test on train set: loss= 0.8938902616500854 acc= 0.9426999092102051 auc= 0.9539928884122262\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.7895555555555556\n",
      "\n",
      "Epoch 179/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.1874\n",
      "\n",
      "Test on train set: loss= 0.8729910850524902 acc= 0.9448041319847107 auc= 0.9467880923979466\n",
      "Test on valid set: loss= 4.513103008270264 acc= 0.7199639081954956 auc= 0.8535555555555556\n",
      "\n",
      "Epoch 180/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 33.0925\n",
      "\n",
      "Test on train set: loss= 0.9503740668296814 acc= 0.9392198324203491 auc= 0.9443091946826618\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8435555555555556\n",
      "\n",
      "Epoch 181/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 38.1030\n",
      "\n",
      "Test on train set: loss= 0.8925114274024963 acc= 0.9432664513587952 auc= 0.9292951289476372\n",
      "Test on valid set: loss= 5.495282173156738 acc= 0.649386465549469 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 182/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 28.8232\n",
      "\n",
      "Test on train set: loss= 0.9309685230255127 acc= 0.9405147433280945 auc= 0.9456550717518001\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8413333333333333\n",
      "\n",
      "Epoch 183/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.3209\n",
      "\n",
      "Test on train set: loss= 1.5812219381332397 acc= 0.900210440158844 auc= 0.9169552915692766\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.8104444444444445\n",
      "\n",
      "Epoch 184/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.5938\n",
      "\n",
      "Test on train set: loss= 1.0202579498291016 acc= 0.9353350400924683 auc= 0.9288870471808661\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399999856948853 auc= 0.7986666666666667\n",
      "\n",
      "Epoch 185/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 30.3350\n",
      "\n",
      "Test on train set: loss= 0.7534723281860352 acc= 0.9520880579948425 auc= 0.9504549913640339\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8231111111111111\n",
      "\n",
      "Epoch 186/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.5070\n",
      "\n",
      "Test on train set: loss= 1.1089774370193481 acc= 0.9295888543128967 auc= 0.9075556181514204\n",
      "Test on valid set: loss= 6.447237968444824 acc= 0.6000000238418579 auc= 0.8200000000000001\n",
      "\n",
      "Epoch 187/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 29.3224\n",
      "\n",
      "Test on train set: loss= 0.9644679427146912 acc= 0.9381676912307739 auc= 0.9158577323603547\n",
      "Test on valid set: loss= 6.7696003913879395 acc= 0.5800000429153442 auc= 0.7853333333333333\n",
      "\n",
      "Epoch 188/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.7064\n",
      "\n",
      "Test on train set: loss= 0.8793244361877441 acc= 0.9435092210769653 auc= 0.9506088717283664\n",
      "Test on valid set: loss= 4.899494171142578 acc= 0.6808125972747803 auc= 0.8417777777777777\n",
      "\n",
      "Epoch 189/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 33.3259\n",
      "\n",
      "Test on train set: loss= 0.9474042654037476 acc= 0.9390579462051392 auc= 0.9354403899188011\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8422222222222222\n",
      "\n",
      "Epoch 190/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 40.5439\n",
      "\n",
      "Test on train set: loss= 0.7523317337036133 acc= 0.9519261717796326 auc= 0.9507190701700694\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8108888888888888\n",
      "\n",
      "Epoch 191/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 32.9300\n",
      "\n",
      "Test on train set: loss= 0.665522575378418 acc= 0.9575914740562439 auc= 0.944298269288463\n",
      "Test on valid set: loss= 5.802514553070068 acc= 0.6399996876716614 auc= 0.8308888888888889\n",
      "\n",
      "Epoch 192/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 36.1448\n",
      "\n",
      "Test on train set: loss= 0.9778387546539307 acc= 0.9376011490821838 auc= 0.9556103375112233\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8222222222222222\n",
      "\n",
      "Epoch 193/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.6094\n",
      "\n",
      "Test on train set: loss= 0.7610195279121399 acc= 0.9513596892356873 auc= 0.9484345953576397\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8320000000000001\n",
      "\n",
      "Epoch 194/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 35.4899\n",
      "\n",
      "Test on train set: loss= 0.921410322189331 acc= 0.9399482011795044 auc= 0.955748783779588\n",
      "Test on valid set: loss= 5.480152606964111 acc= 0.6599999666213989 auc= 0.8195555555555554\n",
      "\n",
      "Epoch 195/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 31.2492\n",
      "\n",
      "Test on train set: loss= 0.7248202562332153 acc= 0.953949511051178 auc= 0.9652697951950024\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.7968888888888889\n",
      "\n",
      "Epoch 196/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 34.3419\n",
      "\n",
      "Test on train set: loss= 0.6288547515869141 acc= 0.9595338106155396 auc= 0.9675517954687161\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6800000071525574 auc= 0.8219999999999998\n",
      "\n",
      "Epoch 197/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 37.3457\n",
      "\n",
      "Test on train set: loss= 0.822131872177124 acc= 0.9476367831230164 auc= 0.9454875223770778\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7599999904632568 auc= 0.8675555555555554\n",
      "\n",
      "Epoch 198/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 37.0881\n",
      "\n",
      "Test on train set: loss= 0.7470508813858032 acc= 0.9523308277130127 auc= 0.9438931680320856\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7399999499320984 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 199/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 27.4025\n",
      "\n",
      "Test on train set: loss= 0.8376960158348083 acc= 0.9466655850410461 auc= 0.9611502322787364\n",
      "Test on valid set: loss= 6.124876499176025 acc= 0.6200000047683716 auc= 0.7886666666666666\n",
      "\n",
      "Epoch 200/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: 25.0775\n",
      "\n",
      "Test on train set: loss= 0.7885475754737854 acc= 0.9494172930717468 auc= 0.9623362366973558\n",
      "Test on valid set: loss= 4.835428237915039 acc= 0.6999999284744263 auc= 0.8433333333333334\n",
      "\n",
      "Epoch 201/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 29.0392\n",
      "\n",
      "Test on train set: loss= 0.48326754570007324 acc= 0.9693266153335571 auc= 0.9656838890363735\n",
      "Test on valid set: loss= 5.157790660858154 acc= 0.6799999475479126 auc= 0.8493333333333334\n",
      "\n",
      "Epoch 202/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 15.0162\n",
      "\n",
      "Test on train set: loss= 0.3992184102535248 acc= 0.9743444323539734 auc= 0.9814982269358005\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8715555555555555\n",
      "\n",
      "Epoch 203/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 14.2106\n",
      "\n",
      "Test on train set: loss= 0.32702985405921936 acc= 0.9787148237228394 auc= 0.9802505969103633\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7399999499320984 auc= 0.8746666666666666\n",
      "\n",
      "Epoch 204/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 11.0760\n",
      "\n",
      "Test on train set: loss= 0.3339586853981018 acc= 0.9783910512924194 auc= 0.981005385018604\n",
      "Test on valid set: loss= 4.1907057762146 acc= 0.7399991154670715 auc= 0.8637777777777778\n",
      "\n",
      "Epoch 205/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 10.7975\n",
      "\n",
      "Test on train set: loss= 0.3120991587638855 acc= 0.9800097346305847 auc= 0.9844483816818439\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8539999999999999\n",
      "\n",
      "Epoch 206/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 8.9330\n",
      "\n",
      "Test on train set: loss= 0.3028443157672882 acc= 0.9804953336715698 auc= 0.9873146246675095\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8562222222222221\n",
      "\n",
      "Epoch 207/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 9.8277\n",
      "\n",
      "Test on train set: loss= 0.2973915636539459 acc= 0.980819046497345 auc= 0.9845628552983399\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8635555555555555\n",
      "\n",
      "Epoch 208/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 10.6607\n",
      "\n",
      "Test on train set: loss= 0.2541342079639435 acc= 0.9834898114204407 auc= 0.9872091950008788\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7200000286102295 auc= 0.8524444444444444\n",
      "\n",
      "Epoch 209/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 7.7903\n",
      "\n",
      "Test on train set: loss= 0.2508157789707184 acc= 0.9836516380310059 auc= 0.9856761591453509\n",
      "Test on valid set: loss= 4.802441596984863 acc= 0.699999988079071 auc= 0.8435555555555556\n",
      "\n",
      "Epoch 210/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 8.3951\n",
      "\n",
      "Test on train set: loss= 0.2523321211338043 acc= 0.9834088683128357 auc= 0.9873582801836216\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7200000286102295 auc= 0.8535555555555556\n",
      "\n",
      "Epoch 211/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 7.7805\n",
      "\n",
      "Test on train set: loss= 0.24269719421863556 acc= 0.9840563535690308 auc= 0.988132050354219\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8542222222222222\n",
      "\n",
      "Epoch 212/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 7.2723\n",
      "\n",
      "Test on train set: loss= 0.22869600355625153 acc= 0.9850274920463562 auc= 0.9881495986433346\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 213/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 8.7313\n",
      "\n",
      "Test on train set: loss= 0.2119060754776001 acc= 0.9861605763435364 auc= 0.9871266042381242\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 214/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 8.0541\n",
      "\n",
      "Test on train set: loss= 0.22318270802497864 acc= 0.9855130910873413 auc= 0.9876674323561808\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444444\n",
      "\n",
      "Epoch 215/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 7.7497\n",
      "\n",
      "Test on train set: loss= 0.2200964093208313 acc= 0.9855940341949463 auc= 0.9887935171123197\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 216/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 7.7400\n",
      "\n",
      "Test on train set: loss= 0.19581647217273712 acc= 0.9868080019950867 auc= 0.990439534604859\n",
      "Test on valid set: loss= 3.545980930328369 acc= 0.7800000309944153 auc= 0.8773333333333333\n",
      "\n",
      "Epoch 217/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.2642\n",
      "\n",
      "Test on train set: loss= 0.19039592146873474 acc= 0.9876982569694519 auc= 0.990220807750838\n",
      "Test on valid set: loss= 4.718738555908203 acc= 0.6811988353729248 auc= 0.8728888888888889\n",
      "\n",
      "Epoch 218/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.1051\n",
      "\n",
      "Test on train set: loss= 0.19059456884860992 acc= 0.9876982569694519 auc= 0.9901302361813433\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8546666666666667\n",
      "\n",
      "Epoch 219/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.0945\n",
      "\n",
      "Test on train set: loss= 0.2113846391439438 acc= 0.9860796332359314 auc= 0.9909609272112505\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8662222222222222\n",
      "\n",
      "Epoch 220/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.6147\n",
      "\n",
      "Test on train set: loss= 0.17681092023849487 acc= 0.988426685333252 auc= 0.9902547868415219\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8662222222222222\n",
      "\n",
      "Epoch 221/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 2s - loss: 5.8467\n",
      "\n",
      "Test on train set: loss= 0.18468885123729706 acc= 0.9881029725074768 auc= 0.9893557174930443\n",
      "Test on valid set: loss= 3.868990421295166 acc= 0.7593628168106079 auc= 0.8655555555555555\n",
      "\n",
      "Epoch 222/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.9424\n",
      "\n",
      "Test on train set: loss= 0.16969986259937286 acc= 0.9890741109848022 auc= 0.9898585580650281\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8653333333333333\n",
      "\n",
      "Epoch 223/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.4915\n",
      "\n",
      "Test on train set: loss= 0.16967876255512238 acc= 0.9890741109848022 auc= 0.990999539970395\n",
      "Test on valid set: loss= 3.8746232986450195 acc= 0.7546101808547974 auc= 0.8653333333333334\n",
      "\n",
      "Epoch 224/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.8731\n",
      "\n",
      "Test on train set: loss= 0.16070713102817535 acc= 0.9894787669181824 auc= 0.9900602746214634\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8655555555555555\n",
      "\n",
      "Epoch 225/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.7935\n",
      "\n",
      "Test on train set: loss= 0.16251714527606964 acc= 0.9891550540924072 auc= 0.9895004667780274\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8444444444444444\n",
      "\n",
      "Epoch 226/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.5417\n",
      "\n",
      "Test on train set: loss= 0.1545199751853943 acc= 0.9897215962409973 auc= 0.9896372560502688\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.845111111111111\n",
      "\n",
      "Epoch 227/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.3717\n",
      "\n",
      "Test on train set: loss= 0.1709822565317154 acc= 0.9886694550514221 auc= 0.9884086728675655\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8448888888888888\n",
      "\n",
      "Epoch 228/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.2726\n",
      "\n",
      "Test on train set: loss= 0.1672072857618332 acc= 0.9889122843742371 auc= 0.9874867917460387\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8546666666666667\n",
      "\n",
      "Epoch 229/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.1814\n",
      "\n",
      "Test on train set: loss= 0.15920865535736084 acc= 0.9893978834152222 auc= 0.9886558211023277\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8637777777777778\n",
      "\n",
      "Epoch 230/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 6.4591\n",
      "\n",
      "Test on train set: loss= 0.153030663728714 acc= 0.9901262521743774 auc= 0.9890864096258069\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 231/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.7330\n",
      "\n",
      "Test on train set: loss= 0.1675344556570053 acc= 0.9891550540924072 auc= 0.9897408902399343\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 232/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.0936\n",
      "\n",
      "Test on train set: loss= 0.17968569695949554 acc= 0.988345742225647 auc= 0.9899327406617843\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8673333333333334\n",
      "\n",
      "Epoch 233/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.1142\n",
      "\n",
      "Test on train set: loss= 0.14702042937278748 acc= 0.9901262521743774 auc= 0.9901971861008677\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8533333333333333\n",
      "\n",
      "Epoch 234/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.7724\n",
      "\n",
      "Test on train set: loss= 0.14911532402038574 acc= 0.9899643659591675 auc= 0.9913469412936973\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8651111111111112\n",
      "\n",
      "Epoch 235/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.5809\n",
      "\n",
      "Test on train set: loss= 0.13393107056617737 acc= 0.9910165071487427 auc= 0.992080402256185\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 236/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.1221\n",
      "\n",
      "Test on train set: loss= 0.15021783113479614 acc= 0.9900453090667725 auc= 0.9912468465904583\n",
      "Test on valid set: loss= 3.545980930328369 acc= 0.7800000905990601 auc= 0.8864444444444445\n",
      "\n",
      "Epoch 237/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.6126\n",
      "\n",
      "Test on train set: loss= 0.1399405300617218 acc= 0.9909355640411377 auc= 0.9925826244509486\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8646666666666667\n",
      "\n",
      "Epoch 238/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.1564\n",
      "\n",
      "Test on train set: loss= 0.146473690867424 acc= 0.9907737374305725 auc= 0.9910742322146657\n",
      "Test on valid set: loss= 3.868377685546875 acc= 0.759965181350708 auc= 0.8653333333333333\n",
      "\n",
      "Epoch 239/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.7070\n",
      "\n",
      "Test on train set: loss= 0.1414041966199875 acc= 0.9905309081077576 auc= 0.9924223489786048\n",
      "Test on valid set: loss= 3.545980930328369 acc= 0.7800000309944153 auc= 0.8764444444444445\n",
      "\n",
      "Epoch 240/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.3518\n",
      "\n",
      "Test on train set: loss= 0.15385058522224426 acc= 0.9898025393486023 auc= 0.9893173178167703\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8764444444444445\n",
      "\n",
      "Epoch 241/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.1990\n",
      "\n",
      "Test on train set: loss= 0.13588647544384003 acc= 0.9908546209335327 auc= 0.9910468415887289\n",
      "Test on valid set: loss= 3.5463714599609375 acc= 0.7796131372451782 auc= 0.8766666666666666\n",
      "\n",
      "Epoch 242/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.6433\n",
      "\n",
      "Test on train set: loss= 0.13831877708435059 acc= 0.9906118512153625 auc= 0.9916474537390817\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8751111111111112\n",
      "\n",
      "Epoch 243/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 3.5066\n",
      "\n",
      "Test on train set: loss= 0.12385635823011398 acc= 0.9919067621231079 auc= 0.9925470036994687\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8673333333333334\n",
      "\n",
      "Epoch 244/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.6424\n",
      "\n",
      "Test on train set: loss= 0.12378117442131042 acc= 0.9921495914459229 auc= 0.9903152780890336\n",
      "Test on valid set: loss= 3.974973201751709 acc= 0.7400967478752136 auc= 0.8657777777777778\n",
      "\n",
      "Epoch 245/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.2264\n",
      "\n",
      "Test on train set: loss= 0.13165508210659027 acc= 0.9914211630821228 auc= 0.9923739915808604\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 246/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.4204\n",
      "\n",
      "Test on train set: loss= 0.12644067406654358 acc= 0.9919067621231079 auc= 0.9917969132589542\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 247/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.2352\n",
      "\n",
      "Test on train set: loss= 0.14233186841011047 acc= 0.9908546209335327 auc= 0.9932567613425098\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8655555555555555\n",
      "\n",
      "Epoch 248/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.8311\n",
      "\n",
      "Test on train set: loss= 0.13027769327163696 acc= 0.9914211630821228 auc= 0.9937416171005957\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 249/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 5.1460\n",
      "\n",
      "Test on train set: loss= 0.14339114725589752 acc= 0.9907737374305725 auc= 0.9911603533866373\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 250/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: 4.3943\n",
      "\n",
      "Test on train set: loss= 0.1283186972141266 acc= 0.9915021061897278 auc= 0.9935662747076709\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 251/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.7076\n",
      "\n",
      "Test on train set: loss= 0.13357146084308624 acc= 0.9912593364715576 auc= 0.9934201483847758\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 252/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1304\n",
      "\n",
      "Test on train set: loss= 0.13514485955238342 acc= 0.9909355640411377 auc= 0.9905049478965644\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 253/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.4014\n",
      "\n",
      "Test on train set: loss= 0.12969183921813965 acc= 0.991744875907898 auc= 0.9929022254885724\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8662222222222222\n",
      "\n",
      "Epoch 254/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1334\n",
      "\n",
      "Test on train set: loss= 0.12003927677869797 acc= 0.9920686483383179 auc= 0.9936571650378847\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 255/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 5.5062\n",
      "\n",
      "Test on train set: loss= 0.1280064731836319 acc= 0.9915830492973328 auc= 0.9923795936546306\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 256/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.5329\n",
      "\n",
      "Test on train set: loss= 0.12343181669712067 acc= 0.991744875907898 auc= 0.9931542759559733\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 257/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1385\n",
      "\n",
      "Test on train set: loss= 0.10953765362501144 acc= 0.9927160739898682 auc= 0.9923067833845604\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8673333333333334\n",
      "\n",
      "Epoch 258/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1471\n",
      "\n",
      "Test on train set: loss= 0.1294344663619995 acc= 0.9913402199745178 auc= 0.9925492701133971\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 259/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.0267\n",
      "\n",
      "Test on train set: loss= 0.11775507032871246 acc= 0.9919877052307129 auc= 0.9921945523711715\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8662222222222222\n",
      "\n",
      "Epoch 260/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.3120\n",
      "\n",
      "Test on train set: loss= 0.13712698221206665 acc= 0.9909355640411377 auc= 0.9936954679323005\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 261/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 2.7386\n",
      "\n",
      "Test on train set: loss= 0.11673631519079208 acc= 0.991744875907898 auc= 0.9924858062078457\n",
      "Test on valid set: loss= 3.8683431148529053 acc= 0.7599998116493225 auc= 0.866\n",
      "\n",
      "Epoch 262/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 5.3956\n",
      "\n",
      "Test on train set: loss= 0.12234517931938171 acc= 0.991744875907898 auc= 0.993064236251417\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 263/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.4833\n",
      "\n",
      "Test on train set: loss= 0.11884374171495438 acc= 0.9919877052307129 auc= 0.9930891321481461\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8673333333333334\n",
      "\n",
      "Epoch 264/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.4333\n",
      "\n",
      "Test on train set: loss= 0.12595099210739136 acc= 0.9916639924049377 auc= 0.9942438032802775\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 265/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.0441\n",
      "\n",
      "Test on train set: loss= 0.11686813831329346 acc= 0.992392361164093 auc= 0.9942392275305231\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 266/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5334\n",
      "\n",
      "Test on train set: loss= 0.12791770696640015 acc= 0.9915021061897278 auc= 0.9936870800469974\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 267/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.6756\n",
      "\n",
      "Test on train set: loss= 0.12379772961139679 acc= 0.9919067621231079 auc= 0.993816056060175\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 268/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5542\n",
      "\n",
      "Test on train set: loss= 0.11431657522916794 acc= 0.9926351308822632 auc= 0.9923999888948385\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 269/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.5277\n",
      "\n",
      "Test on train set: loss= 0.1331513375043869 acc= 0.9912593364715576 auc= 0.9926447664783495\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8655555555555555\n",
      "\n",
      "Epoch 270/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1522\n",
      "\n",
      "Test on train set: loss= 0.11693011969327927 acc= 0.9922304749488831 auc= 0.994033183747991\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 271/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.4901\n",
      "\n",
      "Test on train set: loss= 0.09942325949668884 acc= 0.9930398464202881 auc= 0.9932459707549679\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 272/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1320\n",
      "\n",
      "Test on train set: loss= 0.12824514508247375 acc= 0.9913402199745178 auc= 0.990952436214988\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 273/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.0133\n",
      "\n",
      "Test on train set: loss= 0.1433851718902588 acc= 0.9902881383895874 auc= 0.9943414476405927\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 274/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.7168\n",
      "\n",
      "Test on train set: loss= 0.1097748801112175 acc= 0.992554247379303 auc= 0.9931844260953419\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 275/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.0990\n",
      "\n",
      "Test on train set: loss= 0.1154116615653038 acc= 0.992392361164093 auc= 0.9923754874611141\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 276/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 5.4008\n",
      "\n",
      "Test on train set: loss= 0.12524737417697906 acc= 0.9916639924049377 auc= 0.9939059810899181\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 277/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.0708\n",
      "\n",
      "Test on train set: loss= 0.11075940728187561 acc= 0.9928779602050781 auc= 0.9945225489727327\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 278/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.9558\n",
      "\n",
      "Test on train set: loss= 0.11142294853925705 acc= 0.992554247379303 auc= 0.9941139586865703\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 279/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1934\n",
      "\n",
      "Test on train set: loss= 0.12458322942256927 acc= 0.9918258190155029 auc= 0.992665046165771\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8762222222222222\n",
      "\n",
      "Epoch 280/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.6595\n",
      "\n",
      "Test on train set: loss= 0.12618397176265717 acc= 0.991744875907898 auc= 0.9926905841970202\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 281/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 2.8500\n",
      "\n",
      "Test on train set: loss= 0.12254604697227478 acc= 0.9916639924049377 auc= 0.9933317194218168\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8542222222222222\n",
      "\n",
      "Epoch 282/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.1875\n",
      "\n",
      "Test on train set: loss= 0.12983325123786926 acc= 0.9914211630821228 auc= 0.9918963272482617\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 283/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.7654\n",
      "\n",
      "Test on train set: loss= 0.12276232987642288 acc= 0.991744875907898 auc= 0.9931603115900589\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 284/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.6793\n",
      "\n",
      "Test on train set: loss= 0.1115657165646553 acc= 0.9926351308822632 auc= 0.9922366643345744\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 285/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5778\n",
      "\n",
      "Test on train set: loss= 0.10591879487037659 acc= 0.992473304271698 auc= 0.9913516746131352\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 286/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.9282\n",
      "\n",
      "Test on train set: loss= 0.12026182562112808 acc= 0.9922304749488831 auc= 0.9930837637794345\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.866\n",
      "\n",
      "Epoch 287/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.6045\n",
      "\n",
      "Test on train set: loss= 0.1175212562084198 acc= 0.9919067621231079 auc= 0.9941065558026739\n",
      "Test on valid set: loss= 4.51306676864624 acc= 0.7199999690055847 auc= 0.8642222222222223\n",
      "\n",
      "Epoch 288/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5763\n",
      "\n",
      "Test on train set: loss= 0.11930342018604279 acc= 0.9920686483383179 auc= 0.9939300157298836\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8555555555555555\n",
      "\n",
      "Epoch 289/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5324\n",
      "\n",
      "Test on train set: loss= 0.10239923000335693 acc= 0.9928779602050781 auc= 0.9928304822559577\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8673333333333334\n",
      "\n",
      "Epoch 290/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.2646\n",
      "\n",
      "Test on train set: loss= 0.11136900633573532 acc= 0.9926351308822632 auc= 0.9943427433801244\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 291/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.0014\n",
      "\n",
      "Test on train set: loss= 0.11889881640672684 acc= 0.9919877052307129 auc= 0.9931778293204102\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8651111111111112\n",
      "\n",
      "Epoch 292/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.1149\n",
      "\n",
      "Test on train set: loss= 0.11100959032773972 acc= 0.992473304271698 auc= 0.9946637401184729\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 293/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.2340\n",
      "\n",
      "Test on train set: loss= 0.11378888785839081 acc= 0.992392361164093 auc= 0.9945977602593465\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 294/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.0848\n",
      "\n",
      "Test on train set: loss= 0.11263304948806763 acc= 0.9926351308822632 auc= 0.9919960037089457\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 295/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 2.6069\n",
      "\n",
      "Test on train set: loss= 0.10883601754903793 acc= 0.992554247379303 auc= 0.9915572791136038\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "Epoch 296/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.3376\n",
      "\n",
      "Test on train set: loss= 0.11983449757099152 acc= 0.9920686483383179 auc= 0.9920199376834292\n",
      "Test on valid set: loss= 4.3569793701171875 acc= 0.7200049161911011 auc= 0.8551111111111112\n",
      "\n",
      "Epoch 297/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.9770\n",
      "\n",
      "Test on train set: loss= 0.12321823090314865 acc= 0.9919067621231079 auc= 0.9933591500440556\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8666666666666666\n",
      "\n",
      "Epoch 298/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.5031\n",
      "\n",
      "Test on train set: loss= 0.12056488543748856 acc= 0.991744875907898 auc= 0.9937389192699702\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8664444444444446\n",
      "\n",
      "Epoch 299/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 3.3692\n",
      "\n",
      "Test on train set: loss= 0.1027035042643547 acc= 0.9930398464202881 auc= 0.9930132324330376\n",
      "Test on valid set: loss= 3.868342876434326 acc= 0.7600000500679016 auc= 0.8762222222222222\n",
      "\n",
      "Epoch 300/300\n",
      "\n",
      "Reweight\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: 4.2961\n",
      "\n",
      "Test on train set: loss= 0.10901157557964325 acc= 0.9926351308822632 auc= 0.9936710219226242\n",
      "Test on valid set: loss= 4.190704822540283 acc= 0.7400000095367432 auc= 0.8553333333333333\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "encoding_matrix = tf.Variable(tf.eye(10), trainable=False)\n",
    "trainGen = train_generator(epochs, batch_size, encoding_matrix)\n",
    "model.set_weights(pretrainedWeights)\n",
    "model.compile(optimizer=copy.deepcopy(optimizer), loss = loss_fn)\n",
    "\n",
    "metric_idx = 2\n",
    "trainMetrics = (softConfusionMatrix_train[metric_idx], \n",
    "                confusionMatrix_train[metric_idx],loss_train[metric_idx], \n",
    "                acc_train[metric_idx], auc_train[metric_idx])\n",
    "\n",
    "validMetrics = (softConfusionMatrix_valid[metric_idx], \n",
    "                loss_valid[metric_idx], acc_valid[metric_idx], auc_valid[metric_idx])\n",
    "\n",
    "adjust_lr = AdjustLR(\n",
    "      schedule = lr_schedule,\n",
    "      base_learning_rate = lr,\n",
    "  )\n",
    "\n",
    "uemgm = UpdateEncodingMatrixAndGetMetrics_Reweight(beginEncodingEpoch, endEncodingEpoch,  \n",
    "                                               codingEnhancementRate, mu,\n",
    "                                               train_x_no_valid, train_y_no_valid,\n",
    "                                               valid_x, valid_y, trainMetrics, \n",
    "                                               validMetrics, 'Reweight')\n",
    "                        \n",
    "_ = model.fit(trainGen, \n",
    "              initial_epoch = beginEncodingEpoch, \n",
    "              epochs = epochs, verbose = 2,\n",
    "              steps_per_epoch = steps, callbacks=[uemgm,\n",
    "                                             adjust_lr,\n",
    "                                            ])\n",
    "reweightWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.016666668>\n",
      "97/97 - 6s - loss: 1.6921\n",
      "\n",
      "Test on train set: loss= 2.597219228744507 acc= 0.4876982867717743 auc= 0.6743558796445479\n",
      "Test on valid set: loss= 4.762588977813721 acc= 0.1529083549976349 auc= 0.5924444444444444\n",
      "\n",
      "Epoch 2/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.033333335>\n",
      "97/97 - 3s - loss: -1.7093e+00\n",
      "\n",
      "Test on train set: loss= 2.0040078163146973 acc= 0.48996439576148987 auc= 0.722658215769084\n",
      "Test on valid set: loss= 3.34051513671875 acc= 0.1971767693758011 auc= 0.6502222222222221\n",
      "\n",
      "Epoch 3/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.05>\n",
      "97/97 - 3s - loss: -3.0373e+00\n",
      "\n",
      "Test on train set: loss= 1.7175382375717163 acc= 0.6147620677947998 auc= 0.7664882906842747\n",
      "Test on valid set: loss= 2.9739739894866943 acc= 0.2441065013408661 auc= 0.6915555555555556\n",
      "\n",
      "Epoch 4/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.06666667>\n",
      "97/97 - 3s - loss: -4.7113e+00\n",
      "\n",
      "Test on train set: loss= 1.6078115701675415 acc= 0.6572515368461609 auc= 0.8036532088805595\n",
      "Test on valid set: loss= 2.9492790699005127 acc= 0.26171302795410156 auc= 0.687111111111111\n",
      "\n",
      "Epoch 5/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.083333336>\n",
      "97/97 - 3s - loss: -5.5009e+00\n",
      "\n",
      "Test on train set: loss= 1.8548246622085571 acc= 0.6257688403129578 auc= 0.8100149881284622\n",
      "Test on valid set: loss= 2.7094357013702393 acc= 0.2615855932235718 auc= 0.727111111111111\n",
      "\n",
      "Epoch 6/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.3417e+00\n",
      "\n",
      "Test on train set: loss= 1.6215256452560425 acc= 0.6710909605026245 auc= 0.7412175299746362\n",
      "Test on valid set: loss= 4.754843711853027 acc= 0.25763851404190063 auc= 0.6497777777777778\n",
      "\n",
      "Epoch 7/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.7198e+00\n",
      "\n",
      "Test on train set: loss= 1.193484902381897 acc= 0.7168986797332764 auc= 0.8372877726938169\n",
      "Test on valid set: loss= 2.497412919998169 acc= 0.27540913224220276 auc= 0.72\n",
      "\n",
      "Epoch 8/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0380e+00\n",
      "\n",
      "Test on train set: loss= 1.1745036840438843 acc= 0.6778083443641663 auc= 0.8385508660533171\n",
      "Test on valid set: loss= 2.2764432430267334 acc= 0.29712241888046265 auc= 0.7528888888888889\n",
      "\n",
      "Epoch 9/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.8374e+00\n",
      "\n",
      "Test on train set: loss= 1.0409796237945557 acc= 0.738993227481842 auc= 0.8503050519952324\n",
      "Test on valid set: loss= 1.997907280921936 acc= 0.33281344175338745 auc= 0.7839999999999999\n",
      "\n",
      "Epoch 10/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5916e+00\n",
      "\n",
      "Test on train set: loss= 1.040183186531067 acc= 0.7244253754615784 auc= 0.8378670441826026\n",
      "Test on valid set: loss= 2.725476026535034 acc= 0.2947556674480438 auc= 0.752\n",
      "\n",
      "Epoch 11/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.9131e+00\n",
      "\n",
      "Test on train set: loss= 0.8363722562789917 acc= 0.7689381837844849 auc= 0.8602315837287134\n",
      "Test on valid set: loss= 2.167631149291992 acc= 0.3287741541862488 auc= 0.78\n",
      "\n",
      "Epoch 12/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.3552e+00\n",
      "\n",
      "Test on train set: loss= 0.9490208625793457 acc= 0.7632728815078735 auc= 0.8608560578573261\n",
      "Test on valid set: loss= 2.7159411907196045 acc= 0.30783092975616455 auc= 0.7551111111111111\n",
      "\n",
      "Epoch 13/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1884e+00\n",
      "\n",
      "Test on train set: loss= 0.9776492118835449 acc= 0.7597928047180176 auc= 0.8929272431371565\n",
      "Test on valid set: loss= 2.413029193878174 acc= 0.33259132504463196 auc= 0.7955555555555556\n",
      "\n",
      "Epoch 14/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2732e+00\n",
      "\n",
      "Test on train set: loss= 1.0396311283111572 acc= 0.707267701625824 auc= 0.859883958256663\n",
      "Test on valid set: loss= 2.614967107772827 acc= 0.32817497849464417 auc= 0.7631111111111111\n",
      "\n",
      "Epoch 15/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5634e+00\n",
      "\n",
      "Test on train set: loss= 1.0990829467773438 acc= 0.6947231888771057 auc= 0.8757322325606121\n",
      "Test on valid set: loss= 2.539044141769409 acc= 0.2890623211860657 auc= 0.7666666666666667\n",
      "\n",
      "Epoch 16/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0773e+00\n",
      "\n",
      "Test on train set: loss= 1.2685294151306152 acc= 0.7331660985946655 auc= 0.8390208027640064\n",
      "Test on valid set: loss= 2.5313150882720947 acc= 0.354023277759552 auc= 0.7955555555555556\n",
      "\n",
      "Epoch 17/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.1472e+00\n",
      "\n",
      "Test on train set: loss= 0.9939209818840027 acc= 0.7454677820205688 auc= 0.8617495314400239\n",
      "Test on valid set: loss= 2.2688469886779785 acc= 0.3650703728199005 auc= 0.8022222222222222\n",
      "\n",
      "Epoch 18/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.7258e+00\n",
      "\n",
      "Test on train set: loss= 0.9639834761619568 acc= 0.7557461857795715 auc= 0.8669909473902979\n",
      "Test on valid set: loss= 2.8529083728790283 acc= 0.34722599387168884 auc= 0.792888888888889\n",
      "\n",
      "Epoch 19/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5461e+00\n",
      "\n",
      "Test on train set: loss= 0.9186451435089111 acc= 0.7982356548309326 auc= 0.8726556403124951\n",
      "Test on valid set: loss= 3.0871808528900146 acc= 0.38094979524612427 auc= 0.8084444444444445\n",
      "\n",
      "Epoch 20/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2150e+00\n",
      "\n",
      "Test on train set: loss= 1.0194365978240967 acc= 0.7557461857795715 auc= 0.901958450163147\n",
      "Test on valid set: loss= 2.3778200149536133 acc= 0.3525707423686981 auc= 0.828888888888889\n",
      "\n",
      "Epoch 21/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.0164e+00\n",
      "\n",
      "Test on train set: loss= 1.04738187789917 acc= 0.7416639924049377 auc= 0.8703362491708484\n",
      "Test on valid set: loss= 2.813633918762207 acc= 0.30180618166923523 auc= 0.7542222222222222\n",
      "\n",
      "Epoch 22/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.8664e+00\n",
      "\n",
      "Test on train set: loss= 0.9324332475662231 acc= 0.7915992140769958 auc= 0.9156868830418008\n",
      "Test on valid set: loss= 2.6451714038848877 acc= 0.41643109917640686 auc= 0.8413333333333334\n",
      "\n",
      "Epoch 23/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0819e+00\n",
      "\n",
      "Test on train set: loss= 1.4797732830047607 acc= 0.7460343241691589 auc= 0.8870506791887909\n",
      "Test on valid set: loss= 3.622249126434326 acc= 0.35949572920799255 auc= 0.7693333333333333\n",
      "\n",
      "Epoch 24/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.2703e+00\n",
      "\n",
      "Test on train set: loss= 1.0003325939178467 acc= 0.8052768111228943 auc= 0.890401146019219\n",
      "Test on valid set: loss= 2.7387008666992188 acc= 0.38272184133529663 auc= 0.8271111111111111\n",
      "\n",
      "Epoch 25/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.2810e+00\n",
      "\n",
      "Test on train set: loss= 1.3512564897537231 acc= 0.7406927943229675 auc= 0.8586337693147174\n",
      "Test on valid set: loss= 3.2724661827087402 acc= 0.33859983086586 auc= 0.7893333333333333\n",
      "\n",
      "Epoch 26/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.6839e+00\n",
      "\n",
      "Test on train set: loss= 1.6382442712783813 acc= 0.7381029725074768 auc= 0.8466210077375397\n",
      "Test on valid set: loss= 3.303948402404785 acc= 0.4065066874027252 auc= 0.82\n",
      "\n",
      "Epoch 27/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.2273e+00\n",
      "\n",
      "Test on train set: loss= 1.2007733583450317 acc= 0.7566364407539368 auc= 0.8979738806506354\n",
      "Test on valid set: loss= 3.063704252243042 acc= 0.36248579621315 auc= 0.8244444444444445\n",
      "\n",
      "Epoch 28/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.0080e+00\n",
      "\n",
      "Test on train set: loss= 1.3283435106277466 acc= 0.7375364303588867 auc= 0.8909812889120007\n",
      "Test on valid set: loss= 2.0337064266204834 acc= 0.4824400544166565 auc= 0.8786666666666665\n",
      "\n",
      "Epoch 29/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.8604e+00\n",
      "\n",
      "Test on train set: loss= 1.4320989847183228 acc= 0.7725801467895508 auc= 0.8600258430947946\n",
      "Test on valid set: loss= 3.954498291015625 acc= 0.40495723485946655 auc= 0.8022222222222222\n",
      "\n",
      "Epoch 30/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.4206e+00\n",
      "\n",
      "Test on train set: loss= 1.657395362854004 acc= 0.7224829792976379 auc= 0.8385557114356084\n",
      "Test on valid set: loss= 5.683344841003418 acc= 0.3003230094909668 auc= 0.7448888888888889\n",
      "\n",
      "Epoch 31/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.3006e+00\n",
      "\n",
      "Test on train set: loss= 1.195174217224121 acc= 0.7563127279281616 auc= 0.8677252082055478\n",
      "Test on valid set: loss= 2.7275238037109375 acc= 0.4396161139011383 auc= 0.8235555555555555\n",
      "\n",
      "Epoch 32/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0471e+00\n",
      "\n",
      "Test on train set: loss= 1.1170884370803833 acc= 0.7753317952156067 auc= 0.9006129793872949\n",
      "Test on valid set: loss= 2.9691174030303955 acc= 0.38080981373786926 auc= 0.820888888888889\n",
      "\n",
      "Epoch 33/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.4276e+00\n",
      "\n",
      "Test on train set: loss= 1.0271638631820679 acc= 0.785124659538269 auc= 0.895149647677781\n",
      "Test on valid set: loss= 2.717189311981201 acc= 0.3508387804031372 auc= 0.8097777777777779\n",
      "\n",
      "Epoch 34/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.1510e+00\n",
      "\n",
      "Test on train set: loss= 0.8913760185241699 acc= 0.8102136850357056 auc= 0.9208821997844785\n",
      "Test on valid set: loss= 2.9363598823547363 acc= 0.3889816999435425 auc= 0.8315555555555555\n",
      "\n",
      "Epoch 35/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.6927e+00\n",
      "\n",
      "Test on train set: loss= 1.4462612867355347 acc= 0.7376982569694519 auc= 0.8928286675118559\n",
      "Test on valid set: loss= 3.0244128704071045 acc= 0.4438248574733734 auc= 0.7926666666666667\n",
      "\n",
      "Epoch 36/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.7104e+00\n",
      "\n",
      "Test on train set: loss= 1.5687400102615356 acc= 0.7648106217384338 auc= 0.8775273312060643\n",
      "Test on valid set: loss= 3.7347524166107178 acc= 0.3542460799217224 auc= 0.8039999999999999\n",
      "\n",
      "Epoch 37/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.5557e+00\n",
      "\n",
      "Test on train set: loss= 1.3436927795410156 acc= 0.7911945581436157 auc= 0.8788436320992888\n",
      "Test on valid set: loss= 4.945611476898193 acc= 0.3258631229400635 auc= 0.7448888888888889\n",
      "\n",
      "Epoch 38/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.2352e+00\n",
      "\n",
      "Test on train set: loss= 1.4109976291656494 acc= 0.8041437268257141 auc= 0.8988828781796476\n",
      "Test on valid set: loss= 4.477942943572998 acc= 0.3738240599632263 auc= 0.7942222222222222\n",
      "\n",
      "Epoch 39/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.4764e+00\n",
      "\n",
      "Test on train set: loss= 1.184741497039795 acc= 0.791922926902771 auc= 0.8894797155745484\n",
      "Test on valid set: loss= 3.3647336959838867 acc= 0.38375124335289 auc= 0.7793333333333332\n",
      "\n",
      "Epoch 40/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.8420e+00\n",
      "\n",
      "Test on train set: loss= 2.5219533443450928 acc= 0.6787795424461365 auc= 0.8220302959873175\n",
      "Test on valid set: loss= 3.9493415355682373 acc= 0.3287113606929779 auc= 0.7533333333333333\n",
      "\n",
      "Epoch 41/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.3896e+00\n",
      "\n",
      "Test on train set: loss= 1.77104651927948 acc= 0.745791494846344 auc= 0.8681411360960885\n",
      "Test on valid set: loss= 5.1532368659973145 acc= 0.35321247577667236 auc= 0.7582222222222221\n",
      "\n",
      "Epoch 42/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2960e+01\n",
      "\n",
      "Test on train set: loss= 1.4954664707183838 acc= 0.8005827069282532 auc= 0.8925856820981029\n",
      "Test on valid set: loss= 5.256170272827148 acc= 0.34257790446281433 auc= 0.7457777777777779\n",
      "\n",
      "Epoch 43/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.7794e+01\n",
      "\n",
      "Test on train set: loss= 1.5113067626953125 acc= 0.7903043031692505 auc= 0.9031282921255379\n",
      "Test on valid set: loss= 3.9335525035858154 acc= 0.4293753206729889 auc= 0.836\n",
      "\n",
      "Epoch 44/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0318e+01\n",
      "\n",
      "Test on train set: loss= 1.791349172592163 acc= 0.7390741109848022 auc= 0.8968440927430571\n",
      "Test on valid set: loss= 3.833970308303833 acc= 0.4504125714302063 auc= 0.8102222222222222\n",
      "\n",
      "Epoch 45/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2558e+01\n",
      "\n",
      "Test on train set: loss= 3.0001447200775146 acc= 0.6841210722923279 auc= 0.7872541751008992\n",
      "Test on valid set: loss= 7.804998397827148 acc= 0.24542412161827087 auc= 0.7231111111111111\n",
      "\n",
      "Epoch 46/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5495e+01\n",
      "\n",
      "Test on train set: loss= 2.567554235458374 acc= 0.6835545301437378 auc= 0.8890401579655162\n",
      "Test on valid set: loss= 5.597875595092773 acc= 0.3653847277164459 auc= 0.8186666666666668\n",
      "\n",
      "Epoch 47/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0797e+01\n",
      "\n",
      "Test on train set: loss= 2.322112560272217 acc= 0.7280673384666443 auc= 0.8702396177792687\n",
      "Test on valid set: loss= 5.395383358001709 acc= 0.41077661514282227 auc= 0.7753333333333334\n",
      "\n",
      "Epoch 48/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0086e+01\n",
      "\n",
      "Test on train set: loss= 1.3623414039611816 acc= 0.7842344045639038 auc= 0.9140047159461322\n",
      "Test on valid set: loss= 3.217799186706543 acc= 0.4630630910396576 auc= 0.8515555555555556\n",
      "\n",
      "Epoch 49/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1355e+01\n",
      "\n",
      "Test on train set: loss= 1.5492562055587769 acc= 0.7674004435539246 auc= 0.908368660618639\n",
      "Test on valid set: loss= 3.5555427074432373 acc= 0.5097551941871643 auc= 0.8617777777777776\n",
      "\n",
      "Epoch 50/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6709e+01\n",
      "\n",
      "Test on train set: loss= 1.2925853729248047 acc= 0.792651355266571 auc= 0.9084981165928099\n",
      "Test on valid set: loss= 3.583198308944702 acc= 0.44279083609580994 auc= 0.836\n",
      "\n",
      "Epoch 51/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2200e+01\n",
      "\n",
      "Test on train set: loss= 1.2889623641967773 acc= 0.7805114984512329 auc= 0.8921792261667788\n",
      "Test on valid set: loss= 3.9385552406311035 acc= 0.3721979856491089 auc= 0.8088888888888889\n",
      "\n",
      "Epoch 52/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1065e+01\n",
      "\n",
      "Test on train set: loss= 1.4081494808197021 acc= 0.7942699790000916 auc= 0.8863311125660236\n",
      "Test on valid set: loss= 4.359906196594238 acc= 0.3641737699508667 auc= 0.7946666666666667\n",
      "\n",
      "Epoch 53/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.3832e+01\n",
      "\n",
      "Test on train set: loss= 2.1548752784729004 acc= 0.7147944569587708 auc= 0.8742248892157647\n",
      "Test on valid set: loss= 4.804393768310547 acc= 0.35611388087272644 auc= 0.7826666666666667\n",
      "\n",
      "Epoch 54/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.9450e+00\n",
      "\n",
      "Test on train set: loss= 1.281705617904663 acc= 0.7933797240257263 auc= 0.9177055745101244\n",
      "Test on valid set: loss= 2.986473798751831 acc= 0.433903306722641 auc= 0.8648888888888889\n",
      "\n",
      "Epoch 55/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1029e+01\n",
      "\n",
      "Test on train set: loss= 1.7540630102157593 acc= 0.7664292454719543 auc= 0.8582591317534302\n",
      "Test on valid set: loss= 3.9029040336608887 acc= 0.4234685003757477 auc= 0.804888888888889\n",
      "\n",
      "Epoch 56/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2929e+01\n",
      "\n",
      "Test on train set: loss= 2.507847547531128 acc= 0.7057300209999084 auc= 0.898029317386961\n",
      "Test on valid set: loss= 7.186422348022461 acc= 0.3170611262321472 auc= 0.7933333333333333\n",
      "\n",
      "Epoch 57/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1261e+01\n",
      "\n",
      "Test on train set: loss= 1.2937991619110107 acc= 0.7717707753181458 auc= 0.8966582238295514\n",
      "Test on valid set: loss= 5.032551288604736 acc= 0.41080373525619507 auc= 0.7786666666666666\n",
      "\n",
      "Epoch 58/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6288e+01\n",
      "\n",
      "Test on train set: loss= 1.0676932334899902 acc= 0.8393493294715881 auc= 0.9266310871006118\n",
      "Test on valid set: loss= 3.8748884201049805 acc= 0.5013238191604614 auc= 0.8457777777777779\n",
      "\n",
      "Epoch 59/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8729e+01\n",
      "\n",
      "Test on train set: loss= 1.509528636932373 acc= 0.8139365315437317 auc= 0.8913791560858474\n",
      "Test on valid set: loss= 6.349831581115723 acc= 0.3736896812915802 auc= 0.7586666666666667\n",
      "\n",
      "Epoch 60/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4010e+01\n",
      "\n",
      "Test on train set: loss= 1.179106593132019 acc= 0.8284234404563904 auc= 0.9215994894481726\n",
      "Test on valid set: loss= 4.786367416381836 acc= 0.46533212065696716 auc= 0.8257777777777779\n",
      "\n",
      "Epoch 61/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.7893e+01\n",
      "\n",
      "Test on train set: loss= 1.894680142402649 acc= 0.8089187145233154 auc= 0.8993542001829526\n",
      "Test on valid set: loss= 7.201006889343262 acc= 0.32039400935173035 auc= 0.7193333333333334\n",
      "\n",
      "Epoch 62/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4168e+01\n",
      "\n",
      "Test on train set: loss= 1.2995284795761108 acc= 0.8179022073745728 auc= 0.9121573138186682\n",
      "Test on valid set: loss= 4.040110111236572 acc= 0.48381146788597107 auc= 0.845111111111111\n",
      "\n",
      "Epoch 63/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8448e+01\n",
      "\n",
      "Test on train set: loss= 1.2455451488494873 acc= 0.8223535418510437 auc= 0.9373230734447798\n",
      "Test on valid set: loss= 3.6299707889556885 acc= 0.5009262561798096 auc= 0.8493333333333334\n",
      "\n",
      "Epoch 64/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8867e+01\n",
      "\n",
      "Test on train set: loss= 1.8087643384933472 acc= 0.8054386377334595 auc= 0.8972418720509822\n",
      "Test on valid set: loss= 5.582620620727539 acc= 0.44425997138023376 auc= 0.8095555555555556\n",
      "\n",
      "Epoch 65/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6929e+01\n",
      "\n",
      "Test on train set: loss= 2.724013090133667 acc= 0.7359986901283264 auc= 0.7791175260807064\n",
      "Test on valid set: loss= 6.926982402801514 acc= 0.3890334367752075 auc= 0.7299999999999999\n",
      "\n",
      "Epoch 66/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4523e+01\n",
      "\n",
      "Test on train set: loss= 1.9796983003616333 acc= 0.8026060461997986 auc= 0.8768661859826972\n",
      "Test on valid set: loss= 5.356689453125 acc= 0.5020905137062073 auc= 0.7704444444444445\n",
      "\n",
      "Epoch 67/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.9234e+01\n",
      "\n",
      "Test on train set: loss= 2.1398959159851074 acc= 0.7718517184257507 auc= 0.8844677244532431\n",
      "Test on valid set: loss= 4.5301618576049805 acc= 0.4893109202384949 auc= 0.8275555555555556\n",
      "\n",
      "Epoch 68/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1590e+01\n",
      "\n",
      "Test on train set: loss= 1.9963949918746948 acc= 0.7528326511383057 auc= 0.9092765004448691\n",
      "Test on valid set: loss= 3.6603755950927734 acc= 0.5061444640159607 auc= 0.8124444444444444\n",
      "\n",
      "Epoch 69/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.4628e+01\n",
      "\n",
      "Test on train set: loss= 1.3316211700439453 acc= 0.8351408243179321 auc= 0.8878684438785787\n",
      "Test on valid set: loss= 5.485619068145752 acc= 0.46321624517440796 auc= 0.78\n",
      "\n",
      "Epoch 70/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1874e+01\n",
      "\n",
      "Test on train set: loss= 2.301689624786377 acc= 0.7864195704460144 auc= 0.8240531563247986\n",
      "Test on valid set: loss= 5.916804313659668 acc= 0.44643107056617737 auc= 0.7733333333333332\n",
      "\n",
      "Epoch 71/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.1883e+01\n",
      "\n",
      "Test on train set: loss= 1.8521965742111206 acc= 0.7746843695640564 auc= 0.8470819182612445\n",
      "Test on valid set: loss= 5.1015801429748535 acc= 0.4563067853450775 auc= 0.8200000000000001\n",
      "\n",
      "Epoch 72/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8737e+01\n",
      "\n",
      "Test on train set: loss= 2.022663116455078 acc= 0.7858530282974243 auc= 0.8669009615463557\n",
      "Test on valid set: loss= 4.392095565795898 acc= 0.5338081121444702 auc= 0.8324444444444443\n",
      "\n",
      "Epoch 73/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.5547e+01\n",
      "\n",
      "Test on train set: loss= 2.068042039871216 acc= 0.7592262625694275 auc= 0.8784220768289532\n",
      "Test on valid set: loss= 4.159313201904297 acc= 0.4413415491580963 auc= 0.8273333333333331\n",
      "\n",
      "Epoch 74/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8004e+01\n",
      "\n",
      "Test on train set: loss= 1.809897541999817 acc= 0.8032534718513489 auc= 0.8675510546572724\n",
      "Test on valid set: loss= 5.811049938201904 acc= 0.4159933924674988 auc= 0.7857777777777778\n",
      "\n",
      "Epoch 75/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6449e+01\n",
      "\n",
      "Test on train set: loss= 3.9470298290252686 acc= 0.6200226545333862 auc= 0.8081667877405962\n",
      "Test on valid set: loss= 8.156246185302734 acc= 0.37994715571403503 auc= 0.7753333333333333\n",
      "\n",
      "Epoch 76/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5364e+01\n",
      "\n",
      "Test on train set: loss= 1.9408737421035767 acc= 0.773308515548706 auc= 0.8720006868269639\n",
      "Test on valid set: loss= 5.720037937164307 acc= 0.48165565729141235 auc= 0.7857777777777779\n",
      "\n",
      "Epoch 77/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2504e+01\n",
      "\n",
      "Test on train set: loss= 2.1653811931610107 acc= 0.8061670660972595 auc= 0.8648296914416038\n",
      "Test on valid set: loss= 6.591179370880127 acc= 0.5176928639411926 auc= 0.8097777777777779\n",
      "\n",
      "Epoch 78/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5142e+01\n",
      "\n",
      "Test on train set: loss= 2.1170666217803955 acc= 0.8136937618255615 auc= 0.8929012822046897\n",
      "Test on valid set: loss= 7.354224681854248 acc= 0.41259732842445374 auc= 0.7673333333333332\n",
      "\n",
      "Epoch 79/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8637e+01\n",
      "\n",
      "Test on train set: loss= 1.8689351081848145 acc= 0.8145840167999268 auc= 0.8930357755460416\n",
      "Test on valid set: loss= 6.120222091674805 acc= 0.40876665711402893 auc= 0.8186666666666668\n",
      "\n",
      "Epoch 80/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3455e+01\n",
      "\n",
      "Test on train set: loss= 2.0078024864196777 acc= 0.7958077192306519 auc= 0.9345661989094767\n",
      "Test on valid set: loss= 6.665020942687988 acc= 0.4181276261806488 auc= 0.823111111111111\n",
      "\n",
      "Epoch 81/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3092e+01\n",
      "\n",
      "Test on train set: loss= 1.6099486351013184 acc= 0.8017157912254333 auc= 0.9319954696346917\n",
      "Test on valid set: loss= 3.676595687866211 acc= 0.5319792628288269 auc= 0.8753333333333332\n",
      "\n",
      "Epoch 82/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8709e+01\n",
      "\n",
      "Test on train set: loss= 1.5642740726470947 acc= 0.8039819002151489 auc= 0.943569220067117\n",
      "Test on valid set: loss= 4.234058856964111 acc= 0.578666090965271 auc= 0.8511111111111112\n",
      "\n",
      "Epoch 83/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.8604e+01\n",
      "\n",
      "Test on train set: loss= 1.6071689128875732 acc= 0.7944318652153015 auc= 0.9376570650193459\n",
      "Test on valid set: loss= 4.446712493896484 acc= 0.49496394395828247 auc= 0.8537777777777779\n",
      "\n",
      "Epoch 84/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.6717e+01\n",
      "\n",
      "Test on train set: loss= 1.1166627407073975 acc= 0.8402395844459534 auc= 0.9439512837000299\n",
      "Test on valid set: loss= 4.72523832321167 acc= 0.5712772011756897 auc= 0.8240000000000001\n",
      "\n",
      "Epoch 85/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.0011e+01\n",
      "\n",
      "Test on train set: loss= 1.4405014514923096 acc= 0.7948365211486816 auc= 0.9140377326736393\n",
      "Test on valid set: loss= 4.950774192810059 acc= 0.48232945799827576 auc= 0.7917777777777777\n",
      "\n",
      "Epoch 86/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.9196e+01\n",
      "\n",
      "Test on train set: loss= 1.4186713695526123 acc= 0.8291518092155457 auc= 0.886796673167014\n",
      "Test on valid set: loss= 4.26845645904541 acc= 0.4959305226802826 auc= 0.8315555555555555\n",
      "\n",
      "Epoch 87/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3601e+01\n",
      "\n",
      "Test on train set: loss= 1.705165982246399 acc= 0.8027678728103638 auc= 0.9305759543921399\n",
      "Test on valid set: loss= 4.32667350769043 acc= 0.5695192217826843 auc= 0.8697777777777779\n",
      "\n",
      "Epoch 88/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.3671e+01\n",
      "\n",
      "Test on train set: loss= 1.2790699005126953 acc= 0.8247814774513245 auc= 0.9274678502336856\n",
      "Test on valid set: loss= 4.527561187744141 acc= 0.5003802180290222 auc= 0.8242222222222223\n",
      "\n",
      "Epoch 89/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.4904e+01\n",
      "\n",
      "Test on train set: loss= 1.3117090463638306 acc= 0.8268857002258301 auc= 0.9037043504844025\n",
      "Test on valid set: loss= 4.914261341094971 acc= 0.43661290407180786 auc= 0.8297777777777778\n",
      "\n",
      "Epoch 90/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.5164e+01\n",
      "\n",
      "Test on train set: loss= 2.8168678283691406 acc= 0.7677241563796997 auc= 0.8726831968928875\n",
      "Test on valid set: loss= 7.734644889831543 acc= 0.38409191370010376 auc= 0.7797777777777778\n",
      "\n",
      "Epoch 91/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1957e+01\n",
      "\n",
      "Test on train set: loss= 2.374103546142578 acc= 0.7567983269691467 auc= 0.8887970532279328\n",
      "Test on valid set: loss= 6.681145191192627 acc= 0.43647637963294983 auc= 0.7733333333333334\n",
      "\n",
      "Epoch 92/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.9358e+01\n",
      "\n",
      "Test on train set: loss= 2.6408915519714355 acc= 0.7377792000770569 auc= 0.8684191395971987\n",
      "Test on valid set: loss= 7.0819573402404785 acc= 0.4095079302787781 auc= 0.7904444444444445\n",
      "\n",
      "Epoch 93/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.6732e+01\n",
      "\n",
      "Test on train set: loss= 2.025411367416382 acc= 0.8106183409690857 auc= 0.888565615058924\n",
      "Test on valid set: loss= 6.348618984222412 acc= 0.4972218871116638 auc= 0.821111111111111\n",
      "\n",
      "Epoch 94/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.4201e+01\n",
      "\n",
      "Test on train set: loss= 2.674867630004883 acc= 0.7860149145126343 auc= 0.8887169127078665\n",
      "Test on valid set: loss= 6.583242893218994 acc= 0.4664781987667084 auc= 0.8322222222222223\n",
      "\n",
      "Epoch 95/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.8239e+01\n",
      "\n",
      "Test on train set: loss= 1.5418505668640137 acc= 0.8546454906463623 auc= 0.93778822311785\n",
      "Test on valid set: loss= 6.032930850982666 acc= 0.49898624420166016 auc= 0.8488888888888889\n",
      "\n",
      "Epoch 96/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.9545e+01\n",
      "\n",
      "Test on train set: loss= 1.7959259748458862 acc= 0.8315798044204712 auc= 0.9442918961383725\n",
      "Test on valid set: loss= 6.955607891082764 acc= 0.44247597455978394 auc= 0.8246666666666668\n",
      "\n",
      "Epoch 97/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.1270e+01\n",
      "\n",
      "Test on train set: loss= 1.680645227432251 acc= 0.8409679532051086 auc= 0.9205335007736639\n",
      "Test on valid set: loss= 5.872586727142334 acc= 0.5455489158630371 auc= 0.8446666666666666\n",
      "\n",
      "Epoch 98/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.6064e+01\n",
      "\n",
      "Test on train set: loss= 1.5606863498687744 acc= 0.8429912328720093 auc= 0.929587006575187\n",
      "Test on valid set: loss= 6.643879413604736 acc= 0.4453316330909729 auc= 0.7939999999999999\n",
      "\n",
      "Epoch 99/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.6755e+01\n",
      "\n",
      "Test on train set: loss= 2.254918098449707 acc= 0.7864195704460144 auc= 0.9098000754522133\n",
      "Test on valid set: loss= 8.26495361328125 acc= 0.3808977007865906 auc= 0.7915555555555556\n",
      "\n",
      "Epoch 100/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2188e+01\n",
      "\n",
      "Test on train set: loss= 1.9104136228561401 acc= 0.823081910610199 auc= 0.916413727971574\n",
      "Test on valid set: loss= 6.094794750213623 acc= 0.4984115660190582 auc= 0.8275555555555556\n",
      "\n",
      "Epoch 101/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.3725e+01\n",
      "\n",
      "Test on train set: loss= 1.6259022951126099 acc= 0.8451764583587646 auc= 0.9416973640857405\n",
      "Test on valid set: loss= 5.173846244812012 acc= 0.5675783753395081 auc= 0.8517777777777777\n",
      "\n",
      "Epoch 102/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.6206e+01\n",
      "\n",
      "Test on train set: loss= 1.590195655822754 acc= 0.8475234508514404 auc= 0.9305851957835187\n",
      "Test on valid set: loss= 5.371847152709961 acc= 0.5481821298599243 auc= 0.8575555555555556\n",
      "\n",
      "Epoch 103/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.2346e+01\n",
      "\n",
      "Test on train set: loss= 2.5983998775482178 acc= 0.7750080823898315 auc= 0.8848603716655561\n",
      "Test on valid set: loss= 4.720870494842529 acc= 0.6126151084899902 auc= 0.8546666666666667\n",
      "\n",
      "Epoch 104/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -2.5138e+01\n",
      "\n",
      "Test on train set: loss= 1.6402783393859863 acc= 0.8451764583587646 auc= 0.8858782003864067\n",
      "Test on valid set: loss= 5.473543167114258 acc= 0.5564760565757751 auc= 0.8346666666666668\n",
      "\n",
      "Epoch 105/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 2s - loss: -3.0713e+01\n",
      "\n",
      "Test on train set: loss= 1.395276427268982 acc= 0.8622531294822693 auc= 0.9437666990452704\n",
      "Test on valid set: loss= 5.412517070770264 acc= 0.610336422920227 auc= 0.8386666666666667\n",
      "\n",
      "Epoch 106/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.8471e+01\n",
      "\n",
      "Test on train set: loss= 1.8600455522537231 acc= 0.8320654034614563 auc= 0.9351384196209158\n",
      "Test on valid set: loss= 6.362114429473877 acc= 0.5132754445075989 auc= 0.8524444444444444\n",
      "\n",
      "Epoch 107/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.4990e+01\n",
      "\n",
      "Test on train set: loss= 1.4620652198791504 acc= 0.8556166887283325 auc= 0.9390531777225666\n",
      "Test on valid set: loss= 6.612371921539307 acc= 0.5315804481506348 auc= 0.8502222222222222\n",
      "\n",
      "Epoch 108/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -4.5492e+01\n",
      "\n",
      "Test on train set: loss= 1.9458714723587036 acc= 0.8028488159179688 auc= 0.925708628373985\n",
      "Test on valid set: loss= 5.680278301239014 acc= 0.5295093059539795 auc= 0.8631111111111112\n",
      "\n",
      "Epoch 109/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -3.8964e+01\n",
      "\n",
      "Test on train set: loss= 1.7116215229034424 acc= 0.8385399580001831 auc= 0.9275252186827482\n",
      "Test on valid set: loss= 6.43344259262085 acc= 0.46314001083374023 auc= 0.806\n",
      "\n",
      "Epoch 110/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.6116e+01\n",
      "\n",
      "Test on train set: loss= 1.8255736827850342 acc= 0.834655225276947 auc= 0.9415178120108223\n",
      "Test on valid set: loss= 5.531975746154785 acc= 0.503623902797699 auc= 0.8604444444444445\n",
      "\n",
      "Epoch 111/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0380e+01\n",
      "\n",
      "Test on train set: loss= 1.8215305805206299 acc= 0.8296374082565308 auc= 0.8902915466191373\n",
      "Test on valid set: loss= 6.011415004730225 acc= 0.5011337995529175 auc= 0.7975555555555556\n",
      "\n",
      "Epoch 112/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0789e+01\n",
      "\n",
      "Test on train set: loss= 2.4584903717041016 acc= 0.7705568075180054 auc= 0.918297340600003\n",
      "Test on valid set: loss= 6.133415699005127 acc= 0.5252423882484436 auc= 0.8424444444444446\n",
      "\n",
      "Epoch 113/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.5535e+01\n",
      "\n",
      "Test on train set: loss= 2.2936902046203613 acc= 0.8101327419281006 auc= 0.9222757668461299\n",
      "Test on valid set: loss= 4.908374309539795 acc= 0.5475425720214844 auc= 0.8851111111111111\n",
      "\n",
      "Epoch 114/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.3707e+01\n",
      "\n",
      "Test on train set: loss= 1.9154409170150757 acc= 0.8192780613899231 auc= 0.9244972573911825\n",
      "Test on valid set: loss= 6.345797538757324 acc= 0.4705190658569336 auc= 0.816888888888889\n",
      "\n",
      "Epoch 115/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.1794e+01\n",
      "\n",
      "Test on train set: loss= 1.8836379051208496 acc= 0.8280187845230103 auc= 0.8926032681509272\n",
      "Test on valid set: loss= 8.023863792419434 acc= 0.42717957496643066 auc= 0.7451111111111112\n",
      "\n",
      "Epoch 116/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.5172e+01\n",
      "\n",
      "Test on train set: loss= 2.083740472793579 acc= 0.8412916660308838 auc= 0.8636101093427315\n",
      "Test on valid set: loss= 8.237361907958984 acc= 0.45502281188964844 auc= 0.7584444444444445\n",
      "\n",
      "Epoch 117/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0292e+02\n",
      "\n",
      "Test on train set: loss= 2.828749179840088 acc= 0.7942699790000916 auc= 0.8672507172569169\n",
      "Test on valid set: loss= 7.164371490478516 acc= 0.5217464566230774 auc= 0.7662222222222222\n",
      "\n",
      "Epoch 118/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.1046e+01\n",
      "\n",
      "Test on train set: loss= 2.424302101135254 acc= 0.7760602235794067 auc= 0.8994706290675983\n",
      "Test on valid set: loss= 6.964258193969727 acc= 0.48100709915161133 auc= 0.7742222222222221\n",
      "\n",
      "Epoch 119/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0823e+01\n",
      "\n",
      "Test on train set: loss= 1.8472633361816406 acc= 0.8325510025024414 auc= 0.9169040318581463\n",
      "Test on valid set: loss= 6.807712554931641 acc= 0.5260049104690552 auc= 0.8088888888888889\n",
      "\n",
      "Epoch 120/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9431e+01\n",
      "\n",
      "Test on train set: loss= 1.8773624897003174 acc= 0.823081910610199 auc= 0.8978728511210164\n",
      "Test on valid set: loss= 5.244960308074951 acc= 0.5520265698432922 auc= 0.8177777777777779\n",
      "\n",
      "Epoch 121/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.2240e+01\n",
      "\n",
      "Test on train set: loss= 1.6831293106079102 acc= 0.8370022773742676 auc= 0.9243314377239148\n",
      "Test on valid set: loss= 5.334561824798584 acc= 0.5299886465072632 auc= 0.8608888888888888\n",
      "\n",
      "Epoch 122/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6770e+01\n",
      "\n",
      "Test on train set: loss= 1.6990693807601929 acc= 0.8436387181282043 auc= 0.9303555456015558\n",
      "Test on valid set: loss= 5.3866286277771 acc= 0.5153348445892334 auc= 0.8495555555555555\n",
      "\n",
      "Epoch 123/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.1400e+01\n",
      "\n",
      "Test on train set: loss= 1.8034429550170898 acc= 0.8434768319129944 auc= 0.8819120638327597\n",
      "Test on valid set: loss= 7.751696586608887 acc= 0.43727588653564453 auc= 0.7173333333333334\n",
      "\n",
      "Epoch 124/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.5327e+01\n",
      "\n",
      "Test on train set: loss= 1.9660425186157227 acc= 0.8178213238716125 auc= 0.8910093809939805\n",
      "Test on valid set: loss= 6.231475830078125 acc= 0.5064405202865601 auc= 0.8308888888888889\n",
      "\n",
      "Epoch 125/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.3129e+01\n",
      "\n",
      "Test on train set: loss= 2.2613983154296875 acc= 0.8159598708152771 auc= 0.8525339587264803\n",
      "Test on valid set: loss= 7.15902042388916 acc= 0.48399463295936584 auc= 0.8304444444444444\n",
      "\n",
      "Epoch 126/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.0641e+01\n",
      "\n",
      "Test on train set: loss= 2.262082576751709 acc= 0.8115895390510559 auc= 0.88056782330195\n",
      "Test on valid set: loss= 8.727413177490234 acc= 0.3411576747894287 auc= 0.8019999999999999\n",
      "\n",
      "Epoch 127/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.0629e+01\n",
      "\n",
      "Test on train set: loss= 1.726752758026123 acc= 0.8463094830513 auc= 0.9297490813998479\n",
      "Test on valid set: loss= 7.177459716796875 acc= 0.49379006028175354 auc= 0.8217777777777776\n",
      "\n",
      "Epoch 128/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6508e+01\n",
      "\n",
      "Test on train set: loss= 1.9286649227142334 acc= 0.8473616242408752 auc= 0.9228728621469164\n",
      "Test on valid set: loss= 6.164974212646484 acc= 0.5585929155349731 auc= 0.8295555555555556\n",
      "\n",
      "Epoch 129/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.1974e+01\n",
      "\n",
      "Test on train set: loss= 1.4413737058639526 acc= 0.8751214146614075 auc= 0.9509204683587752\n",
      "Test on valid set: loss= 5.520150661468506 acc= 0.5422013998031616 auc= 0.8371111111111113\n",
      "\n",
      "Epoch 130/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.1907e+01\n",
      "\n",
      "Test on train set: loss= 1.364635705947876 acc= 0.8723697066307068 auc= 0.9514505487762437\n",
      "Test on valid set: loss= 5.2754058837890625 acc= 0.5629326701164246 auc= 0.8753333333333334\n",
      "\n",
      "Epoch 131/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.6383e+01\n",
      "\n",
      "Test on train set: loss= 2.051060914993286 acc= 0.8115895390510559 auc= 0.9431685426538708\n",
      "Test on valid set: loss= 4.87505578994751 acc= 0.5850143432617188 auc= 0.9115555555555558\n",
      "\n",
      "Epoch 132/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9084e+01\n",
      "\n",
      "Test on train set: loss= 1.4042551517486572 acc= 0.8350598812103271 auc= 0.9382969607252084\n",
      "Test on valid set: loss= 6.918941020965576 acc= 0.47949743270874023 auc= 0.8571111111111112\n",
      "\n",
      "Epoch 133/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.6882e+01\n",
      "\n",
      "Test on train set: loss= 1.6862038373947144 acc= 0.8438814878463745 auc= 0.9162970947131882\n",
      "Test on valid set: loss= 6.1439690589904785 acc= 0.5564203262329102 auc= 0.8453333333333333\n",
      "\n",
      "Epoch 134/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.4998e+01\n",
      "\n",
      "Test on train set: loss= 2.8601818084716797 acc= 0.7763029932975769 auc= 0.8395909484446286\n",
      "Test on valid set: loss= 8.769023895263672 acc= 0.3969186842441559 auc= 0.761111111111111\n",
      "\n",
      "Epoch 135/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.6461e+01\n",
      "\n",
      "Test on train set: loss= 1.6027661561965942 acc= 0.8625769019126892 auc= 0.9179934993034445\n",
      "Test on valid set: loss= 5.366485595703125 acc= 0.6164132356643677 auc= 0.8473333333333335\n",
      "\n",
      "Epoch 136/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.5358e+01\n",
      "\n",
      "Test on train set: loss= 1.692680835723877 acc= 0.8531887531280518 auc= 0.9350545977757362\n",
      "Test on valid set: loss= 5.939875602722168 acc= 0.5601240396499634 auc= 0.8624444444444445\n",
      "\n",
      "Epoch 137/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.5227e+01\n",
      "\n",
      "Test on train set: loss= 1.9409066438674927 acc= 0.8476853370666504 auc= 0.9329495874491958\n",
      "Test on valid set: loss= 5.608175277709961 acc= 0.5630416870117188 auc= 0.8600000000000001\n",
      "\n",
      "Epoch 138/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.3971e+01\n",
      "\n",
      "Test on train set: loss= 2.6829285621643066 acc= 0.7901424169540405 auc= 0.8748546172039393\n",
      "Test on valid set: loss= 7.193833827972412 acc= 0.49351367354393005 auc= 0.8337777777777777\n",
      "\n",
      "Epoch 139/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.9270e+01\n",
      "\n",
      "Test on train set: loss= 2.1069793701171875 acc= 0.8243768215179443 auc= 0.8544834900308619\n",
      "Test on valid set: loss= 6.74688720703125 acc= 0.4940694272518158 auc= 0.7993333333333335\n",
      "\n",
      "Epoch 140/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.4970e+01\n",
      "\n",
      "Test on train set: loss= 1.926908016204834 acc= 0.8407251834869385 auc= 0.9208329908753683\n",
      "Test on valid set: loss= 7.146087646484375 acc= 0.5180696249008179 auc= 0.7853333333333333\n",
      "\n",
      "Epoch 141/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.5775e+01\n",
      "\n",
      "Test on train set: loss= 2.296868085861206 acc= 0.8260763883590698 auc= 0.9243828416497344\n",
      "Test on valid set: loss= 5.933150768280029 acc= 0.617803692817688 auc= 0.8633333333333335\n",
      "\n",
      "Epoch 142/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.7753e+01\n",
      "\n",
      "Test on train set: loss= 1.9364551305770874 acc= 0.8337649703025818 auc= 0.9475090104550257\n",
      "Test on valid set: loss= 6.201776504516602 acc= 0.5783582925796509 auc= 0.8751111111111112\n",
      "\n",
      "Epoch 143/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.9121e+01\n",
      "\n",
      "Test on train set: loss= 1.8538340330123901 acc= 0.8319035172462463 auc= 0.9423422973103854\n",
      "Test on valid set: loss= 7.454986572265625 acc= 0.4450114369392395 auc= 0.8408888888888889\n",
      "\n",
      "Epoch 144/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.8822e+01\n",
      "\n",
      "Test on train set: loss= 1.7224152088165283 acc= 0.8393493294715881 auc= 0.923027307004879\n",
      "Test on valid set: loss= 5.7238616943359375 acc= 0.5440450310707092 auc= 0.8184444444444445\n",
      "\n",
      "Epoch 145/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.3535e+01\n",
      "\n",
      "Test on train set: loss= 1.8733093738555908 acc= 0.842343807220459 auc= 0.9420964642707128\n",
      "Test on valid set: loss= 7.591726303100586 acc= 0.4145691394805908 auc= 0.8204444444444444\n",
      "\n",
      "Epoch 146/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -5.3866e+01\n",
      "\n",
      "Test on train set: loss= 1.9069783687591553 acc= 0.8310942053794861 auc= 0.925389454885057\n",
      "Test on valid set: loss= 5.878636360168457 acc= 0.5226795673370361 auc= 0.8722222222222223\n",
      "\n",
      "Epoch 147/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.1997e+01\n",
      "\n",
      "Test on train set: loss= 2.013073205947876 acc= 0.8471997380256653 auc= 0.9275009829274248\n",
      "Test on valid set: loss= 6.752625942230225 acc= 0.5259677171707153 auc= 0.8484444444444446\n",
      "\n",
      "Epoch 148/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.7526e+01\n",
      "\n",
      "Test on train set: loss= 1.6020952463150024 acc= 0.857478141784668 auc= 0.9533901354211645\n",
      "Test on valid set: loss= 6.613402843475342 acc= 0.5371469259262085 auc= 0.8295555555555556\n",
      "\n",
      "Epoch 149/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.5034e+01\n",
      "\n",
      "Test on train set: loss= 1.6292445659637451 acc= 0.8675947189331055 auc= 0.953706441711731\n",
      "Test on valid set: loss= 7.272714614868164 acc= 0.45611414313316345 auc= 0.8071111111111111\n",
      "\n",
      "Epoch 150/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2196e+02\n",
      "\n",
      "Test on train set: loss= 1.694731593132019 acc= 0.8684040307998657 auc= 0.9256501692956576\n",
      "Test on valid set: loss= 4.857640266418457 acc= 0.6570664644241333 auc= 0.9008888888888889\n",
      "\n",
      "Epoch 151/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2813e+02\n",
      "\n",
      "Test on train set: loss= 1.9960733652114868 acc= 0.8502751588821411 auc= 0.9398766803583453\n",
      "Test on valid set: loss= 6.38955545425415 acc= 0.5615037083625793 auc= 0.8699999999999999\n",
      "\n",
      "Epoch 152/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0272e+02\n",
      "\n",
      "Test on train set: loss= 1.8421112298965454 acc= 0.8454192280769348 auc= 0.9521861365986333\n",
      "Test on valid set: loss= 5.468569278717041 acc= 0.5774326920509338 auc= 0.8617777777777779\n",
      "\n",
      "Epoch 153/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2155e+02\n",
      "\n",
      "Test on train set: loss= 1.779778003692627 acc= 0.8651667237281799 auc= 0.9462104601408103\n",
      "Test on valid set: loss= 6.409417152404785 acc= 0.5733810663223267 auc= 0.858\n",
      "\n",
      "Epoch 154/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.0130e+01\n",
      "\n",
      "Test on train set: loss= 1.7008997201919556 acc= 0.869294285774231 auc= 0.9283897482860818\n",
      "Test on valid set: loss= 7.143084526062012 acc= 0.5005553960800171 auc= 0.8102222222222222\n",
      "\n",
      "Epoch 155/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.1999e+01\n",
      "\n",
      "Test on train set: loss= 2.0894594192504883 acc= 0.8472806811332703 auc= 0.8867597278272037\n",
      "Test on valid set: loss= 7.336812973022461 acc= 0.5137952566146851 auc= 0.7935555555555556\n",
      "\n",
      "Epoch 156/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.8812e+01\n",
      "\n",
      "Test on train set: loss= 2.514209747314453 acc= 0.8084331750869751 auc= 0.8893078447753247\n",
      "Test on valid set: loss= 6.8860368728637695 acc= 0.5276557207107544 auc= 0.824888888888889\n",
      "\n",
      "Epoch 157/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.4385e+01\n",
      "\n",
      "Test on train set: loss= 1.565383791923523 acc= 0.8710747957229614 auc= 0.8870837097067781\n",
      "Test on valid set: loss= 6.035024642944336 acc= 0.5699570775032043 auc= 0.812\n",
      "\n",
      "Epoch 158/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.2871e+01\n",
      "\n",
      "Test on train set: loss= 1.528906226158142 acc= 0.8764163255691528 auc= 0.9285463896873889\n",
      "Test on valid set: loss= 6.115792274475098 acc= 0.5675682425498962 auc= 0.8504444444444443\n",
      "\n",
      "Epoch 159/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.7364e+01\n",
      "\n",
      "Test on train set: loss= 1.4499471187591553 acc= 0.8770637512207031 auc= 0.9474692109495386\n",
      "Test on valid set: loss= 5.990493297576904 acc= 0.5822854042053223 auc= 0.874\n",
      "\n",
      "Epoch 160/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.1773e+01\n",
      "\n",
      "Test on train set: loss= 2.258624792098999 acc= 0.8332793712615967 auc= 0.9189240260265059\n",
      "Test on valid set: loss= 7.085007190704346 acc= 0.5496441125869751 auc= 0.8357777777777778\n",
      "\n",
      "Epoch 161/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -6.4574e+01\n",
      "\n",
      "Test on train set: loss= 1.7026323080062866 acc= 0.8559404611587524 auc= 0.9359866281240162\n",
      "Test on valid set: loss= 5.8838887214660645 acc= 0.5878551006317139 auc= 0.8724444444444444\n",
      "\n",
      "Epoch 162/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.0524e+01\n",
      "\n",
      "Test on train set: loss= 1.582183599472046 acc= 0.8676756024360657 auc= 0.9452289334389997\n",
      "Test on valid set: loss= 6.098149299621582 acc= 0.5437922477722168 auc= 0.8615555555555556\n",
      "\n",
      "Epoch 163/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.5131e+01\n",
      "\n",
      "Test on train set: loss= 1.3215049505233765 acc= 0.8865328431129456 auc= 0.921963621789984\n",
      "Test on valid set: loss= 4.878292560577393 acc= 0.639009952545166 auc= 0.8886666666666667\n",
      "\n",
      "Epoch 164/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0193e+02\n",
      "\n",
      "Test on train set: loss= 1.5526762008666992 acc= 0.8792489767074585 auc= 0.910897657157277\n",
      "Test on valid set: loss= 6.230059623718262 acc= 0.5708521604537964 auc= 0.8328888888888889\n",
      "\n",
      "Epoch 165/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.1411e+01\n",
      "\n",
      "Test on train set: loss= 1.0259721279144287 acc= 0.9070896506309509 auc= 0.9608168637901168\n",
      "Test on valid set: loss= 5.410735607147217 acc= 0.5622521042823792 auc= 0.898\n",
      "\n",
      "Epoch 166/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.4592e+01\n",
      "\n",
      "Test on train set: loss= 1.5882785320281982 acc= 0.8711557388305664 auc= 0.9274364150746809\n",
      "Test on valid set: loss= 6.8349080085754395 acc= 0.5357401967048645 auc= 0.8688888888888888\n",
      "\n",
      "Epoch 167/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.2968e+01\n",
      "\n",
      "Test on train set: loss= 1.4565229415893555 acc= 0.8789252042770386 auc= 0.9222133370145607\n",
      "Test on valid set: loss= 7.169564247131348 acc= 0.5036465525627136 auc= 0.8542222222222223\n",
      "\n",
      "Epoch 168/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.9439e+01\n",
      "\n",
      "Test on train set: loss= 1.1933937072753906 acc= 0.8966494202613831 auc= 0.9444763342105933\n",
      "Test on valid set: loss= 5.144588470458984 acc= 0.6428781747817993 auc= 0.8953333333333331\n",
      "\n",
      "Epoch 169/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.2734e+01\n",
      "\n",
      "Test on train set: loss= 1.2614198923110962 acc= 0.8973777890205383 auc= 0.9538428226363939\n",
      "Test on valid set: loss= 4.627222537994385 acc= 0.6083491444587708 auc= 0.9039999999999999\n",
      "\n",
      "Epoch 170/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.9116e+01\n",
      "\n",
      "Test on train set: loss= 1.1447234153747559 acc= 0.9039332866668701 auc= 0.9452799392714282\n",
      "Test on valid set: loss= 5.3738861083984375 acc= 0.6201272010803223 auc= 0.8882222222222221\n",
      "\n",
      "Epoch 171/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.7253e+01\n",
      "\n",
      "Test on train set: loss= 1.1456472873687744 acc= 0.9065231680870056 auc= 0.9524386543376039\n",
      "Test on valid set: loss= 5.018789768218994 acc= 0.6599991321563721 auc= 0.884\n",
      "\n",
      "Epoch 172/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.3950e+01\n",
      "\n",
      "Test on train set: loss= 1.496111512184143 acc= 0.8797345161437988 auc= 0.9338952549795347\n",
      "Test on valid set: loss= 5.9256157875061035 acc= 0.5747408866882324 auc= 0.8675555555555554\n",
      "\n",
      "Epoch 173/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.5441e+01\n",
      "\n",
      "Test on train set: loss= 1.2415133714675903 acc= 0.9009388089179993 auc= 0.9185590310627456\n",
      "Test on valid set: loss= 6.637086391448975 acc= 0.5799943208694458 auc= 0.8491111111111111\n",
      "\n",
      "Epoch 174/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.7199e+01\n",
      "\n",
      "Test on train set: loss= 1.371429443359375 acc= 0.8891226649284363 auc= 0.9474536481025451\n",
      "Test on valid set: loss= 6.039251804351807 acc= 0.6009021997451782 auc= 0.8824444444444446\n",
      "\n",
      "Epoch 175/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.7681e+01\n",
      "\n",
      "Test on train set: loss= 1.5273579359054565 acc= 0.8817578554153442 auc= 0.9557157766849524\n",
      "Test on valid set: loss= 5.946982383728027 acc= 0.6026949882507324 auc= 0.8622222222222222\n",
      "\n",
      "Epoch 176/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.5841e+01\n",
      "\n",
      "Test on train set: loss= 1.3003051280975342 acc= 0.90425705909729 auc= 0.9446039386213577\n",
      "Test on valid set: loss= 6.261127471923828 acc= 0.5998595356941223 auc= 0.826\n",
      "\n",
      "Epoch 177/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.5621e+01\n",
      "\n",
      "Test on train set: loss= 1.9615577459335327 acc= 0.854159951210022 auc= 0.8993143040226595\n",
      "Test on valid set: loss= 7.462051868438721 acc= 0.48077186942100525 auc= 0.8393333333333333\n",
      "\n",
      "Epoch 178/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.3780e+01\n",
      "\n",
      "Test on train set: loss= 1.2745610475540161 acc= 0.8975396752357483 auc= 0.9577499213990311\n",
      "Test on valid set: loss= 5.1112847328186035 acc= 0.6170262098312378 auc= 0.8875555555555558\n",
      "\n",
      "Epoch 179/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.2736e+01\n",
      "\n",
      "Test on train set: loss= 1.4638983011245728 acc= 0.8866137862205505 auc= 0.9455231815369466\n",
      "Test on valid set: loss= 4.811044216156006 acc= 0.6429005265235901 auc= 0.8915555555555554\n",
      "\n",
      "Epoch 180/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.8464e+01\n",
      "\n",
      "Test on train set: loss= 1.469809651374817 acc= 0.8823243975639343 auc= 0.9319340004743031\n",
      "Test on valid set: loss= 5.955977916717529 acc= 0.5656204223632812 auc= 0.858888888888889\n",
      "\n",
      "Epoch 181/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0217e+02\n",
      "\n",
      "Test on train set: loss= 1.4552273750305176 acc= 0.8851569890975952 auc= 0.9420395008544006\n",
      "Test on valid set: loss= 6.040815353393555 acc= 0.5833657383918762 auc= 0.8575555555555555\n",
      "\n",
      "Epoch 182/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0500e+02\n",
      "\n",
      "Test on train set: loss= 1.5758143663406372 acc= 0.8754451274871826 auc= 0.9382731269585193\n",
      "Test on valid set: loss= 4.373763084411621 acc= 0.6782202124595642 auc= 0.918888888888889\n",
      "\n",
      "Epoch 183/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1584e+02\n",
      "\n",
      "Test on train set: loss= 1.6095050573349 acc= 0.873421847820282 auc= 0.939691471808229\n",
      "Test on valid set: loss= 5.364187717437744 acc= 0.597053050994873 auc= 0.9071111111111112\n",
      "\n",
      "Epoch 184/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.5991e+01\n",
      "\n",
      "Test on train set: loss= 1.7245985269546509 acc= 0.8685658574104309 auc= 0.9086144540034133\n",
      "Test on valid set: loss= 5.971531867980957 acc= 0.5981075763702393 auc= 0.8513333333333334\n",
      "\n",
      "Epoch 185/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.3148e+01\n",
      "\n",
      "Test on train set: loss= 2.0401456356048584 acc= 0.8480090498924255 auc= 0.8932412502263993\n",
      "Test on valid set: loss= 5.4073381423950195 acc= 0.5910146236419678 auc= 0.844\n",
      "\n",
      "Epoch 186/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1040e+02\n",
      "\n",
      "Test on train set: loss= 1.4636677503585815 acc= 0.8881515264511108 auc= 0.9515039867780655\n",
      "Test on valid set: loss= 6.964041709899902 acc= 0.5409654974937439 auc= 0.8562222222222221\n",
      "\n",
      "Epoch 187/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.0910e+02\n",
      "\n",
      "Test on train set: loss= 1.5530059337615967 acc= 0.8824052810668945 auc= 0.9466036936984032\n",
      "Test on valid set: loss= 6.452212333679199 acc= 0.5662555694580078 auc= 0.881111111111111\n",
      "\n",
      "Epoch 188/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1857e+02\n",
      "\n",
      "Test on train set: loss= 1.5051939487457275 acc= 0.8708319664001465 auc= 0.9709585982545175\n",
      "Test on valid set: loss= 6.709921836853027 acc= 0.5598680973052979 auc= 0.8886666666666667\n",
      "\n",
      "Epoch 189/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.1589e+01\n",
      "\n",
      "Test on train set: loss= 1.4220794439315796 acc= 0.8903366923332214 auc= 0.9492825062047782\n",
      "Test on valid set: loss= 6.769843578338623 acc= 0.5797563791275024 auc= 0.8653333333333333\n",
      "\n",
      "Epoch 190/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1872e+02\n",
      "\n",
      "Test on train set: loss= 1.1836645603179932 acc= 0.900048553943634 auc= 0.9560461559958913\n",
      "Test on valid set: loss= 5.763858795166016 acc= 0.5918275117874146 auc= 0.8606666666666667\n",
      "\n",
      "Epoch 191/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1002e+02\n",
      "\n",
      "Test on train set: loss= 1.3572555780410767 acc= 0.8937358260154724 auc= 0.9200779375922835\n",
      "Test on valid set: loss= 6.128479480743408 acc= 0.5870548486709595 auc= 0.8268888888888888\n",
      "\n",
      "Epoch 192/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1668e+02\n",
      "\n",
      "Test on train set: loss= 2.0173189640045166 acc= 0.8476853370666504 auc= 0.9275906670120733\n",
      "Test on valid set: loss= 7.644385814666748 acc= 0.4979134202003479 auc= 0.8473333333333335\n",
      "\n",
      "Epoch 193/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.1160e+02\n",
      "\n",
      "Test on train set: loss= 1.222952127456665 acc= 0.907494306564331 auc= 0.969984037155893\n",
      "Test on valid set: loss= 5.956540584564209 acc= 0.5953124165534973 auc= 0.8802222222222221\n",
      "\n",
      "Epoch 194/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.3504e+02\n",
      "\n",
      "Test on train set: loss= 1.7237298488616943 acc= 0.8748785853385925 auc= 0.9432490240420511\n",
      "Test on valid set: loss= 5.975973129272461 acc= 0.6024947762489319 auc= 0.8593333333333332\n",
      "\n",
      "Epoch 195/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -1.2048e+02\n",
      "\n",
      "Test on train set: loss= 1.1945425271987915 acc= 0.9019909501075745 auc= 0.9252037642900068\n",
      "Test on valid set: loss= 5.035760402679443 acc= 0.641432523727417 auc= 0.8826666666666668\n",
      "\n",
      "Epoch 196/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.7763e+01\n",
      "\n",
      "Test on train set: loss= 1.4484928846359253 acc= 0.8943833112716675 auc= 0.9587155159984345\n",
      "Test on valid set: loss= 5.453418731689453 acc= 0.6441789865493774 auc= 0.8859999999999999\n",
      "\n",
      "Epoch 197/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -8.8073e+01\n",
      "\n",
      "Test on train set: loss= 1.7440669536590576 acc= 0.8743929862976074 auc= 0.9380246319640207\n",
      "Test on valid set: loss= 6.191137313842773 acc= 0.5950286984443665 auc= 0.868\n",
      "\n",
      "Epoch 198/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.3570e+01\n",
      "\n",
      "Test on train set: loss= 2.151867628097534 acc= 0.8402395844459534 auc= 0.8930700201359754\n",
      "Test on valid set: loss= 5.585834980010986 acc= 0.537467896938324 auc= 0.8608888888888888\n",
      "\n",
      "Epoch 199/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -7.5907e+01\n",
      "\n",
      "Test on train set: loss= 1.858540415763855 acc= 0.8605535626411438 auc= 0.9561114709613555\n",
      "Test on valid set: loss= 5.535873889923096 acc= 0.6403903365135193 auc= 0.886888888888889\n",
      "\n",
      "Epoch 200/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "97/97 - 3s - loss: -9.0174e+01\n",
      "\n",
      "Test on train set: loss= 1.975577712059021 acc= 0.857397198677063 auc= 0.8920868761663867\n",
      "Test on valid set: loss= 6.695670127868652 acc= 0.5774751305580139 auc= 0.8162222222222223\n",
      "\n",
      "Epoch 201/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3245e+02\n",
      "\n",
      "Test on train set: loss= 1.282928228378296 acc= 0.9012625217437744 auc= 0.9588313183743529\n",
      "Test on valid set: loss= 5.739716053009033 acc= 0.5746118426322937 auc= 0.8744444444444446\n",
      "\n",
      "Epoch 202/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3600e+02\n",
      "\n",
      "Test on train set: loss= 1.1847188472747803 acc= 0.9033668041229248 auc= 0.9666041245987678\n",
      "Test on valid set: loss= 5.329816818237305 acc= 0.6192681789398193 auc= 0.8855555555555557\n",
      "\n",
      "Epoch 203/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2510e+02\n",
      "\n",
      "Test on train set: loss= 1.1247397661209106 acc= 0.9092748165130615 auc= 0.9572164377893294\n",
      "Test on valid set: loss= 5.455320835113525 acc= 0.6398395299911499 auc= 0.8880000000000001\n",
      "\n",
      "Epoch 204/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.0548e+02\n",
      "\n",
      "Test on train set: loss= 1.053802251815796 acc= 0.9116218686103821 auc= 0.9609728069836553\n",
      "Test on valid set: loss= 4.962921142578125 acc= 0.6375724673271179 auc= 0.8768888888888888\n",
      "\n",
      "Epoch 205/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -9.8837e+01\n",
      "\n",
      "Test on train set: loss= 0.9995279908180237 acc= 0.9150210618972778 auc= 0.9655930668909974\n",
      "Test on valid set: loss= 5.556174278259277 acc= 0.6024646759033203 auc= 0.898\n",
      "\n",
      "Epoch 206/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.0159e+02\n",
      "\n",
      "Test on train set: loss= 0.9652947187423706 acc= 0.9206053614616394 auc= 0.968770630970111\n",
      "Test on valid set: loss= 5.447797775268555 acc= 0.6232724785804749 auc= 0.9033333333333333\n",
      "\n",
      "Epoch 207/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.1402e+02\n",
      "\n",
      "Test on train set: loss= 1.0571285486221313 acc= 0.915101945400238 auc= 0.9443181496115676\n",
      "Test on valid set: loss= 6.271823883056641 acc= 0.600011944770813 auc= 0.9035555555555558\n",
      "\n",
      "Epoch 208/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.1934e+02\n",
      "\n",
      "Test on train set: loss= 0.9714343547821045 acc= 0.92295241355896 auc= 0.9435975724806367\n",
      "Test on valid set: loss= 5.741077423095703 acc= 0.6381857395172119 auc= 0.9097777777777779\n",
      "\n",
      "Epoch 209/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2848e+02\n",
      "\n",
      "Test on train set: loss= 0.8952215313911438 acc= 0.9292651414871216 auc= 0.9275402639776218\n",
      "Test on valid set: loss= 5.447269916534424 acc= 0.649620532989502 auc= 0.9082222222222223\n",
      "\n",
      "Epoch 210/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2909e+02\n",
      "\n",
      "Test on train set: loss= 0.8757378458976746 acc= 0.9293460845947266 auc= 0.9475804517755444\n",
      "Test on valid set: loss= 5.14346170425415 acc= 0.6798008680343628 auc= 0.9097777777777779\n",
      "\n",
      "Epoch 211/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2469e+02\n",
      "\n",
      "Test on train set: loss= 0.8859838843345642 acc= 0.9297507405281067 auc= 0.9515131881969277\n",
      "Test on valid set: loss= 5.422918796539307 acc= 0.6531422138214111 auc= 0.9135555555555556\n",
      "\n",
      "Epoch 212/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.1062e+02\n",
      "\n",
      "Test on train set: loss= 0.831021785736084 acc= 0.9337973594665527 auc= 0.961082456788197\n",
      "Test on valid set: loss= 5.082884788513184 acc= 0.6780504584312439 auc= 0.9155555555555557\n",
      "\n",
      "Epoch 213/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.1902e+02\n",
      "\n",
      "Test on train set: loss= 0.8465516567230225 acc= 0.9324215054512024 auc= 0.9684201857764739\n",
      "Test on valid set: loss= 5.592991352081299 acc= 0.6400002837181091 auc= 0.9253333333333333\n",
      "\n",
      "Epoch 214/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2108e+02\n",
      "\n",
      "Test on train set: loss= 0.8159810304641724 acc= 0.9325833320617676 auc= 0.9704669252682209\n",
      "Test on valid set: loss= 5.4989824295043945 acc= 0.6379810571670532 auc= 0.920888888888889\n",
      "\n",
      "Epoch 215/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.2735e+02\n",
      "\n",
      "Test on train set: loss= 0.8031389713287354 acc= 0.9355778694152832 auc= 0.9707571459705695\n",
      "Test on valid set: loss= 5.215298652648926 acc= 0.6576946973800659 auc= 0.9277777777777778\n",
      "\n",
      "Epoch 216/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3881e+02\n",
      "\n",
      "Test on train set: loss= 0.8320201635360718 acc= 0.9350922703742981 auc= 0.9573743643989611\n",
      "Test on valid set: loss= 4.569404125213623 acc= 0.6822795867919922 auc= 0.9113333333333333\n",
      "\n",
      "Epoch 217/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3771e+02\n",
      "\n",
      "Test on train set: loss= 0.828800618648529 acc= 0.9331498742103577 auc= 0.9609709913270287\n",
      "Test on valid set: loss= 4.805776596069336 acc= 0.6629989147186279 auc= 0.9195555555555556\n",
      "\n",
      "Epoch 218/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3450e+02\n",
      "\n",
      "Test on train set: loss= 0.8165187239646912 acc= 0.934363842010498 auc= 0.9648766216680815\n",
      "Test on valid set: loss= 5.202477931976318 acc= 0.6407724618911743 auc= 0.9071111111111112\n",
      "\n",
      "Epoch 219/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4128e+02\n",
      "\n",
      "Test on train set: loss= 0.8293442726135254 acc= 0.9342829585075378 auc= 0.965087375189597\n",
      "Test on valid set: loss= 5.616738796234131 acc= 0.6200703382492065 auc= 0.9066666666666666\n",
      "\n",
      "Epoch 220/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4445e+02\n",
      "\n",
      "Test on train set: loss= 0.8380647301673889 acc= 0.9293460845947266 auc= 0.9572231597094358\n",
      "Test on valid set: loss= 4.987107753753662 acc= 0.6603518724441528 auc= 0.9046666666666667\n",
      "\n",
      "Epoch 221/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4905e+02\n",
      "\n",
      "Test on train set: loss= 0.766975462436676 acc= 0.9368727803230286 auc= 0.9650319958677894\n",
      "Test on valid set: loss= 5.091268062591553 acc= 0.6597706079483032 auc= 0.9208888888888888\n",
      "\n",
      "Epoch 222/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4309e+02\n",
      "\n",
      "Test on train set: loss= 0.7150713801383972 acc= 0.9397863149642944 auc= 0.9574412950554064\n",
      "Test on valid set: loss= 5.557665824890137 acc= 0.6400005221366882 auc= 0.8979999999999999\n",
      "\n",
      "Epoch 223/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4237e+02\n",
      "\n",
      "Test on train set: loss= 0.7250293493270874 acc= 0.9404338002204895 auc= 0.9632817714899466\n",
      "Test on valid set: loss= 5.26028299331665 acc= 0.6582775115966797 auc= 0.9082222222222223\n",
      "\n",
      "Epoch 224/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4964e+02\n",
      "\n",
      "Test on train set: loss= 0.7184117436408997 acc= 0.9439948201179504 auc= 0.9705976100695635\n",
      "Test on valid set: loss= 4.483614921569824 acc= 0.7013086080551147 auc= 0.918888888888889\n",
      "\n",
      "Epoch 225/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4839e+02\n",
      "\n",
      "Test on train set: loss= 0.7609789967536926 acc= 0.938572347164154 auc= 0.9688596444905366\n",
      "Test on valid set: loss= 5.781872749328613 acc= 0.6208013892173767 auc= 0.8871111111111111\n",
      "\n",
      "Epoch 226/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3323e+02\n",
      "\n",
      "Test on train set: loss= 0.6922671794891357 acc= 0.9431855082511902 auc= 0.9822818779576045\n",
      "Test on valid set: loss= 4.587575912475586 acc= 0.7000758051872253 auc= 0.9337777777777779\n",
      "\n",
      "Epoch 227/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4070e+02\n",
      "\n",
      "Test on train set: loss= 0.7193748354911804 acc= 0.9426999092102051 auc= 0.9722005188966779\n",
      "Test on valid set: loss= 5.322097301483154 acc= 0.6600054502487183 auc= 0.9177777777777779\n",
      "\n",
      "Epoch 228/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4516e+02\n",
      "\n",
      "Test on train set: loss= 0.709510326385498 acc= 0.9426999092102051 auc= 0.976766080530975\n",
      "Test on valid set: loss= 4.980200290679932 acc= 0.6662300825119019 auc= 0.9266666666666665\n",
      "\n",
      "Epoch 229/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5590e+02\n",
      "\n",
      "Test on train set: loss= 0.7190998196601868 acc= 0.9432664513587952 auc= 0.9717348337098002\n",
      "Test on valid set: loss= 4.522730350494385 acc= 0.6819021105766296 auc= 0.9228888888888889\n",
      "\n",
      "Epoch 230/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.6591e+02\n",
      "\n",
      "Test on train set: loss= 0.752913773059845 acc= 0.9413240551948547 auc= 0.9693508857415238\n",
      "Test on valid set: loss= 3.9894180297851562 acc= 0.7359915375709534 auc= 0.9126666666666667\n",
      "\n",
      "Epoch 231/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5005e+02\n",
      "\n",
      "Test on train set: loss= 0.6669700741767883 acc= 0.9475558400154114 auc= 0.970038345355363\n",
      "Test on valid set: loss= 5.344607353210449 acc= 0.6211943030357361 auc= 0.9006666666666666\n",
      "\n",
      "Epoch 232/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.3254e+02\n",
      "\n",
      "Test on train set: loss= 0.6713013648986816 acc= 0.9475558400154114 auc= 0.972170431492977\n",
      "Test on valid set: loss= 4.638442516326904 acc= 0.7000118494033813 auc= 0.9033333333333333\n",
      "\n",
      "Epoch 233/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4200e+02\n",
      "\n",
      "Test on train set: loss= 0.7104429006576538 acc= 0.9446423053741455 auc= 0.9647440585100628\n",
      "Test on valid set: loss= 4.628827095031738 acc= 0.6706287264823914 auc= 0.904888888888889\n",
      "\n",
      "Epoch 234/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5436e+02\n",
      "\n",
      "Test on train set: loss= 0.7316111326217651 acc= 0.9410812854766846 auc= 0.9603800494760598\n",
      "Test on valid set: loss= 4.136622905731201 acc= 0.7010693550109863 auc= 0.8973333333333333\n",
      "\n",
      "Epoch 235/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5789e+02\n",
      "\n",
      "Test on train set: loss= 0.6754857897758484 acc= 0.9436711072921753 auc= 0.9656478736144412\n",
      "Test on valid set: loss= 5.047664642333984 acc= 0.6400761008262634 auc= 0.8837777777777778\n",
      "\n",
      "Epoch 236/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4341e+02\n",
      "\n",
      "Test on train set: loss= 0.6185484528541565 acc= 0.9482033252716064 auc= 0.9720642886515651\n",
      "Test on valid set: loss= 4.317285060882568 acc= 0.6933112144470215 auc= 0.9068888888888889\n",
      "\n",
      "Epoch 237/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5652e+02\n",
      "\n",
      "Test on train set: loss= 0.6392804980278015 acc= 0.9470702409744263 auc= 0.9722703987672828\n",
      "Test on valid set: loss= 4.478740692138672 acc= 0.6957735419273376 auc= 0.9051111111111112\n",
      "\n",
      "Epoch 238/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5715e+02\n",
      "\n",
      "Test on train set: loss= 0.6328849792480469 acc= 0.9480414390563965 auc= 0.9712707170395719\n",
      "Test on valid set: loss= 4.084299087524414 acc= 0.7125034332275391 auc= 0.905111111111111\n",
      "\n",
      "Epoch 239/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4624e+02\n",
      "\n",
      "Test on train set: loss= 0.5812379717826843 acc= 0.949741005897522 auc= 0.9713230775555637\n",
      "Test on valid set: loss= 5.1152119636535645 acc= 0.6597777605056763 auc= 0.8966666666666667\n",
      "\n",
      "Epoch 240/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4612e+02\n",
      "\n",
      "Test on train set: loss= 0.6501086950302124 acc= 0.946341872215271 auc= 0.9702301639998525\n",
      "Test on valid set: loss= 4.506717205047607 acc= 0.7053542733192444 auc= 0.8955555555555555\n",
      "\n",
      "Epoch 241/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4911e+02\n",
      "\n",
      "Test on train set: loss= 0.5988508462905884 acc= 0.9516834020614624 auc= 0.9730868232573023\n",
      "Test on valid set: loss= 4.481070041656494 acc= 0.6847760081291199 auc= 0.8966666666666665\n",
      "\n",
      "Epoch 242/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.4410e+02\n",
      "\n",
      "Test on train set: loss= 0.6216939687728882 acc= 0.9479604959487915 auc= 0.9815796947536504\n",
      "Test on valid set: loss= 5.158623218536377 acc= 0.6791845560073853 auc= 0.916\n",
      "\n",
      "Epoch 243/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5180e+02\n",
      "\n",
      "Test on train set: loss= 0.6192407011985779 acc= 0.9503075480461121 auc= 0.9796107512123611\n",
      "Test on valid set: loss= 4.878286838531494 acc= 0.6778383255004883 auc= 0.9120000000000001\n",
      "\n",
      "Epoch 244/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5621e+02\n",
      "\n",
      "Test on train set: loss= 0.5907596349716187 acc= 0.9517643451690674 auc= 0.9744677399498904\n",
      "Test on valid set: loss= 4.466465950012207 acc= 0.6838257312774658 auc= 0.9122222222222222\n",
      "\n",
      "Epoch 245/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5609e+02\n",
      "\n",
      "Test on train set: loss= 0.6645010113716125 acc= 0.9482842087745667 auc= 0.9724126397246569\n",
      "Test on valid set: loss= 5.21553897857666 acc= 0.6586354970932007 auc= 0.8882222222222221\n",
      "\n",
      "Epoch 246/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5652e+02\n",
      "\n",
      "Test on train set: loss= 0.6081727147102356 acc= 0.9512787461280823 auc= 0.9775701643251175\n",
      "Test on valid set: loss= 4.453578472137451 acc= 0.6839467883110046 auc= 0.8931111111111111\n",
      "\n",
      "Epoch 247/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5100e+02\n",
      "\n",
      "Test on train set: loss= 0.5488021373748779 acc= 0.953787624835968 auc= 0.9769859159008604\n",
      "Test on valid set: loss= 5.205779552459717 acc= 0.6438604593276978 auc= 0.8851111111111111\n",
      "\n",
      "Epoch 248/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.5883e+02\n",
      "\n",
      "Test on train set: loss= 0.5643261671066284 acc= 0.9526546001434326 auc= 0.971694435617728\n",
      "Test on valid set: loss= 5.054561138153076 acc= 0.655735433101654 auc= 0.8904444444444444\n",
      "\n",
      "Epoch 249/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.6467e+02\n",
      "\n",
      "Test on train set: loss= 0.5340794920921326 acc= 0.9545160531997681 auc= 0.9762781139707457\n",
      "Test on valid set: loss= 4.651529312133789 acc= 0.6857381463050842 auc= 0.8926666666666666\n",
      "\n",
      "Epoch 250/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "97/97 - 3s - loss: -1.6778e+02\n",
      "\n",
      "Test on train set: loss= 0.6043471693992615 acc= 0.9489316940307617 auc= 0.9768662481794597\n",
      "Test on valid set: loss= 4.480076313018799 acc= 0.7199999094009399 auc= 0.8797777777777778\n",
      "\n",
      "Epoch 251/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7195e+02\n",
      "\n",
      "Test on train set: loss= 0.5703427195549011 acc= 0.9526546001434326 auc= 0.9777660509330215\n",
      "Test on valid set: loss= 4.405954360961914 acc= 0.7200000286102295 auc= 0.89\n",
      "\n",
      "Epoch 252/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6796e+02\n",
      "\n",
      "Test on train set: loss= 0.5534129738807678 acc= 0.9535448551177979 auc= 0.9809933421407578\n",
      "Test on valid set: loss= 4.536285877227783 acc= 0.6819095611572266 auc= 0.8993333333333334\n",
      "\n",
      "Epoch 253/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6279e+02\n",
      "\n",
      "Test on train set: loss= 0.6014558672904968 acc= 0.9500647187232971 auc= 0.9769218100898127\n",
      "Test on valid set: loss= 5.201488494873047 acc= 0.660006046295166 auc= 0.8960000000000001\n",
      "\n",
      "Epoch 254/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6348e+02\n",
      "\n",
      "Test on train set: loss= 0.5497297644615173 acc= 0.9544351100921631 auc= 0.9778846413121357\n",
      "Test on valid set: loss= 4.55746603012085 acc= 0.6818225383758545 auc= 0.9011111111111111\n",
      "\n",
      "Epoch 255/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6701e+02\n",
      "\n",
      "Test on train set: loss= 0.5577626824378967 acc= 0.9543541669845581 auc= 0.9785956652626316\n",
      "Test on valid set: loss= 5.010868072509766 acc= 0.6616701483726501 auc= 0.9022222222222223\n",
      "\n",
      "Epoch 256/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6440e+02\n",
      "\n",
      "Test on train set: loss= 0.5562778115272522 acc= 0.9549207091331482 auc= 0.980046121272434\n",
      "Test on valid set: loss= 4.997033596038818 acc= 0.679901123046875 auc= 0.8960000000000001\n",
      "\n",
      "Epoch 257/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 2s - loss: -1.6533e+02\n",
      "\n",
      "Test on train set: loss= 0.5543253421783447 acc= 0.9548397660255432 auc= 0.9789580950311974\n",
      "Test on valid set: loss= 4.944427967071533 acc= 0.6610447764396667 auc= 0.8942222222222224\n",
      "\n",
      "Epoch 258/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6516e+02\n",
      "\n",
      "Test on train set: loss= 0.5659620761871338 acc= 0.9529783129692078 auc= 0.9759160142165056\n",
      "Test on valid set: loss= 4.910832405090332 acc= 0.6625981330871582 auc= 0.9002222222222223\n",
      "\n",
      "Epoch 259/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6618e+02\n",
      "\n",
      "Test on train set: loss= 0.5720193982124329 acc= 0.9528973698616028 auc= 0.9785951423142197\n",
      "Test on valid set: loss= 4.802220344543457 acc= 0.6918870806694031 auc= 0.8946666666666667\n",
      "\n",
      "Epoch 260/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6833e+02\n",
      "\n",
      "Test on train set: loss= 0.5682817697525024 acc= 0.9527354836463928 auc= 0.9768468197320923\n",
      "Test on valid set: loss= 5.258616924285889 acc= 0.6601292490959167 auc= 0.8942222222222223\n",
      "\n",
      "Epoch 261/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6789e+02\n",
      "\n",
      "Test on train set: loss= 0.549467146396637 acc= 0.9542732238769531 auc= 0.9782035649996701\n",
      "Test on valid set: loss= 4.125674247741699 acc= 0.7346859574317932 auc= 0.8955555555555555\n",
      "\n",
      "Epoch 262/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6947e+02\n",
      "\n",
      "Test on train set: loss= 0.5698060393333435 acc= 0.9533829689025879 auc= 0.977562637350957\n",
      "Test on valid set: loss= 4.6953206062316895 acc= 0.6920414566993713 auc= 0.8953333333333333\n",
      "\n",
      "Epoch 263/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6404e+02\n",
      "\n",
      "Test on train set: loss= 0.5617446899414062 acc= 0.9542732238769531 auc= 0.9777051249640933\n",
      "Test on valid set: loss= 4.815606117248535 acc= 0.6752667427062988 auc= 0.8962222222222221\n",
      "\n",
      "Epoch 264/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6528e+02\n",
      "\n",
      "Test on train set: loss= 0.5883787274360657 acc= 0.9509549736976624 auc= 0.9757517509049922\n",
      "Test on valid set: loss= 4.902838706970215 acc= 0.67982417345047 auc= 0.8939999999999999\n",
      "\n",
      "Epoch 265/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6485e+02\n",
      "\n",
      "Test on train set: loss= 0.5584662556648254 acc= 0.9547588229179382 auc= 0.9763882403204386\n",
      "Test on valid set: loss= 5.295306205749512 acc= 0.6385349631309509 auc= 0.8928888888888891\n",
      "\n",
      "Epoch 266/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6446e+02\n",
      "\n",
      "Test on train set: loss= 0.5412395000457764 acc= 0.957267701625824 auc= 0.9783767108419241\n",
      "Test on valid set: loss= 4.748136520385742 acc= 0.6767762899398804 auc= 0.8937777777777779\n",
      "\n",
      "Epoch 267/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6763e+02\n",
      "\n",
      "Test on train set: loss= 0.5525499582290649 acc= 0.9547588229179382 auc= 0.9775191828859183\n",
      "Test on valid set: loss= 4.476408004760742 acc= 0.6816843152046204 auc= 0.8993333333333332\n",
      "\n",
      "Epoch 268/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6608e+02\n",
      "\n",
      "Test on train set: loss= 0.5437152981758118 acc= 0.9549207091331482 auc= 0.977552634637782\n",
      "Test on valid set: loss= 4.246006965637207 acc= 0.698379635810852 auc= 0.8982222222222223\n",
      "\n",
      "Epoch 269/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6162e+02\n",
      "\n",
      "Test on train set: loss= 0.515519380569458 acc= 0.9586435556411743 auc= 0.9794500099679778\n",
      "Test on valid set: loss= 5.026176452636719 acc= 0.6606601476669312 auc= 0.89\n",
      "\n",
      "Epoch 270/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.5907e+02\n",
      "\n",
      "Test on train set: loss= 0.5281490683555603 acc= 0.9562156200408936 auc= 0.9781602747358175\n",
      "Test on valid set: loss= 4.846249580383301 acc= 0.6467956304550171 auc= 0.8966666666666667\n",
      "\n",
      "Epoch 271/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6319e+02\n",
      "\n",
      "Test on train set: loss= 0.5186988711357117 acc= 0.9581579566001892 auc= 0.981052046347197\n",
      "Test on valid set: loss= 5.190095901489258 acc= 0.6401863694190979 auc= 0.8886666666666667\n",
      "\n",
      "Epoch 272/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6779e+02\n",
      "\n",
      "Test on train set: loss= 0.5349012613296509 acc= 0.9565393328666687 auc= 0.977981472172815\n",
      "Test on valid set: loss= 5.075006484985352 acc= 0.6471299529075623 auc= 0.8931111111111113\n",
      "\n",
      "Epoch 273/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7020e+02\n",
      "\n",
      "Test on train set: loss= 0.5465803742408752 acc= 0.9560537338256836 auc= 0.9774771398017968\n",
      "Test on valid set: loss= 4.981512069702148 acc= 0.6601403951644897 auc= 0.8893333333333334\n",
      "\n",
      "Epoch 274/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7456e+02\n",
      "\n",
      "Test on train set: loss= 0.526872992515564 acc= 0.957915186882019 auc= 0.9776893526494905\n",
      "Test on valid set: loss= 5.051702499389648 acc= 0.6600174307823181 auc= 0.8940000000000001\n",
      "\n",
      "Epoch 275/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7168e+02\n",
      "\n",
      "Test on train set: loss= 0.5327099561691284 acc= 0.9581579566001892 auc= 0.9793766301634642\n",
      "Test on valid set: loss= 4.8917131423950195 acc= 0.6613656282424927 auc= 0.8951111111111111\n",
      "\n",
      "Epoch 276/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7357e+02\n",
      "\n",
      "Test on train set: loss= 0.533198893070221 acc= 0.9559727907180786 auc= 0.977173663221284\n",
      "Test on valid set: loss= 4.906888008117676 acc= 0.6800333857536316 auc= 0.89\n",
      "\n",
      "Epoch 277/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6784e+02\n",
      "\n",
      "Test on train set: loss= 0.5254331231117249 acc= 0.9582388997077942 auc= 0.9788633322475109\n",
      "Test on valid set: loss= 5.354974269866943 acc= 0.6400493383407593 auc= 0.8951111111111111\n",
      "\n",
      "Epoch 278/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6740e+02\n",
      "\n",
      "Test on train set: loss= 0.5290289521217346 acc= 0.9559727907180786 auc= 0.9759066616368856\n",
      "Test on valid set: loss= 5.222825527191162 acc= 0.6315659880638123 auc= 0.8915555555555557\n",
      "\n",
      "Epoch 279/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7088e+02\n",
      "\n",
      "Test on train set: loss= 0.5323153734207153 acc= 0.9575105309486389 auc= 0.9797873750640658\n",
      "Test on valid set: loss= 5.251214981079102 acc= 0.6601872444152832 auc= 0.8935555555555557\n",
      "\n",
      "Epoch 280/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6857e+02\n",
      "\n",
      "Test on train set: loss= 0.5578358769416809 acc= 0.9550825357437134 auc= 0.9771219720141202\n",
      "Test on valid set: loss= 5.233740329742432 acc= 0.6438809633255005 auc= 0.8946666666666665\n",
      "\n",
      "Epoch 281/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6935e+02\n",
      "\n",
      "Test on train set: loss= 0.5609015226364136 acc= 0.9533829689025879 auc= 0.9770828427205801\n",
      "Test on valid set: loss= 4.871151924133301 acc= 0.6817634105682373 auc= 0.8937777777777777\n",
      "\n",
      "Epoch 282/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6747e+02\n",
      "\n",
      "Test on train set: loss= 0.542338490486145 acc= 0.9550825357437134 auc= 0.9788350574068383\n",
      "Test on valid set: loss= 4.695379257202148 acc= 0.6653076410293579 auc= 0.8904444444444444\n",
      "\n",
      "Epoch 283/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6874e+02\n",
      "\n",
      "Test on train set: loss= 0.5408193469047546 acc= 0.9558109641075134 auc= 0.9773966389305887\n",
      "Test on valid set: loss= 5.163321495056152 acc= 0.6609244346618652 auc= 0.8926666666666667\n",
      "\n",
      "Epoch 284/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6843e+02\n",
      "\n",
      "Test on train set: loss= 0.5198974609375 acc= 0.957267701625824 auc= 0.9790792980990444\n",
      "Test on valid set: loss= 4.958453178405762 acc= 0.6546591520309448 auc= 0.8908888888888888\n",
      "\n",
      "Epoch 285/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6989e+02\n",
      "\n",
      "Test on train set: loss= 0.532121479511261 acc= 0.9558109641075134 auc= 0.9785778703473793\n",
      "Test on valid set: loss= 4.541238307952881 acc= 0.6747620701789856 auc= 0.8884444444444444\n",
      "\n",
      "Epoch 286/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7142e+02\n",
      "\n",
      "Test on train set: loss= 0.5358298420906067 acc= 0.9570249319076538 auc= 0.9791974600167652\n",
      "Test on valid set: loss= 4.723928928375244 acc= 0.6643161177635193 auc= 0.8871111111111111\n",
      "\n",
      "Epoch 287/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6827e+02\n",
      "\n",
      "Test on train set: loss= 0.5691261887550354 acc= 0.9541113376617432 auc= 0.9763940056864872\n",
      "Test on valid set: loss= 5.024980068206787 acc= 0.6728811860084534 auc= 0.8960000000000001\n",
      "\n",
      "Epoch 288/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.6985e+02\n",
      "\n",
      "Test on train set: loss= 0.5366091728210449 acc= 0.9568630456924438 auc= 0.9797054858900163\n",
      "Test on valid set: loss= 4.8397932052612305 acc= 0.670325517654419 auc= 0.8933333333333333\n",
      "\n",
      "Epoch 289/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7140e+02\n",
      "\n",
      "Test on train set: loss= 0.5465945601463318 acc= 0.9577533006668091 auc= 0.9777992969277893\n",
      "Test on valid set: loss= 4.880369186401367 acc= 0.6627290844917297 auc= 0.8891111111111112\n",
      "\n",
      "Epoch 290/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7006e+02\n",
      "\n",
      "Test on train set: loss= 0.5600863099098206 acc= 0.953949511051178 auc= 0.9769441418485204\n",
      "Test on valid set: loss= 4.797069549560547 acc= 0.6799174547195435 auc= 0.8939999999999999\n",
      "\n",
      "Epoch 291/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7186e+02\n",
      "\n",
      "Test on train set: loss= 0.5420406460762024 acc= 0.9571058750152588 auc= 0.9771698873983669\n",
      "Test on valid set: loss= 4.767482757568359 acc= 0.6769867539405823 auc= 0.8977777777777778\n",
      "\n",
      "Epoch 292/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7442e+02\n",
      "\n",
      "Test on train set: loss= 0.5727788209915161 acc= 0.9549207091331482 auc= 0.9754109610160382\n",
      "Test on valid set: loss= 4.712040901184082 acc= 0.6569094657897949 auc= 0.8928888888888891\n",
      "\n",
      "Epoch 293/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7432e+02\n",
      "\n",
      "Test on train set: loss= 0.5773717164993286 acc= 0.9549207091331482 auc= 0.9752512255195083\n",
      "Test on valid set: loss= 5.1473565101623535 acc= 0.6534593105316162 auc= 0.8859999999999999\n",
      "\n",
      "Epoch 294/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7529e+02\n",
      "\n",
      "Test on train set: loss= 0.5615167021751404 acc= 0.9561346769332886 auc= 0.9743171002433367\n",
      "Test on valid set: loss= 4.605882167816162 acc= 0.6614892482757568 auc= 0.8964444444444444\n",
      "\n",
      "Epoch 295/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7638e+02\n",
      "\n",
      "Test on train set: loss= 0.5638240575790405 acc= 0.9560537338256836 auc= 0.9768171641858447\n",
      "Test on valid set: loss= 4.571488380432129 acc= 0.6757003664970398 auc= 0.8991111111111112\n",
      "\n",
      "Epoch 296/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7043e+02\n",
      "\n",
      "Test on train set: loss= 0.5633352994918823 acc= 0.9565393328666687 auc= 0.9786955937854664\n",
      "Test on valid set: loss= 4.997757434844971 acc= 0.6600307822227478 auc= 0.8997777777777778\n",
      "\n",
      "Epoch 297/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7199e+02\n",
      "\n",
      "Test on train set: loss= 0.582680344581604 acc= 0.9554063081741333 auc= 0.9756832561618873\n",
      "Test on valid set: loss= 5.1050801277160645 acc= 0.6600293517112732 auc= 0.8915555555555554\n",
      "\n",
      "Epoch 298/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7695e+02\n",
      "\n",
      "Test on train set: loss= 0.5962391495704651 acc= 0.9548397660255432 auc= 0.975026618208846\n",
      "Test on valid set: loss= 4.7578887939453125 acc= 0.6676551699638367 auc= 0.9022222222222223\n",
      "\n",
      "Epoch 299/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7506e+02\n",
      "\n",
      "Test on train set: loss= 0.5844659209251404 acc= 0.9563774466514587 auc= 0.9792827492752656\n",
      "Test on valid set: loss= 5.158251762390137 acc= 0.6562976837158203 auc= 0.8955555555555555\n",
      "\n",
      "Epoch 300/300\n",
      "\n",
      "CoSen\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "97/97 - 3s - loss: -1.7476e+02\n",
      "\n",
      "Test on train set: loss= 0.5636438727378845 acc= 0.9563774466514587 auc= 0.9751659205129337\n",
      "Test on valid set: loss= 4.995255947113037 acc= 0.6555122137069702 auc= 0.9037777777777778\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "encoding_matrix = tf.Variable(tf.eye(10), trainable=False)\n",
    "trainGen = train_generator(epochs, batch_size, encoding_matrix)\n",
    "model.set_weights(pretrainedWeights)\n",
    "model.compile(optimizer=copy.deepcopy(optimizer), loss = loss_fn)\n",
    "\n",
    "\n",
    "metric_idx = 3\n",
    "trainMetrics = (softConfusionMatrix_train[metric_idx], \n",
    "                confusionMatrix_train[metric_idx],loss_train[metric_idx], \n",
    "                acc_train[metric_idx], auc_train[metric_idx])\n",
    "\n",
    "validMetrics = (softConfusionMatrix_valid[metric_idx], \n",
    "                loss_valid[metric_idx], acc_valid[metric_idx], auc_valid[metric_idx])\n",
    "\n",
    "adjust_lr = AdjustLR(\n",
    "      schedule = lr_schedule,\n",
    "      base_learning_rate = lr,\n",
    "  )\n",
    "\n",
    "uemgm = UpdateEncodingMatrixAndGetMetrics_CoSen(beginEncodingEpoch, endEncodingEpoch,  \n",
    "                                               codingEnhancementRate, mu,\n",
    "                                               train_x_no_valid, train_y_no_valid,\n",
    "                                               valid_x, valid_y, trainMetrics, \n",
    "                                               validMetrics, 'CoSen')\n",
    "_ = model.fit(trainGen, \n",
    "              initial_epoch = beginEncodingEpoch, \n",
    "              epochs = epochs, verbose = 2,\n",
    "              steps_per_epoch = steps, callbacks=[uemgm,\n",
    "                                             adjust_lr,\n",
    "                                            ])\n",
    "\n",
    "cosenWeights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print and Plot the Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training or Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beginShowingEpoch = 0\n",
    "\n",
    "# plt.plot(acc_train[0][beginShowingEpoch:])\n",
    "# plt.plot(acc_train[1][beginShowingEpoch:])\n",
    "# plt.plot(acc_train[2][beginShowingEpoch:])\n",
    "# plt.plot(acc_train[3][beginShowingEpoch:])\n",
    "\n",
    "# plt.plot(loss_train[0][beginShowingEpoch:])\n",
    "# plt.plot(loss_train[1][beginShowingEpoch:])\n",
    "# plt.plot(loss_train[2][beginShowingEpoch:])\n",
    "# plt.plot(loss_train[3][beginShowingEpoch:])\n",
    "\n",
    "plt.plot(acc_valid[0][beginShowingEpoch:])\n",
    "plt.plot(acc_valid[1][beginShowingEpoch:])\n",
    "plt.plot(acc_valid[2][beginShowingEpoch:])\n",
    "plt.plot(acc_valid[3][beginShowingEpoch:])\n",
    "\n",
    "# plt.plot(loss_valid[0][beginShowingEpoch:])\n",
    "# plt.plot(loss_valid[1][beginShowingEpoch:])\n",
    "# plt.plot(loss_valid[2][beginShowingEpoch:])\n",
    "# plt.plot(loss_valid[3][beginShowingEpoch:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9Kf7zhM1xpuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of baseline: 0.6373000144958496\n",
      "minority accuracy of baseline: 0.4477999985218048\n",
      "\n",
      "test accuracy of enhencement encoding: 0.6866999864578247\n",
      "minority accuracy of enhencement encoding: 0.5259999990463257\n",
      "\n",
      "test accuracy of reweighting: 0.6764000058174133\n",
      "minority accuracy of reweighting: 0.501800000667572\n",
      "\n",
      "test accuracy of cost-sensitiveness: 0.6597999930381775\n",
      "minority accuracy of cost-sensitiveness: 0.502999997138977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(labels, preds):\n",
    "    pred_classes = tf.one_hot(tf.argmax(preds, axis=1), 10)\n",
    "    cm=tf.matmul(labels, pred_classes, transpose_a=True)\n",
    "    cm=cm/tf.reduce_sum(cm, axis=1, keepdims=True)\n",
    "    return cm\n",
    "\n",
    "def soft_confusion_matrix(labels, preds):\n",
    "    scm=tf.matmul(labels, preds, transpose_a=True)\n",
    "    scm=scm/tf.reduce_sum(scm, axis=1, keepdims=True)\n",
    "    return scm\n",
    "\n",
    "softConfusionMatrix_test = np.zeros((4, n_class, n_class))\n",
    "confusionMatrix_test = np.zeros((4, n_class, n_class))\n",
    "loss_test=np.zeros((4,))\n",
    "acc_test=np.zeros((4,))\n",
    "auc_test=np.zeros((4,))\n",
    "minority_acc_test=np.zeros((4,))\n",
    "experiment_keywords=['baseline', 'enhencement encoding', 'reweighting', 'cost-sensitiveness']\n",
    "weight_list = [baselineWeights, enhancementWeights, reweightWeights, cosenWeights]\n",
    "\n",
    "n_minority_class = 5\n",
    "minority_class_beging_idx = n_class - n_minority_class\n",
    "\n",
    "\n",
    "for metric_idx in range(4):\n",
    "    model.set_weights(weight_list[metric_idx])\n",
    "    y_h = tf.constant(model.predict(test_x, batch_size=evaluation_batch_size, verbose=0))\n",
    "    y = test_y\n",
    "    softConfusionMatrix_test[metric_idx] = soft_confusion_matrix(y, y_h).numpy()\n",
    "    confusionMatrix_test[metric_idx] = confusion_matrix(y, y_h).numpy()\n",
    "    loss_test[metric_idx] = tf.reduce_mean(loss_fn(y, y_h)).numpy()\n",
    "    acc_test[metric_idx] = tf.reduce_mean(keras.metrics.categorical_accuracy(y, y_h)).numpy()\n",
    "    auc_test[metric_idx] = metrics.roc_auc_score(y.numpy(), y_h.numpy(), multi_class='ovr')\n",
    "    minority_acc_test[metric_idx] = confusionMatrix_test[metric_idx,\n",
    "                                                         minority_class_beging_idx:,\n",
    "                                                         minority_class_beging_idx:].diagonal().mean()\n",
    "\n",
    "\n",
    "for k,a,ma in zip(experiment_keywords,acc_test, minority_acc_test):\n",
    "    print('test accuracy of '+k+':', a)\n",
    "    print('minority accuracy of '+k+':', ma)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Soft-Confusion Matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = [20,5])\n",
    "\n",
    "for scm_idx in range(4):\n",
    "    scm = softConfusionMatrix_test[scm_idx] * 100\n",
    "    plt.subplot(1,4,scm_idx+1)\n",
    "    plt.imshow(scm, cmap = 'Blues', vmax = 100, vmin = 0)\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            z = np.around(scm[i, j],2)\n",
    "            c = 'k' if z<50 else 'w'\n",
    "            text = plt.text(j, i, z,\n",
    "                           ha=\"center\", va=\"center\", size = 7.5,\n",
    "                           color = c\n",
    "                           )\n",
    "            \n",
    "    plt.ylabel('Index of True Class')\n",
    "    plt.xlabel('Index of Predicted Class')\n",
    "    plt.title(experiment_keywords[scm_idx])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x450 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = [20,4.5])\n",
    "\n",
    "for tsne_idx in range(4):\n",
    "    model.set_weights(weight_list[tsne_idx])\n",
    "    y_h = model.predict(test_x, batch_size=evaluation_batch_size, verbose=0)\n",
    "    predictions = np.argmax(y_h, axis = 1)\n",
    "    ts = TSNE(init= 'pca', learning_rate = 'auto')\n",
    "    results = ts.fit_transform(y_h)\n",
    "    x_min, x_max = np.min(results[:,0]), np.max(results[:,0])\n",
    "    y_min, y_max = np.min(results[:,1]), np.max(results[:,1])\n",
    "    x = (results[:,0] - x_min) / (x_max - x_min)\n",
    "    y = (results[:,1] - y_min) / (y_max - y_min)\n",
    "    plt.subplot(1,4,tsne_idx+1)  \n",
    "    plt.scatter(x, y, c = ['C'+str(p) for p in predictions])\n",
    "    plt.xticks([])        \n",
    "    plt.yticks([])\n",
    "    plt.title(experiment_keywords[tsne_idx])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFA10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "xxx",
   "language": "python",
   "name": "xxx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
